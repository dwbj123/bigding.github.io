[{"title":"java虚拟机相关问题","date":"2020-12-05T16:00:00.000Z","path":"2020/12/06/软件研发/后端/基础巩固/java/jvm/java虚拟机相关问题/","text":"Java内存模型我们开发人员编写的Java代码是怎么让电脑认识的 首先先了解电脑是二进制的系统，他只认识 01010101 比如我们经常要编写 HelloWord.java 电脑是怎么认识运行的 HelloWord.java是我们程序员编写的，我们人可以认识，但是电脑不认识 Java文件编译的过程 程序员编写的.java文件 由javac编译成字节码文件.class：（为什么编译成class文件，因为JVM只认识.class文件） 在由JVM编译成电脑认识的文件 （对于电脑系统来说 文件代表一切） 1（这是一个大概的观念 抽象画的概念） 在这里插入图片描述 为什么说java是跨平台语言 这个夸平台是中间语言（JVM）实现的夸平台 Java有JVM从软件层面屏蔽了底层硬件、指令层面的细节让他兼容各种系统 1难道 C 和 C++ 不能夸平台吗 其实也可以` `C和C++需要在编译器层面去兼容不同操作系统的不同层面，写过C和C++的就知道不同操作系统的有些代码是不一样 Jdk和Jre和JVM的区别 Jdk包括了Jre和Jvm，Jre包括了Jvm Jdk是我们编写代码使用的开发工具包 Jre 是Java的运行时环境，他大部分都是 C 和 C++ 语言编写的，他是我们在编译java时所需要的基础的类库 Jvm俗称Java虚拟机，他是java运行环境的一部分，它虚构出来的一台计算机，在通过在实际的计算机上仿真模拟各种计算机功能来实现Java应用程序 看Java官方的图片，Jdk中包括了Jre，Jre中包括了JVM 说一下 JVM由那些部分组成，运行流程是什么？ JVM包含两个子系统和两个组件: 两个子系统为Class loader(类装载)、Execution engine(执行引擎)； 两个组件为Runtime data area(运行时数据区)、Native Interface(本地接口)。 Class loader(类装载)：根据给定的全限定名类名(如：java.lang.Object)来装载class文件到Runtime data area中的method area。 Execution engine（执行引擎）：执行classes中的指令。 Native Interface(本地接口)：与native libraries交互，是其它编程语言交互的接口。 Runtime data area(运行时数据区域)：这就是我们常说的JVM的内存。 流程 ：首先通过编译器把 Java 代码转换成字节码，类加载器（ClassLoader）再把字节码加载到内存中，将其放在运行时数据区（Runtime data area）的方法区内，而字节码文件只是 JVM 的一套指令集规范，并不能直接交给底层操作系统去执行，因此需要特定的命令解析器执行引擎（Execution Engine），将字节码翻译成底层系统指令，再交由 CPU 去执行，而这个过程中需要调用其他语言的本地库接口（Native Interface）来实现整个程序的功能。 说一下 JVM 运行时数据区 Java 虚拟机在执行 Java 程序的过程中会把它所管理的内存区域划分为若干个不同的数据区域。这些区域都有各自的用途，以及创建和销毁的时间，有些区域随着虚拟机进程的启动而存在，有些区域则是依赖线程的启动和结束而建立和销毁。Java 虚拟机所管理的内存被划分为如下几个区域： 1简单的说就是我们java运行时的东西是放在那里的 在这里插入图片描述 程序计数器（Program Counter Register）：当前线程所执行的字节码的行号指示器，字节码解析器的工作是通过改变这个计数器的值，来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能，都需要依赖这个计数器来完成； 为什么要线程计数器？因为线程是不具备记忆功能 Java 虚拟机栈（Java Virtual Machine Stacks）：每个方法在执行的同时都会在Java 虚拟机栈中创建一个栈帧（Stack Frame）用于存储局部变量表、操作数栈、动态链接、方法出口等信息； 栈帧就是Java虚拟机栈中的下一个单位 本地方法栈（Native Method Stack）：与虚拟机栈的作用是一样的，只不过虚拟机栈是服务 Java 方法的，而本地方法栈是为虚拟机调用 Native 方法服务的； Native 关键字修饰的方法是看不到的，Native 方法的源码大部分都是 C和C++ 的代码 Java 堆（Java Heap）：Java 虚拟机中内存最大的一块，是被所有线程共享的，几乎所有的对象实例都在这里分配内存； 方法区（Methed Area）：用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译后的代码等数据。 1后面有详细的说明JVM 运行时数据区 详细的介绍下程序计数器？（重点理解） 程序计数器是一块较小的内存空间，它可以看作是：保存当前线程所正在执行的字节码指令的地址(行号) 由于Java虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，一个处理器都只会执行一条线程中的指令。因此，为了线程切换后能恢复到正确的执行位置，每条线程都有一个独立的程序计数器，各个线程之间计数器互不影响，独立存储。称之为“线程私有”的内存。程序计数器内存区域是虚拟机中唯一没有规定OutOfMemoryError情况的区域。 总结：也可以把它叫做线程计数器 例子：在java中最小的执行单位是线程，线程是要执行指令的，执行的指令最终操作的就是我们的电脑，就是 CPU。在CPU上面去运行，有个非常不稳定的因素，叫做调度策略，这个调度策略是时基于时间片的，也就是当前的这一纳秒是分配给那个指令的。 假如： 线程A在看直播 在这里插入图片描述 突然，线程B来了一个视频电话，就会抢夺线程A的时间片，就会打断了线程A，线程A就会挂起 在这里插入图片描述 然后，视频电话结束，这时线程A究竟该干什么？ （线程是最小的执行单位，他不具备记忆功能，他只负责去干，那这个记忆就由：程序计数器来记录） 在这里插入图片描述 详细介绍下Java虚拟机栈?（重点理解） Java虚拟机是线程私有的，它的生命周期和线程相同。 虚拟机栈描述的是Java方法执行的内存模型：每个方法在执行的同时都会创建一个栈帧（Stack Frame）用于存储局部变量表、操作数栈、动态链接、方法出口等信息。 解释：虚拟机栈中是有单位的，单位就是栈帧，一个方法一个栈帧。一个栈帧中他又要存储，局部变量，操作数栈，动态链接，出口等。 解析栈帧： 局部变量表：是用来存储我们临时8个基本数据类型、对象引用地址、returnAddress类型。（returnAddress中保存的是return后要执行的字节码的指令地址。） 操作数栈：操作数栈就是用来操作的，例如代码中有个 i = 6*6，他在一开始的时候就会进行操作，读取我们的代码，进行计算后再放入局部变量表中去 动态链接：假如我方法中，有个 service.add()方法，要链接到别的方法中去，这就是动态链接，存储链接的地方。 出口：出口是什呢，出口正常的话就是return 不正常的话就是抛出异常落 一个方法调用另一个方法，会创建很多栈帧吗？ 答：会创建。如果一个栈中有动态链接调用别的方法，就会去创建新的栈帧，栈中是由顺序的，一个栈帧调用另一个栈帧，另一个栈帧就会排在调用者下面 栈指向堆是什么意思？ 栈指向堆是什么意思，就是栈中要使用成员变量怎么办，栈中不会存储成员变量，只会存储一个应用地址 递归的调用自己会创建很多栈帧吗？ 答：递归的话也会创建多个栈帧，就是在栈中一直从上往下排下去 你能给我详细的介绍Java堆吗?（重点理解） java堆（Java Heap）是java虚拟机所管理的内存中最大的一块，是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例。 在Java虚拟机规范中的描述是：所有的对象实例以及数组都要在堆上分配。 java堆是垃圾收集器管理的主要区域，因此也被成为“GC堆”。 从内存回收角度来看java堆可分为：新生代和老生代。 从内存分配的角度看，线程共享的Java堆中可能划分出多个线程私有的分配缓冲区。 无论怎么划分，都与存放内容无关，无论哪个区域，存储的都是对象实例，进一步的划分都是为了更好的回收内存，或者更快的分配内存。 根据Java虚拟机规范的规定，java堆可以处于物理上不连续的内存空间中。当前主流的虚拟机都是可扩展的（通过 -Xmx 和 -Xms 控制）。如果堆中没有内存可以完成实例分配，并且堆也无法再扩展时，将会抛出OutOfMemoryError异常。 能不能解释一下本地方法栈？ 本地方法栈很好理解，他很栈很像，只不过方法上带了 native 关键字的栈字 它是虚拟机栈为虚拟机执行Java方法（也就是字节码）的服务方法 native关键字的方法是看不到的，必须要去oracle官网去下载才可以看的到，而且native关键字修饰的大部分源码都是C和C++的代码。 同理可得，本地方法栈中就是C和C++的代码 能不能解释一下方法区（重点理解） 方法区是所有线程共享的内存区域，它用于存储已被Java虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。 它有个别命叫Non-Heap（非堆）。当方法区无法满足内存分配需求时，抛出OutOfMemoryError异常。 什么是JVM字节码执行引擎 虚拟机核心的组件就是执行引擎，它负责执行虚拟机的字节码，一般户先进行编译成机器码后执行。 “虚拟机”是一个相对于“物理机”的概念，虚拟机的字节码是不能直接在物理机上运行的，需要JVM字节码执行引擎- 编译成机器码后才可在物理机上执行。 你听过直接内存吗？ 直接内存（Direct Memory）并不是虚拟机运行时数据区的一部分，也不是Java虚拟机中定义的内存区域。但是这部分内存也被频繁地使用，而且也可能导致 OutOfMemoryError 异常出现，所以我们放到这里一起讲解。 我的理解就是直接内存是基于物理内存和Java虚拟机内存的中间内存 知道垃圾收集系统吗？ 程序在运行过程中，会产生大量的内存垃圾（一些没有引用指向的内存对象都属于内存垃圾，因为这些对象已经无法访问，程序用不了它们了，对程序而言它们已经死亡），为了确保程序运行时的性能，java虚拟机在程序运行的过程中不断地进行自动的垃圾回收（GC）。 垃圾收集系统是Java的核心，也是不可少的，Java有一套自己进行垃圾清理的机制，开发人员无需手工清理 有一部分原因就是因为Java垃圾回收系统的强大导致Java领先市场 堆栈的区别是什么？ 对比 JVM堆 JVM栈 物理地址 堆的物理地址分配对对象是不连续的。因此性能慢些。在GC的时候也要考虑到不连续的分配，所以有各种算法。比如，标记-消除，复制，标记-压缩，分代（即新生代使用复制算法，老年代使用标记——压缩） 栈使用的是数据结构中的栈，先进后出的原则，物理地址分配是连续的。所以性能快。 内存分别 堆因为是不连续的，所以分配的内存是在运行期确认的，因此大小不固定。一般堆大小远远大于栈。 栈是连续的，所以分配的内存大小要在编译期就确认，大小是固定的。 存放的内容 堆存放的是对象的实例和数组。因此该区更关注的是数据的存储 栈存放：局部变量，操作数栈，返回结果。该区更关注的是程序方法的执行。 程序的可见度 堆对于整个应用程序都是共享、可见的。 栈只对于线程是可见的。所以也是线程私有。他的生命周期和线程相同。 注意： 静态变量放在方法区 静态的对象还是放在堆。 深拷贝和浅拷贝 浅拷贝（shallowCopy）只是增加了一个指针指向已存在的内存地址， 深拷贝（deepCopy）是增加了一个指针并且申请了一个新的内存，使这个增加的指针指向这个新的内存， 浅复制：仅仅是指向被复制的内存地址，如果原地址发生改变，那么浅复制出来的对象也会相应的改变。 深复制：在计算机中开辟一块新的内存地址用于存放复制的对象。 Java会存在内存泄漏吗？请说明为什么？ 内存泄漏是指不再被使用的对象或者变量一直被占据在内存中。理论上来说，Java是有GC垃圾回收机制的，也就是说，不再被使用的对象，会被GC自动回收掉，自动从内存中清除。 但是，即使这样，Java也还是存在着内存泄漏的情况，java导致内存泄露的原因很明确：长生命周期的对象持有短生命周期对象的引用就很可能发生内存泄露，尽管短生命周期对象已经不再需要，但是因为长生命周期对象持有它的引用而导致不能被回收，这就是java中内存泄露的发生场景。 垃圾回收机制及算法简述Java垃圾回收机制 在java中，程序员是不需要显示的去释放一个对象的内存的，而是由虚拟机自行执行。在JVM中，有一个垃圾回收线程，它是低优先级的，在正常情况下是不会执行的，只有在虚拟机空闲或者当前堆内存不足时，才会触发执行，扫面那些没有被任何引用的对象，并将它们添加到要回收的集合中，进行回收。 GC是什么？为什么要GC GC 是垃圾收集的意思（Gabage Collection）,内存处理是编程人员容易出现问题的地方，忘记或者错误的内存回收会导致程序或系统的不稳定甚至崩溃，Java 提供的 GC 功能可以自动监测对象是否超过作用域从而达到自动回收内存的目的，Java 语言没有提供释放已分配内存的显示操作方法。 垃圾回收的优点和缺点 优点：JVM的垃圾回收器都不需要我们手动处理无引用的对象了，这个就是最大的优点 缺点：程序员不能实时的对某个对象或所有对象调用垃圾回收器进行垃圾回收。 垃圾回收器的原理是什么？有什么办法手动进行垃圾回收？ 对于GC来说，当程序员创建对象时，GC就开始监控这个对象的地址、大小以及使用情况。 通常，GC采用有向图的方式记录和管理堆(heap)中的所有对象。通过这种方式确定哪些对象是”可达的”，哪些对象是”不可达的”。当GC确定一些对象为”不可达”时，GC就有责任回收这些内存空间。 可以。程序员可以手动执行System.gc()，通知GC运行，但是Java语言规范并不保证GC一定会执行。 JVM 中都有哪些引用类型？ 强引用：发生 gc 的时候不会被回收。 软引用：有用但不是必须的对象，在发生内存溢出之前会被回收。 弱引用：有用但不是必须的对象，在下一次GC时会被回收。 虚引用（幽灵引用/幻影引用）：无法通过虚引用获得对象，用 PhantomReference 实现虚引用，虚引用的用途是在 gc 时返回一个通知。 怎么判断对象是否可以被回收？ 垃圾收集器在做垃圾回收的时候，首先需要判定的就是哪些内存是需要被回收的，哪些对象是存活的，是不可以被回收的；哪些对象已经死掉了，需要被回收。 一般有两种方法来判断： 引用计数器法：为每个对象创建一个引用计数，有对象引用时计数器 +1，引用被释放时计数 -1，当计数器为 0 时就可以被回收。它有一个缺点不能解决循环引用的问题；（这个已经淘汰了） 可达性分析算法：从 GC Roots 开始向下搜索，搜索所走过的路径称为引用链。当一个对象到 GC Roots 没有任何引用链相连时，则证明此对象是可以被回收的。（市场上用的非常非常广泛） Full GC是什么 清理整个堆空间—包括年轻代和老年代和永久代 因为Full GC是清理整个堆空间所以Full GC执行速度非常慢，在Java开发中最好保证少触发Full GC 对象什么时候可以被垃圾器回收 当对象对当前使用这个对象的应用程序变得不可触及的时候，这个对象就可以被回收了。 垃圾回收不会发生在永久代，如果永久代满了或者是超过了临界值，会触发完全垃圾回收(Full GC)。如果你仔细查看垃圾收集器的输出信息，就会发现永久代也是被回收的。这就是为什么正确的永久代大小对避免Full GC是非常重要的原因。 JVM 垃圾回收算法有哪些？ 标记-清除算法：标记无用对象，然后进行清除回收。缺点：效率不高，无法清除垃圾碎片。 复制算法：按照容量划分二个大小相等的内存区域，当一块用完的时候将活着的对象复制到另一块上，然后再把已使用的内存空间一次清理掉。缺点：内存使用率不高，只有原来的一半。 标记-整理算法：标记无用对象，让所有存活的对象都向一端移动，然后直接清除掉端边界以外的内存。 分代算法：根据对象存活周期的不同将内存划分为几块，一般是新生代和老年代，新生代基本采用复制算法，老年代采用标记整理算法。 标记-清除算法 标记无用对象，然后进行清除回收。 标记-清除算法（Mark-Sweep）是一种常见的基础垃圾收集算法，它将垃圾收集分为两个阶段： 标记阶段：标记出可以回收的对象。 清除阶段：回收被标记的对象所占用的空间。 标记-清除算法之所以是基础的，是因为后面讲到的垃圾收集算法都是在此算法的基础上进行改进的。 优点：实现简单，不需要对象进行移动。 缺点：标记、清除过程效率低，产生大量不连续的内存碎片，提高了垃圾回收的频率。 标记-清除算法的执行的过程如下图所示 复制算法 为了解决标记-清除算法的效率不高的问题，产生了复制算法。它把内存空间划为两个相等的区域，每次只使用其中一个区域。垃圾收集时，遍历当前使用的区域，把存活对象复制到另外一个区域中，最后将当前使用的区域的可回收的对象进行回收。 优点：按顺序分配内存即可，实现简单、运行高效，不用考虑内存碎片。 缺点：可用的内存大小缩小为原来的一半，对象存活率高时会频繁进行复制。 复制算法的执行过程如下图所示 标记-整理算法 在新生代中可以使用复制算法，但是在老年代就不能选择复制算法了，因为老年代的对象存活率会较高，这样会有较多的复制操作，导致效率变低。标记-清除算法可以应用在老年代中，但是它效率不高，在内存回收后容易产生大量内存碎片。因此就出现了一种标记-整理算法（Mark-Compact）算法，与标记-整理算法不同的是，在标记可回收的对象后将所有存活的对象压缩到内存的一端，使他们紧凑的排列在一起，然后对端边界以外的内存进行回收。回收后，已用和未用的内存都各自一边。 优点：解决了标记-清理算法存在的内存碎片问题。 缺点：仍需要进行局部对象移动，一定程度上降低了效率。 标记-整理算法的执行过程如下图所示 分代收集算法 当前商业虚拟机都采用 分代收集的垃圾收集算法。分代收集算法，顾名思义是根据对象的存活周期将内存划分为几块。一般包括年轻代、老年代和 永久代，如图所示：（后面有重点讲解） JVM中的永久代中会发生垃圾回收吗 垃圾回收不会发生在永久代，如果永久代满了或者是超过了临界值，会触发完全垃圾回收(Full GC)。如果你仔细查看垃圾收集器的输出信息，就会发现永久代也是被回收的。这就是为什么正确的永久代大小对避免Full GC是非常重要的原因。请参考下Java8：从永久代到元数据区 (注：Java8中已经移除了永久代，新加了一个叫做元数据区的native内存区) 垃圾收集器以及新生代、老年代、永久代讲一下新生代、老年代、永久代的区别 在 Java 中，堆被划分成两个不同的区域：新生代 ( Young )、老年代 ( Old )。而新生代 ( Young ) 又被划分为三个区域：Eden、From Survivor、To Survivor。这样划分的目的是为了使 JVM 能够更好的管理堆内存中的对象，包括内存的分配以及回收。 新生代中一般保存新出现的对象，所以每次垃圾收集时都发现大批对象死去，只有少量对象存活，便采用了复制算法，只需要付出少量存活对象的复制成本就可以完成收集。 老年代中一般保存存活了很久的对象，他们存活率高、没有额外空间对它进行分配担保，就必须采用“标记-清理”或者“标记-整理”算法。 永久代就是JVM的方法区。在这里都是放着一些被虚拟机加载的类信息，静态变量，常量等数据。这个区中的东西比老年代和新生代更不容易回收。 Minor GC、Major GC、Full GC是什么 Minor GC是新生代GC，指的是发生在新生代的垃圾收集动作。由于java对象大都是朝生夕死的，所以Minor GC非常频繁，一般回收速度也比较快。（一般采用复制算法回收垃圾） Major GC是老年代GC，指的是发生在老年代的GC，通常执行Major GC会连着Minor GC一起执行。Major GC的速度要比Minor GC慢的多。（可采用标记清楚法和标记整理法） Full GC是清理整个堆空间，包括年轻代和老年代 Minor GC、Major GC、Full GC区别及触发条件 Minor GC 触发条件一般为： eden区满时，触发MinorGC。即申请一个对象时，发现eden区不够用，则触发一次MinorGC。 新创建的对象大小 &gt; Eden所剩空间时触发Minor GC Major GC和Full GC 触发条件一般为： Major GC通常是跟full GC是等价的 每次晋升到老年代的对象平均大小&gt;老年代剩余空间 MinorGC后存活的对象超过了老年代剩余空间 永久代空间不足 执行System.gc() CMS GC异常 堆内存分配很大的对象 为什么新生代要分Eden和两个 Survivor 区域？ 如果没有Survivor，Eden区每进行一次Minor GC，存活的对象就会被送到老年代。老年代很快被填满，触发Major GC.老年代的内存空间远大于新生代，进行一次Full GC消耗的时间比Minor GC长得多,所以需要分为Eden和Survivor。 Survivor的存在意义，就是减少被送到老年代的对象，进而减少Full GC的发生，Survivor的预筛选保证，只有经历15次Minor GC还能在新生代中存活的对象，才会被送到老年代。 设置两个Survivor区最大的好处就是解决了碎片化，刚刚新建的对象在Eden中，经历一次Minor GC，Eden中的存活对象就会被移动到第一块survivor space S0，Eden被清空；等Eden区再满了，就再触发一次Minor GC，Eden和S0中的存活对象又会被复制送入第二块survivor space S1（这个过程非常重要，因为这种复制算法保证了S1中来自S0和Eden两部分的存活对象占用连续的内存空间，避免了碎片化的发生） Java堆老年代( Old ) 和新生代 ( Young ) 的默认比例？ 默认的，新生代 ( Young ) 与老年代 ( Old ) 的比例的值为 1:2 ( 该值可以通过参数 –XX:NewRatio 来指定 )，即：新生代 ( Young ) = 1/3 的堆空间大小。老年代 ( Old ) = 2/3 的堆空间大小。 其中，新生代 ( Young ) 被细分为 Eden 和 两个 Survivor 区域，Edem 和俩个Survivor 区域比例是 = 8 : 1 : 1 ( 可以通过参数 –XX:SurvivorRatio 来设定 )， 但是JVM 每次只会使用 Eden 和其中的一块 Survivor 区域来为对象服务，所以无论什么时候，总是有一块 Survivor 区域是空闲着的。 为什么要这样分代： 其实主要原因就是可以根据各个年代的特点进行对象分区存储，更便于回收，采用最适当的收集算法： 新生代中，每次垃圾收集时都发现大批对象死去，只有少量对象存活，便采用了复制算法，只需要付出少量存活对象的复制成本就可以完成收集。 而老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须采用“标记-清理”或者“标记-整理”算法。 新生代又分为Eden和Survivor （From与To，这里简称一个区）两个区。加上老年代就这三个区。数据会首先分配到Eden区当中（当然也有特殊情况，如果是大对象那么会直接放入到老年代（大对象是指需要大量连续内存空间的java对象）。当Eden没有足够空间的时候就会触发jvm发起一次Minor GC，。如果对象经过一次Minor-GC还存活，并且又能被Survivor空间接受，那么将被移动到Survivor空间当中。并将其年龄设为1，对象在Survivor每熬过一次Minor GC，年龄就加1，当年龄达到一定的程度（默认为15）时，就会被晋升到老年代中了，当然晋升老年代的年龄是可以设置的。 什么是垃圾回收器他和垃圾算法有什么区别 垃圾收集器是垃圾回收算法（标记清楚法、标记整理法、复制算法、分代算法）的具体实现，不同垃圾收集器、不同版本的JVM所提供的垃圾收集器可能会有很在差别。 说一下 JVM 有哪些垃圾回收器？ 如果说垃圾收集算法是内存回收的方法论，那么垃圾收集器就是内存回收的具体实现。下图展示了7种作用于不同分代的收集器，其中用于回收新生代的收集器包括Serial、PraNew、Parallel Scavenge，回收老年代的收集器包括Serial Old、Parallel Old、CMS，还有用于回收整个Java堆的G1收集器。不同收集器之间的连线表示它们可以搭配使用。 垃圾回收器 工作区域 回收算法 工作线程 用户线程并行 描述 Serial 新生带 复制算法 单线程 否 Client模式下默认新生代收集器。简单高效 ParNew 新生带 复制算法 多线程 否 Serial的多线程版本，Server模式下首选， 可搭配CMS的新生代收集器 Parallel Scavenge 新生带 复制算法 多线程 否 目标是达到可控制的吞吐量 Serial Old 老年带 标记-整理 单线程 否 Serial老年代版本，给Client模式下的虚拟机使用 Parallel Old 老年带 标记-整理 多线程 否 Parallel Scavenge老年代版本，吞吐量优先 G1 新生带 + 老年带 标记-整理 + 复制算法 多线程 是 JDK1.9默认垃圾收集器 Serial收集器（复制算法): 新生代单线程收集器，标记和清理都是单线程，优点是简单高效； ParNew收集器 (复制算法): 新生代收并行集器，实际上是Serial收集器的多线程版本，在多核CPU环境下有着比Serial更好的表现； Parallel Scavenge收集器 (复制算法): 新生代并行收集器，追求高吞吐量，高效利用 CPU。吞吐量 = 用户线程时间/(用户线程时间+GC线程时间)，高吞吐量可以高效率的利用CPU时间，尽快完成程序的运算任务，适合后台应用等对交互相应要求不高的场景； Serial Old收集器 (标记-整理算法): 老年代单线程收集器，Serial收集器的老年代版本； Parallel Old收集器 (标记-整理算法)： 老年代并行收集器，吞吐量优先，Parallel Scavenge收集器的老年代版本； CMS(Concurrent Mark Sweep)收集器（标记-清除算法）： 老年代并行收集器，以获取最短回收停顿时间为目标的收集器，具有高并发、低停顿的特点，追求最短GC回收停顿时间。 G1(Garbage First)收集器 ( 标记整理 + 复制算法来回收垃圾 )： Java堆并行收集器，G1收集器是JDK1.7提供的一个新收集器，G1收集器基于“标记-整理”算法实现，也就是说不会产生内存碎片。此外，G1收集器不同于之前的收集器的一个重要特点是：G1回收的范围是整个Java堆(包括新生代，老年代)，而前六种收集器回收的范围仅限于新生代或老年代。 收集器可以这么分配？（了解就好了）12345678Serial / Serial OldSerial / CMSParNew / Serial OldParNew / CMSParallel Scavenge / Serial OldParallel Scavenge / Parallel OldG1复制代码 新生代垃圾回收器和老年代垃圾回收器都有哪些？有什么区别？ 新生代回收器：Serial、ParNew、Parallel Scavenge 老年代回收器：Serial Old、Parallel Old、CMS 整堆回收器：G1 新生代垃圾回收器一般采用的是复制算法，复制算法的优点是效率高，缺点是内存利用率低；老年代回收器一般采用的是标记-整理的算法进行垃圾回收。 简述分代垃圾回收器是怎么工作的？ 分代回收器有两个分区：老生代和新生代，新生代默认的空间占比总空间的 1/3，老生代的默认占比是 2/3。 新生代使用的是复制算法，新生代里有 3 个分区：Eden、To Survivor、From Survivor，它们的默认占比是 8:1:1，它的执行流程如下： 把 Eden + From Survivor 存活的对象放入 To Survivor 区； 清空 Eden 和 From Survivor 分区； From Survivor 和 To Survivor 分区交换，From Survivor 变 To Survivor，To Survivor 变 From Survivor。 每次在 From Survivor 到 To Survivor 移动时都存活的对象，年龄就 +1，当年龄到达 15（默认配置是 15）时，升级为老生代。大对象也会直接进入老生代。 老生代当空间占用到达某个值之后就会触发全局垃圾收回，一般使用标记整理的执行算法。以上这些循环往复就构成了整个分代垃圾回收的整体执行流程。 内存分配策略简述java内存分配与回收策率以及Minor GC和Major GC 所谓自动内存管理，最终要解决的也就是内存分配和内存回收两个问题。前面我们介绍了内存回收，这里我们再来聊聊内存分配。 对象的内存分配通常是在 Java 堆上分配（随着虚拟机优化技术的诞生，某些场景下也会在栈上分配，后面会详细介绍），对象主要分配在新生代的 Eden 区，如果启动了本地线程缓冲，将按照线程优先在 TLAB 上分配。少数情况下也会直接在老年代上分配。总的来说分配规则不是百分百固定的，其细节取决于哪一种垃圾收集器组合以及虚拟机相关参数有关，但是虚拟机对于内存的分配还是会遵循以下几种「普世」规则： 对象优先在 Eden 区分配 多数情况，对象都在新生代 Eden 区分配。当 Eden 区分配没有足够的空间进行分配时，虚拟机将会发起一次 Minor GC。如果本次 GC 后还是没有足够的空间，则将启用分配担保机制在老年代中分配内存。 这里我们提到 Minor GC，如果你仔细观察过 GC 日常，通常我们还能从日志中发现 Major GC/Full GC。 Minor GC 是指发生在新生代的 GC，因为 Java 对象大多都是朝生夕死，所有 Minor GC 非常频繁，一般回收速度也非常快； Major GC/Full GC 是指发生在老年代的 GC，出现了 Major GC 通常会伴随至少一次 Minor GC。Major GC 的速度通常会比 Minor GC 慢 10 倍以上。 为什么大对象直接进入老年代 所谓大对象是指需要大量连续内存空间的对象，频繁出现大对象是致命的，会导致在内存还有不少空间的情况下提前触发 GC 以获取足够的连续空间来安置新对象。 前面我们介绍过新生代使用的是标记-清除算法来处理垃圾回收的，如果大对象直接在新生代分配就会导致 Eden 区和两个 Survivor 区之间发生大量的内存复制。因此对于大对象都会直接在老年代进行分配。 长期存活对象将进入老年代 虚拟机采用分代收集的思想来管理内存，那么内存回收时就必须判断哪些对象应该放在新生代，哪些对象应该放在老年代。因此虚拟机给每个对象定义了一个对象年龄的计数器，如果对象在 Eden 区出生，并且能够被 Survivor 容纳，将被移动到 Survivor 空间中，这时设置对象年龄为 1。对象在 Survivor 区中每「熬过」一次 Minor GC 年龄就加 1，当年龄达到一定程度（默认 15） 就会被晋升到老年代。 虚拟机类加载机制简述java类加载机制? 虚拟机把描述类的数据从Class文件加载到内存，并对数据进行校验，解析和初始化，最终形成可以被虚拟机直接使用的java类型。 类加载的机制及过程 程序主动使用某个类时，如果该类还未被加载到内存中，则JVM会通过加载、连接、初始化3个步骤来对该类进行初始化。如果没有意外，JVM将会连续完成3个步骤，所以有时也把这个3个步骤统称为类加载或类初始化。 1、加载 加载指的是将类的class文件读入到内存，并将这些静态数据转换成方法区中的运行时数据结构，并在堆中生成一个代表这个类的java.lang.Class对象，作为方法区类数据的访问入口，这个过程需要类加载器参与。 Java类加载器由JVM提供，是所有程序运行的基础，JVM提供的这些类加载器通常被称为系统类加载器。除此之外，开发者可以通过继承ClassLoader基类来创建自己的类加载器。 类加载器，可以从不同来源加载类的二进制数据，比如：本地Class文件、Jar包Class文件、网络Class文件等等等。 类加载的最终产物就是位于堆中的Class对象（注意不是目标类对象），该对象封装了类在方法区中的数据结构，并且向用户提供了访问方法区数据结构的接口，即Java反射的接口 2、连接过程 当类被加载之后，系统为之生成一个对应的Class对象，接着将会进入连接阶段，连接阶段负责把类的二进制数据合并到JRE中（意思就是将java类的二进制代码合并到JVM的运行状态之中）。类连接又可分为如下3个阶段。 验证：确保加载的类信息符合JVM规范，没有安全方面的问题。主要验证是否符合Class文件格式规范，并且是否能被当前的虚拟机加载处理。 准备：正式为类变量（static变量）分配内存并设置类变量初始值的阶段，这些内存都将在方法区中进行分配 解析：虚拟机常量池的符号引用替换为字节引用过程 3、初始化 初始化阶段是执行类构造器() 方法的过程。类构造器()方法是由编译器自动收藏类中的所有类变量的赋值动作和静态语句块(static块)中的语句合并产生，代码从上往下执行。 当初始化一个类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化 虚拟机会保证一个类的() 方法在多线程环境中被正确加锁和同步 1初始化的总结就是：初始化是为类的静态变量赋予正确的初始值 描述一下JVM加载Class文件的原理机制 Java中的所有类，都需要由类加载器装载到JVM中才能运行。类加载器本身也是一个类，而它的工作就是把class文件从硬盘读取到内存中。在写程序的时候，我们几乎不需要关心类的加载，因为这些都是隐式装载的，除非我们有特殊的用法，像是反射，就需要显式的加载所需要的类。 类装载方式，有两种 ： 1.隐式装载， 程序在运行过程中当碰到通过new 等方式生成对象时，隐式调用类装载器加载对应的类到jvm中， 2.显式装载， 通过class.forname()等方法，显式加载需要的类 Java类的加载是动态的，它并不会一次性将所有类全部加载后再运行，而是保证程序运行的基础类(像是基类)完全加载到jvm中，至于其他类，则在需要的时候才加载。这当然就是为了节省内存开销。 什么是类加载器，类加载器有哪些? 实现通过类的权限定名获取该类的二进制字节流的代码块叫做类加载器。 主要有一下四种类加载器: 启动类加载器(Bootstrap ClassLoader)用来加载java核心类库，无法被java程序直接引用。 扩展类加载器(extensions class loader):它用来加载 Java 的扩展库。Java 虚拟机的实现会提供一个扩展库目录。该类加载器在此目录里面查找并加载 Java 类。 系统类加载器（system class loader）：它根据 Java 应用的类路径（CLASSPATH）来加载 Java 类。一般来说，Java 应用的类都是由它来完成加载的。可以通过 ClassLoader.getSystemClassLoader()来获取它。 用户自定义类加载器，通过继承 java.lang.ClassLoader类的方式实现。 说一下类装载的执行过程？ 类装载分为以下 5 个步骤： 加载：根据查找路径找到相应的 class 文件然后导入； 验证：检查加载的 class 文件的正确性； 准备：给类中的静态变量分配内存空间； 解析：虚拟机将常量池中的符号引用替换成直接引用的过程。符号引用就理解为一个标示，而在直接引用直接指向内存中的地址； 初始化：对静态变量和静态代码块执行初始化工作。 什么是双亲委派模型？ 在介绍双亲委派模型之前先说下类加载器。对于任意一个类，都需要由加载它的类加载器和这个类本身一同确立在 JVM 中的唯一性，每一个类加载器，都有一个独立的类名称空间。类加载器就是根据指定全限定名称将 class 文件加载到 JVM 内存，然后再转化为 class 对象。 类加载器分类： 启动类加载器（Bootstrap ClassLoader），是虚拟机自身的一部分，用来加载Java_HOME/lib/目录中的，或者被 -Xbootclasspath 参数所指定的路径中并且被虚拟机识别的类库； 其他类加载器： 扩展类加载器（Extension ClassLoader）：负责加载\\lib\\ext目录或Java. ext. dirs系统变量指定的路径中的所有类库； 应用程序类加载器（Application ClassLoader）。负责加载用户类路径（classpath）上的指定类库，我们可以直接使用这个类加载器。一般情况，如果我们没有自定义类加载器默认就是用这个加载器。 双亲委派模型：如果一个类加载器收到了类加载的请求，它首先不会自己去加载这个类，而是把这个请求委派给父类加载器去完成，每一层的类加载器都是如此，这样所有的加载请求都会被传送到顶层的启动类加载器中，只有当父加载无法完成加载请求（它的搜索范围中没找到所需的类）时，子加载器才会尝试去加载类。 总结就是：当一个类收到了类加载请求时，不会自己先去加载这个类，而是将其委派给父类，由父类去加载，如果此时父类不能加载，反馈给子类，由子类去完成类的加载。 JVM调优JVM 调优的参数可以在那设置参数值 可以在IDEA，Eclipse，工具里设置 如果上线了是WAR包的话可以在Tomcat设置 如果是Jar包直接 ：java -jar 是直接插入JVM命令就好了 12java -Xms1024m -Xmx1024m ...等等等 JVM参数 -jar springboot_app.jar &amp; 复制代码 说一下 JVM 调优的工具？ JDK 自带了很多监控工具，都位于 JDK 的 bin 目录下，其中最常用的是 jconsole 和 jvisualvm 这两款视图监控工具。 jconsole：用于对 JVM 中的内存、线程和类等进行监控； 在这里插入图片描述 jvisualvm：JDK 自带的全能分析工具，可以分析：内存快照、线程快照、程序死锁、监控内存的变化、gc 变化等。 在这里插入图片描述 常用的 JVM 调优的参数都有哪些？12345678910111213141516171819202122232425262728293031323334353637383940414243#常用的设置-Xms：初始堆大小，JVM 启动的时候，给定堆空间大小。 -Xmx：最大堆大小，JVM 运行过程中，如果初始堆空间不足的时候，最大可以扩展到多少。 -Xmn：设置堆中年轻代大小。整个堆大小=年轻代大小+年老代大小+持久代大小。 -XX:NewSize=n 设置年轻代初始化大小大小 -XX:MaxNewSize=n 设置年轻代最大值-XX:NewRatio=n 设置年轻代和年老代的比值。如: -XX:NewRatio=3，表示年轻代与年老代比值为 1：3，年轻代占整个年轻代+年老代和的 1/4 -XX:SurvivorRatio=n 年轻代中 Eden 区与两个 Survivor 区的比值。注意 Survivor 区有两个。8表示两个Survivor :eden=2:8 ,即一个Survivor占年轻代的1/10，默认就为8-Xss：设置每个线程的堆栈大小。JDK5后每个线程 Java 栈大小为 1M，以前每个线程堆栈大小为 256K。-XX:ThreadStackSize=n 线程堆栈大小-XX:PermSize=n 设置持久代初始值 -XX:MaxPermSize=n 设置持久代大小 -XX:MaxTenuringThreshold=n 设置年轻带垃圾对象最大年龄。如果设置为 0 的话，则年轻代对象不经过 Survivor 区，直接进入年老代。#下面是一些不常用的-XX:LargePageSizeInBytes=n 设置堆内存的内存页大小-XX:+UseFastAccessorMethods 优化原始类型的getter方法性能-XX:+DisableExplicitGC 禁止在运行期显式地调用System.gc()，默认启用 -XX:+AggressiveOpts 是否启用JVM开发团队最新的调优成果。例如编译优化，偏向锁，并行年老代收集等，jdk6纸之后默认启动-XX:+UseBiasedLocking 是否启用偏向锁，JDK6默认启用 -Xnoclassgc 是否禁用垃圾回收-XX:+UseThreadPriorities 使用本地线程的优先级，默认启用 等等等......复制代码 JVM的GC收集器设置 -xx:+Use xxx GC xxx 代表垃圾收集器名称 1234567891011-XX:+UseSerialGC:设置串行收集器，年轻带收集器 -XX:+UseParNewGC:设置年轻代为并行收集。可与 CMS 收集同时使用。JDK5.0 以上，JVM 会根据系统配置自行设置，所以无需再设置此值。-XX:+UseParallelGC:设置并行收集器，目标是目标是达到可控制的吞吐量-XX:+UseParallelOldGC:设置并行年老代收集器，JDK6.0 支持对年老代并行收集。 -XX:+UseConcMarkSweepGC:设置年老代并发收集器-XX:+UseG1GC:设置 G1 收集器，JDK1.9默认垃圾收集器 作者：小杰要吃蛋链接：https://juejin.cn/post/6844904125696573448来源：掘金著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 【1】简书主页·share猿【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"},{"name":"基础","slug":"基础","permalink":"https://lywlefan.github.io/tags/基础/"}]},{"title":"java异常相关问题","date":"2020-09-02T16:00:00.000Z","path":"2020/09/03/软件研发/后端/基础巩固/java/异常/java异常相关问题/","text":"Java异常架构与异常关键字Java异常简介 Java异常是Java提供的一种识别及响应错误的一致性机制。 Java异常机制可以使程序中异常处理代码和正常业务代码分离，保证程序代码更加优雅，并提高程序健壮性。在有效使用异常的情况下，异常能清晰的回答what, where, why这3个问题：异常类型回答了“什么”被抛出，异常堆栈跟踪回答了“在哪”抛出，异常信息回答了“为什么”会抛出。 Java异常架构 1. Throwable Throwable 是 Java 语言中所有错误与异常的超类。 Throwable 包含两个子类：Error（错误）和 Exception（异常），它们通常用于指示发生了异常情况。 Throwable 包含了其线程创建时线程执行堆栈的快照，它提供了 printStackTrace() 等接口用于获取堆栈跟踪数据等信息。 2. Error（错误） 定义：Error 类及其子类。程序中无法处理的错误，表示运行应用程序中出现了严重的错误。 特点：此类错误一般表示代码运行时 JVM 出现问题。通常有 Virtual MachineError（虚拟机运行错误）、NoClassDefFoundError（类定义错误）等。比如 OutOfMemoryError：内存不足错误；StackOverflowError：栈溢出错误。此类错误发生时，JVM 将终止线程。 这些错误是不受检异常，非代码性错误。因此，当此类错误发生时，应用程序不应该去处理此类错误。按照Java惯例，我们是不应该实现任何新的Error子类的！ 3. Exception（异常） 程序本身可以捕获并且可以处理的异常。Exception 这种异常又分为两类：运行时异常和编译时异常。 运行时异常 定义：RuntimeException 类及其子类，表示 JVM 在运行期间可能出现的异常。 特点：Java 编译器不会检查它。也就是说，当程序中可能出现这类异常时，倘若既”没有通过throws声明抛出它”，也”没有用try-catch语句捕获它”，还是会编译通过。比如NullPointerException空指针异常、ArrayIndexOutBoundException数组下标越界异常、ClassCastException类型转换异常、ArithmeticExecption算术异常。此类异常属于不受检异常，一般是由程序逻辑错误引起的，在程序中可以选择捕获处理，也可以不处理。虽然 Java 编译器不会检查运行时异常，但是我们也可以通过 throws 进行声明抛出，也可以通过 try-catch 对它进行捕获处理。如果产生运行时异常，则需要通过修改代码来进行避免。例如，若会发生除数为零的情况，则需要通过代码避免该情况的发生！ RuntimeException 异常会由 Java 虚拟机自动抛出并自动捕获（就算我们没写异常捕获语句运行时也会抛出错误！！），此类异常的出现绝大数情况是代码本身有问题应该从逻辑上去解决并改进代码。 编译时异常 定义: Exception 中除 RuntimeException 及其子类之外的异常。 特点: Java 编译器会检查它。如果程序中出现此类异常，比如 ClassNotFoundException（没有找到指定的类异常），IOException（IO流异常），要么通过throws进行声明抛出，要么通过try-catch进行捕获处理，否则不能通过编译。在程序中，通常不会自定义该类异常，而是直接使用系统提供的异常类。该异常我们必须手动在代码里添加捕获语句来处理该异常。 4. 受检异常与非受检异常 Java 的所有异常可以分为受检异常（checked exception）和非受检异常（unchecked exception）。 受检异常 编译器要求必须处理的异常。正确的程序在运行过程中，经常容易出现的、符合预期的异常情况。一旦发生此类异常，就必须采用某种方式进行处理。除 RuntimeException 及其子类外，其他的 Exception 异常都属于受检异常。编译器会检查此类异常，也就是说当编译器检查到应用中的某处可能会此类异常时，将会提示你处理本异常——要么使用try-catch捕获，要么使用方法签名中用 throws 关键字抛出，否则编译不通过。 非受检异常 编译器不会进行检查并且不要求必须处理的异常，也就说当程序中出现此类异常时，即使我们没有try-catch捕获它，也没有使用throws抛出该异常，编译也会正常通过。该类异常包括运行时异常（RuntimeException极其子类）和错误（Error）。 Java异常关键字 try – 用于监听。将要被监听的代码(可能抛出异常的代码)放在try语句块之内，当try语句块内发生异常时，异常就被抛出。 catch – 用于捕获异常。catch用来捕获try语句块中发生的异常。 finally – finally语句块总是会被执行。它主要用于回收在try块里打开的物力资源(如数据库连接、网络连接和磁盘文件)。只有finally块，执行完成之后，才会回来执行try或者catch块中的return或者throw语句，如果finally中使用了return或者throw等终止方法的语句，则就不会跳回执行，直接停止。 throw – 用于抛出异常。 throws – 用在方法签名中，用于声明该方法可能抛出的异常。 Java异常处理 Java 通过面向对象的方法进行异常处理，一旦方法抛出异常，系统自动根据该异常对象寻找合适异常处理器（Exception Handler）来处理该异常，把各种不同的异常进行分类，并提供了良好的接口。在 Java 中，每个异常都是一个对象，它是 Throwable 类或其子类的实例。当一个方法出现异常后便抛出一个异常对象，该对象中包含有异常信息，调用这个对象的方法可以捕获到这个异常并可以对其进行处理。Java 的异常处理是通过 5 个关键词来实现的：try、catch、throw、throws 和 finally。 在Java应用中，异常的处理机制分为声明异常，抛出异常和捕获异常。 声明异常 通常，应该捕获那些知道如何处理的异常，将不知道如何处理的异常继续传递下去。传递异常可以在方法签名处使用 throws 关键字声明可能会抛出的异常。 注意 非检查异常（Error、RuntimeException 或它们的子类）不可使用 throws 关键字来声明要抛出的异常。 一个方法出现编译时异常，就需要 try-catch/ throws 处理，否则会导致编译错误。 抛出异常 如果你觉得解决不了某些异常问题，且不需要调用者处理，那么你可以抛出异常。 throw关键字作用是在方法内部抛出一个Throwable类型的异常。任何Java代码都可以通过throw语句抛出异常。 捕获异常 程序通常在运行之前不报错，但是运行后可能会出现某些未知的错误，但是还不想直接抛出到上一级，那么就需要通过try…catch…的形式进行异常捕获，之后根据不同的异常情况来进行相应的处理。 如何选择异常类型 可以根据下图来选择是捕获异常，声明异常还是抛出异常 常见异常处理方式直接抛出异常 通常，应该捕获那些知道如何处理的异常，将不知道如何处理的异常继续传递下去。传递异常可以在方法签名处使用 throws 关键字声明可能会抛出的异常。 12345678910private static void readFile(String filePath) throws IOException &#123; File file = new File(filePath); String result; BufferedReader reader = new BufferedReader(new FileReader(file)); while((result = reader.readLine())!=null) &#123; System.out.println(result); &#125; reader.close();&#125;复制代码 封装异常再抛出 有时我们会从 catch 中抛出一个异常，目的是为了改变异常的类型。多用于在多系统集成时，当某个子系统故障，异常类型可能有多种，可以用统一的异常类型向外暴露，不需暴露太多内部异常细节。 12345678910private static void readFile(String filePath) throws MyException &#123; try &#123; // code &#125; catch (IOException e) &#123; MyException ex = new MyException(&quot;read file failed.&quot;); ex.initCause(e); throw ex; &#125;&#125;复制代码 捕获异常 在一个 try-catch 语句块中可以捕获多个异常类型，并对不同类型的异常做出不同的处理 12345678910private static void readFile(String filePath) &#123; try &#123; // code &#125; catch (FileNotFoundException e) &#123; // handle FileNotFoundException &#125; catch (IOException e)&#123; // handle IOException &#125;&#125;复制代码 同一个 catch 也可以捕获多种类型异常，用 | 隔开 12345678910private static void readFile(String filePath) &#123; try &#123; // code &#125; catch (FileNotFoundException | UnknownHostException e) &#123; // handle FileNotFoundException or UnknownHostException &#125; catch (IOException e)&#123; // handle IOException &#125;&#125;复制代码 自定义异常 习惯上，定义一个异常类应包含两个构造函数，一个无参构造函数和一个带有详细描述信息的构造函数（Throwable 的 toString 方法会打印这些详细信息，调试时很有用） 12345678public class MyException extends Exception &#123; public MyException()&#123; &#125; public MyException(String msg)&#123; super(msg); &#125; // ...&#125;复制代码 try-catch-finally 当方法中发生异常，异常处之后的代码不会再执行，如果之前获取了一些本地资源需要释放，则需要在方法正常结束时和 catch 语句中都调用释放本地资源的代码，显得代码比较繁琐，finally 语句可以解决这个问题。 1234567891011121314151617181920212223242526private static void readFile(String filePath) throws MyException &#123; File file = new File(filePath); String result; BufferedReader reader = null; try &#123; reader = new BufferedReader(new FileReader(file)); while((result = reader.readLine())!=null) &#123; System.out.println(result); &#125; &#125; catch (IOException e) &#123; System.out.println(&quot;readFile method catch block.&quot;); MyException ex = new MyException(&quot;read file failed.&quot;); ex.initCause(e); throw ex; &#125; finally &#123; System.out.println(&quot;readFile method finally block.&quot;); if (null != reader) &#123; try &#123; reader.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;复制代码 调用该方法时，读取文件时若发生异常，代码会进入 catch 代码块，之后进入 finally 代码块；若读取文件时未发生异常，则会跳过 catch 代码块直接进入 finally 代码块。所以无论代码中是否发生异常，fianlly 中的代码都会执行。 若 catch 代码块中包含 return 语句，finally 中的代码还会执行吗？将以上代码中的 catch 子句修改如下： 12345catch (IOException e) &#123; System.out.println(&quot;readFile method catch block.&quot;); return;&#125;复制代码 调用 readFile 方法，观察当 catch 子句中调用 return 语句时，finally 子句是否执行 123readFile method catch block.readFile method finally block.复制代码 可见，即使 catch 中包含了 return 语句，finally 子句依然会执行。若 finally 中也包含 return 语句，finally 中的 return 会覆盖前面的 return. try-with-resource 上面例子中，finally 中的 close 方法也可能抛出 IOException, 从而覆盖了原始异常。JAVA 7 提供了更优雅的方式来实现资源的自动释放，自动释放的资源需要是实现了 AutoCloseable 接口的类。 12345678private static void tryWithResourceTest()&#123; try (Scanner scanner = new Scanner(new FileInputStream(&quot;c:/abc&quot;),&quot;UTF-8&quot;))&#123; // code &#125; catch (IOException e)&#123; // handle exception &#125;&#125;复制代码 try 代码块退出时，会自动调用 scanner.close 方法，和把 scanner.close 方法放在 finally 代码块中不同的是，若 scanner.close 抛出异常，则会被抑制，抛出的仍然为原始异常。被抑制的异常会由 addSusppressed 方法添加到原来的异常，如果想要获取被抑制的异常列表，可以调用 getSuppressed 方法来获取。 Java异常常见面试题1. Error 和 Exception 区别是什么？ Error 类型的错误通常为虚拟机相关错误，如系统崩溃，内存不足，堆栈溢出等，编译器不会对这类错误进行检测，JAVA 应用程序也不应对这类错误进行捕获，一旦这类错误发生，通常应用程序会被终止，仅靠应用程序本身无法恢复； Exception 类的错误是可以在应用程序中进行捕获并处理的，通常遇到这种错误，应对其进行处理，使应用程序可以继续正常运行。 2. 运行时异常和一般异常(受检异常)区别是什么？ 运行时异常包括 RuntimeException 类及其子类，表示 JVM 在运行期间可能出现的异常。 Java 编译器不会检查运行时异常。 受检异常是Exception 中除 RuntimeException 及其子类之外的异常。 Java 编译器会检查受检异常。 RuntimeException异常和受检异常之间的区别：是否强制要求调用者必须处理此异常，如果强制要求调用者必须进行处理，那么就使用受检异常，否则就选择非受检异常(RuntimeException)。一般来讲，如果没有特殊的要求，我们建议使用RuntimeException异常。 3. JVM 是如何处理异常的？ 在一个方法中如果发生异常，这个方法会创建一个异常对象，并转交给 JVM，该异常对象包含异常名称，异常描述以及异常发生时应用程序的状态。创建异常对象并转交给 JVM 的过程称为抛出异常。可能有一系列的方法调用，最终才进入抛出异常的方法，这一系列方法调用的有序列表叫做调用栈。 JVM 会顺着调用栈去查找看是否有可以处理异常的代码，如果有，则调用异常处理代码。当 JVM 发现可以处理异常的代码时，会把发生的异常传递给它。如果 JVM 没有找到可以处理该异常的代码块，JVM 就会将该异常转交给默认的异常处理器（默认处理器为 JVM 的一部分），默认异常处理器打印出异常信息并终止应用程序。 4. throw 和 throws 的区别是什么？ Java 中的异常处理除了包括捕获异常和处理异常之外，还包括声明异常和拋出异常，可以通过 throws 关键字在方法上声明该方法要拋出的异常，或者在方法内部通过 throw 拋出异常对象。 throws 关键字和 throw 关键字在使用上的几点区别如下： throw 关键字用在方法内部，只能用于抛出一种异常，用来抛出方法或代码块中的异常，受查异常和非受查异常都可以被抛出。 throws 关键字用在方法声明上，可以抛出多个异常，用来标识该方法可能抛出的异常列表。一个方法用 throws 标识了可能抛出的异常列表，调用该方法的方法中必须包含可处理异常的代码，否则也要在方法签名中用 throws 关键字声明相应的异常。 5. final、finally、finalize 有什么区别？ final可以修饰类、变量、方法，修饰类表示该类不能被继承、修饰方法表示该方法不能被重写、修饰变量表示该变量是一个常量不能被重新赋值。 finally一般作用在try-catch代码块中，在处理异常的时候，通常我们将一定要执行的代码方法finally代码块中，表示不管是否出现异常，该代码块都会执行，一般用来存放一些关闭资源的代码。 finalize是一个方法，属于Object类的一个方法，而Object类是所有类的父类，Java 中允许使用 finalize()方法在垃圾收集器将对象从内存中清除出去之前做必要的清理工作。 6. NoClassDefFoundError 和 ClassNotFoundException 区别？ NoClassDefFoundError 是一个 Error 类型的异常，是由 JVM 引起的，不应该尝试捕获这个异常。 引起该异常的原因是 JVM 或 ClassLoader 尝试加载某类时在内存中找不到该类的定义，该动作发生在运行期间，即编译时该类存在，但是在运行时却找不到了，可能是变异后被删除了等原因导致； ClassNotFoundException 是一个受查异常，需要显式地使用 try-catch 对其进行捕获和处理，或在方法签名中用 throws 关键字进行声明。当使用 Class.forName, ClassLoader.loadClass 或 ClassLoader.findSystemClass 动态加载类到内存的时候，通过传入的类路径参数没有找到该类，就会抛出该异常；另一种抛出该异常的可能原因是某个类已经由一个类加载器加载至内存中，另一个加载器又尝试去加载它。 7. try-catch-finally 中哪个部分可以省略？ 答：catch 可以省略 原因 更为严格的说法其实是：try只适合处理运行时异常，try+catch适合处理运行时异常+普通异常。也就是说，如果你只用try去处理普通异常却不加以catch处理，编译是通不过的，因为编译器硬性规定，普通异常如果选择捕获，则必须用catch显示声明以便进一步处理。而运行时异常在编译时没有如此规定，所以catch可以省略，你加上catch编译器也觉得无可厚非。 理论上，编译器看任何代码都不顺眼，都觉得可能有潜在的问题，所以你即使对所有代码加上try，代码在运行期时也只不过是在正常运行的基础上加一层皮。但是你一旦对一段代码加上try，就等于显示地承诺编译器，对这段代码可能抛出的异常进行捕获而非向上抛出处理。如果是普通异常，编译器要求必须用catch捕获以便进一步处理；如果运行时异常，捕获然后丢弃并且+finally扫尾处理，或者加上catch捕获以便进一步处理。 至于加上finally，则是在不管有没捕获异常，都要进行的“扫尾”处理。 8. try-catch-finally 中，如果 catch 中 return 了，finally 还会执行吗？ 答：会执行，在 return 前执行。 注意：在 finally 中改变返回值的做法是不好的，因为如果存在 finally 代码块，try中的 return 语句不会立马返回调用者，而是记录下返回值待 finally 代码块执行完毕之后再向调用者返回其值，然后如果在 finally 中修改了返回值，就会返回修改后的值。显然，在 finally 中返回或者修改返回值会对程序造成很大的困扰，C#中直接用编译错误的方式来阻止程序员干这种龌龊的事情，Java 中也可以通过提升编译器的语法检查级别来产生警告或错误。 代码示例1： 12345678910111213141516171819public static int getInt() &#123; int a = 10; try &#123; System.out.println(a / 0); a = 20; &#125; catch (ArithmeticException e) &#123; a = 30; return a; /* * return a 在程序执行到这一步的时候，这里不是return a 而是 return 30；这个返回路径就形成了 * 但是呢，它发现后面还有finally，所以继续执行finally的内容，a=40 * 再次回到以前的路径,继续走return 30，形成返回路径之后，这里的a就不是a变量了，而是常量30 */ &#125; finally &#123; a = 40; &#125; return a;&#125;复制代码 执行结果：30 代码示例2： 12345678910111213141516public static int getInt() &#123; int a = 10; try &#123; System.out.println(a / 0); a = 20; &#125; catch (ArithmeticException e) &#123; a = 30; return a; &#125; finally &#123; a = 40; //如果这样，就又重新形成了一条返回路径，由于只能通过1个return返回，所以这里直接返回40 return a; &#125;&#125;复制代码 执行结果：40 9. 类 ExampleA 继承 Exception，类 ExampleB 继承ExampleA。 有如下代码片断： 12345678try &#123; throw new ExampleB(&quot;b&quot;)&#125; catch（ExampleA e）&#123; System.out.println(&quot;ExampleA&quot;);&#125; catch（Exception e）&#123; System.out.println(&quot;Exception&quot;);&#125;复制代码 请问执行此段代码的输出是什么？ 答：输出：ExampleA。（根据里氏代换原则[能使用父类型的地方一定能使用子类型]，抓取 ExampleA 类型异常的 catch 块能够抓住 try 块中抛出的 ExampleB 类型的异常） 面试题 - 说出下面代码的运行结果。（此题的出处是《Java 编程思想》一书） 1234567891011121314151617181920212223class Annoyance extends Exception &#123;&#125;class Sneeze extends Annoyance &#123;&#125;class Human &#123; public static void main(String[] args) throws Exception &#123; try &#123; try &#123; throw new Sneeze(); &#125; catch ( Annoyance a ) &#123; System.out.println(&quot;Caught Annoyance&quot;); throw a; &#125; &#125; catch ( Sneeze s ) &#123; System.out.println(&quot;Caught Sneeze&quot;); return ; &#125; finally &#123; System.out.println(&quot;Hello World!&quot;); &#125; &#125;&#125;复制代码 结果 1234Caught AnnoyanceCaught SneezeHello World!复制代码 10. 常见的 RuntimeException 有哪些？ ClassCastException(类转换异常) IndexOutOfBoundsException(数组越界) NullPointerException(空指针) ArrayStoreException(数据存储异常，操作数组时类型不一致) 还有IO操作的BufferOverflowException异常 11. Java常见异常有哪些 java.lang.IllegalAccessError：违法访问错误。当一个应用试图访问、修改某个类的域（Field）或者调用其方法，但是又违反域或方法的可见性声明，则抛出该异常。 java.lang.InstantiationError：实例化错误。当一个应用试图通过Java的new操作符构造一个抽象类或者接口时抛出该异常. java.lang.OutOfMemoryError：内存不足错误。当可用内存不足以让Java虚拟机分配给一个对象时抛出该错误。 java.lang.StackOverflowError：堆栈溢出错误。当一个应用递归调用的层次太深而导致堆栈溢出或者陷入死循环时抛出该错误。 java.lang.ClassCastException：类造型异常。假设有类A和B（A不是B的父类或子类），O是A的实例，那么当强制将O构造为类B的实例时抛出该异常。该异常经常被称为强制类型转换异常。 java.lang.ClassNotFoundException：找不到类异常。当应用试图根据字符串形式的类名构造类，而在遍历CLASSPAH之后找不到对应名称的class文件时，抛出该异常。 java.lang.ArithmeticException：算术条件异常。譬如：整数除零等。 java.lang.ArrayIndexOutOfBoundsException：数组索引越界异常。当对数组的索引值为负数或大于等于数组大小时抛出。 java.lang.IndexOutOfBoundsException：索引越界异常。当访问某个序列的索引值小于0或大于等于序列大小时，抛出该异常。 java.lang.InstantiationException：实例化异常。当试图通过newInstance()方法创建某个类的实例，而该类是一个抽象类或接口时，抛出该异常。 java.lang.NoSuchFieldException：属性不存在异常。当访问某个类的不存在的属性时抛出该异常。 java.lang.NoSuchMethodException：方法不存在异常。当访问某个类的不存在的方法时抛出该异常。- java.lang.NullPointerException：空指针异常。当应用试图在要求使用对象的地方使用了null时，抛出该异常。譬如：调用null对象的实例方法、访问null对象的属性、计算null对象的长度、使用throw语句抛出null等等。 java.lang.NumberFormatException：数字格式异常。当试图将一个String转换为指定的数字类型，而该字符串确不满足数字类型要求的格式时，抛出该异常。 java.lang.StringIndexOutOfBoundsException：字符串索引越界异常。当使用索引值访问某个字符串中的字符，而该索引值小于0或大于等于序列大小时，抛出该异常。 Java异常处理最佳实践 在 Java 中处理异常并不是一个简单的事情。不仅仅初学者很难理解，即使一些有经验的开发者也需要花费很多时间来思考如何处理异常，包括需要处理哪些异常，怎样处理等等。这也是绝大多数开发团队都会制定一些规则来规范进行异常处理的原因。而团队之间的这些规范往往是截然不同的。 本文给出几个被很多团队使用的异常处理最佳实践。 1. 在 finally 块中清理资源或者使用 try-with-resource 语句 当使用类似InputStream这种需要使用后关闭的资源时，一个常见的错误就是在try块的最后关闭资源。 123456789101112131415public void doNotCloseResourceInTry() &#123; FileInputStream inputStream = null; try &#123; File file = new File(&quot;./tmp.txt&quot;); inputStream = new FileInputStream(file); // use the inputStream to read a file // do NOT do this inputStream.close(); &#125; catch (FileNotFoundException e) &#123; log.error(e); &#125; catch (IOException e) &#123; log.error(e); &#125;&#125;复制代码 问题就是，只有没有异常抛出的时候，这段代码才可以正常工作。try 代码块内代码会正常执行，并且资源可以正常关闭。但是，使用 try 代码块是有原因的，一般调用一个或多个可能抛出异常的方法，而且，你自己也可能会抛出一个异常，这意味着代码可能不会执行到 try 代码块的最后部分。结果就是，你并没有关闭资源。 所以，你应该把清理工作的代码放到 finally 里去，或者使用 try-with-resource 特性。 1.1 使用 finally 代码块 与前面几行 try 代码块不同，finally 代码块总是会被执行。不管 try 代码块成功执行之后还是你在 catch 代码块中处理完异常后都会执行。因此，你可以确保你清理了所有打开的资源。 12345678910111213141516171819public void closeResourceInFinally() &#123; FileInputStream inputStream = null; try &#123; File file = new File(&quot;./tmp.txt&quot;); inputStream = new FileInputStream(file); // use the inputStream to read a file &#125; catch (FileNotFoundException e) &#123; log.error(e); &#125; finally &#123; if (inputStream != null) &#123; try &#123; inputStream.close(); &#125; catch (IOException e) &#123; log.error(e); &#125; &#125; &#125;&#125;复制代码 1.2 Java 7 的 try-with-resource 语法 如果你的资源实现了 AutoCloseable 接口，你可以使用这个语法。大多数的 Java 标准资源都继承了这个接口。当你在 try 子句中打开资源，资源会在 try 代码块执行后或异常处理后自动关闭。 123456789101112public void automaticallyCloseResource() &#123; File file = new File(&quot;./tmp.txt&quot;); try (FileInputStream inputStream = new FileInputStream(file);) &#123; // use the inputStream to read a file &#125; catch (FileNotFoundException e) &#123; log.error(e); &#125; catch (IOException e) &#123; log.error(e); &#125;&#125;复制代码 2. 优先明确的异常 你抛出的异常越明确越好，永远记住，你的同事或者几个月之后的你，将会调用你的方法并且处理异常。 因此需要保证提供给他们尽可能多的信息。这样你的 API 更容易被理解。你的方法的调用者能够更好的处理异常并且避免额外的检查。 因此，总是尝试寻找最适合你的异常事件的类，例如，抛出一个 NumberFormatException 来替换一个 IllegalArgumentException 。避免抛出一个不明确的异常。 12345678public void doNotDoThis() throws Exception &#123; ...&#125;public void doThis() throws NumberFormatException &#123; ...&#125;复制代码 3. 对异常进行文档说明 当在方法上声明抛出异常时，也需要进行文档说明。目的是为了给调用者提供尽可能多的信息，从而可以更好地避免或处理异常。 在 Javadoc 添加 @throws 声明，并且描述抛出异常的场景。 12345public void doSomething(String input) throws MyBusinessException &#123; ...&#125;复制代码 4. 使用描述性消息抛出异常 在抛出异常时，需要尽可能精确地描述问题和相关信息，这样无论是打印到日志中还是在监控工具中，都能够更容易被人阅读，从而可以更好地定位具体错误信息、错误的严重程度等。 但这里并不是说要对错误信息长篇大论，因为本来 Exception 的类名就能够反映错误的原因，因此只需要用一到两句话描述即可。 如果抛出一个特定的异常，它的类名很可能已经描述了这种错误。所以，你不需要提供很多额外的信息。一个很好的例子是 NumberFormatException 。当你以错误的格式提供 String 时，它将被 java.lang.Long 类的构造函数抛出。 1234567try &#123; new Long(&quot;xyz&quot;);&#125; catch (NumberFormatException e) &#123; log.error(e);&#125;复制代码 5. 优先捕获最具体的异常 大多数 IDE 都可以帮助你实现这个最佳实践。当你尝试首先捕获较不具体的异常时，它们会报告无法访问的代码块。 但问题在于，只有匹配异常的第一个 catch 块会被执行。 因此，如果首先捕获 IllegalArgumentException ，则永远不会到达应该处理更具体的 NumberFormatException 的 catch 块，因为它是 IllegalArgumentException 的子类。 总是优先捕获最具体的异常类，并将不太具体的 catch 块添加到列表的末尾。 你可以在下面的代码片断中看到这样一个 try-catch 语句的例子。 第一个 catch 块处理所有 NumberFormatException 异常，第二个处理所有非 NumberFormatException 异常的IllegalArgumentException 异常。 1234567891011public void catchMostSpecificExceptionFirst() &#123; try &#123; doSomething(&quot;A message&quot;); &#125; catch (NumberFormatException e) &#123; log.error(e); &#125; catch (IllegalArgumentException e) &#123; log.error(e) &#125;&#125;复制代码 6. 不要捕获 Throwable 类 Throwable 是所有异常和错误的超类。你可以在 catch 子句中使用它，但是你永远不应该这样做！ 如果在 catch 子句中使用 Throwable ，它不仅会捕获所有异常，也将捕获所有的错误。JVM 抛出错误，指出不应该由应用程序处理的严重问题。 典型的例子是 OutOfMemoryError 或者 StackOverflowError 。两者都是由应用程序控制之外的情况引起的，无法处理。 所以，最好不要捕获 Throwable ，除非你确定自己处于一种特殊的情况下能够处理错误。 123456789public void doNotCatchThrowable() &#123; try &#123; // do something &#125; catch (Throwable t) &#123; // don&apos;t do this! &#125;&#125;复制代码 7. 不要忽略异常 很多时候，开发者很有自信不会抛出异常，因此写了一个catch块，但是没有做任何处理或者记录日志。 123456789public void doNotIgnoreExceptions() &#123; try &#123; // do something &#125; catch (NumberFormatException e) &#123; // this will never happen &#125;&#125;复制代码 但现实是经常会出现无法预料的异常，或者无法确定这里的代码未来是不是会改动(删除了阻止异常抛出的代码)，而此时由于异常被捕获，使得无法拿到足够的错误信息来定位问题。 合理的做法是至少要记录异常的信息。 123456789public void logAnException() &#123; try &#123; // do something &#125; catch (NumberFormatException e) &#123; log.error(&quot;This should never happen: &quot; + e); &#125;&#125;复制代码 8. 不要记录并抛出异常 这可能是本文中最常被忽略的最佳实践。可以发现很多代码甚至类库中都会有捕获异常、记录日志并再次抛出的逻辑。如下： 12345678try &#123; new Long(&quot;xyz&quot;);&#125; catch (NumberFormatException e) &#123; log.error(e); throw e;&#125;复制代码 这个处理逻辑看着是合理的。但这经常会给同一个异常输出多条日志。如下： 12345678917:44:28,945 ERROR TestExceptionHandling:65 - java.lang.NumberFormatException: For input string: &quot;xyz&quot;Exception in thread &quot;main&quot; java.lang.NumberFormatException: For input string: &quot;xyz&quot;at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)at java.lang.Long.parseLong(Long.java:589)at java.lang.Long.(Long.java:965)at com.stackify.example.TestExceptionHandling.logAndThrowException(TestExceptionHandling.java:63)at com.stackify.example.TestExceptionHandling.main(TestExceptionHandling.java:58)复制代码 如上所示，后面的日志也没有附加更有用的信息。如果想要提供更加有用的信息，那么可以将异常包装为自定义异常。 123456789public void wrapException(String input) throws MyBusinessException &#123; try &#123; // do something &#125; catch (NumberFormatException e) &#123; throw new MyBusinessException(&quot;A message that describes the error.&quot;, e); &#125;&#125;复制代码 因此，仅仅当想要处理异常时才去捕获，否则只需要在方法签名中声明让调用者去处理。 9. 包装异常时不要抛弃原始的异常 捕获标准异常并包装为自定义异常是一个很常见的做法。这样可以添加更为具体的异常信息并能够做针对的异常处理。 在你这样做时，请确保将原始异常设置为原因（注：参考下方代码 NumberFormatException e 中的原始异常 e ）。Exception 类提供了特殊的构造函数方法，它接受一个 Throwable 作为参数。否则，你将会丢失堆栈跟踪和原始异常的消息，这将会使分析导致异常的异常事件变得困难。 123456789public void wrapException(String input) throws MyBusinessException &#123; try &#123; // do something &#125; catch (NumberFormatException e) &#123; throw new MyBusinessException(&quot;A message that describes the error.&quot;, e); &#125;&#125;复制代码 10. 不要使用异常控制程序的流程 不应该使用异常控制应用的执行流程，例如，本应该使用if语句进行条件判断的情况下，你却使用异常处理，这是非常不好的习惯，会严重影响应用的性能。 11. 使用标准异常 如果使用内建的异常可以解决问题，就不要定义自己的异常。Java API 提供了上百种针对不同情况的异常类型，在开发中首先尽可能使用 Java API 提供的异常，如果标准的异常不能满足你的要求，这时候创建自己的定制异常。尽可能得使用标准异常有利于新加入的开发者看懂项目代码。 12. 异常会影响性能 异常处理的性能成本非常高，每个 Java 程序员在开发时都应牢记这句话。创建一个异常非常慢，抛出一个异常又会消耗1~5ms，当一个异常在应用的多个层级之间传递时，会拖累整个应用的性能。 仅在异常情况下使用异常； 在可恢复的异常情况下使用异常； 尽管使用异常有利于 Java 开发，但是在应用中最好不要捕获太多的调用栈，因为在很多情况下都不需要打印调用栈就知道哪里出错了。因此，异常消息应该提供恰到好处的信息。 13. 总结 综上所述，当你抛出或捕获异常的时候，有很多不同的情况需要考虑，而且大部分事情都是为了改善代码的可读性或者 API 的可用性。 异常不仅仅是一个错误控制机制，也是一个通信媒介。因此，为了和同事更好的合作，一个团队必须要制定出一个最佳实践和规则，只有这样，团队成员才能理解这些通用概念，同时在工作中使用它。 异常处理-阿里巴巴Java开发手册 【强制】Java 类库中定义的可以通过预检查方式规避的RuntimeException异常不应该通过catch 的方式来处理，比如：NullPointerException，IndexOutOfBoundsException等等。 说明：无法通过预检查的异常除外，比如，在解析字符串形式的数字时，可能存在数字格式错误，不得不通过catch NumberFormatException来实现。 正例：if (obj != null) {…} 反例：try { obj.method(); } catch (NullPointerException e) {…} 【强制】异常不要用来做流程控制，条件控制。 说明：异常设计的初衷是解决程序运行中的各种意外情况，且异常的处理效率比条件判断方式要低很多。 【强制】catch时请分清稳定代码和非稳定代码，稳定代码指的是无论如何不会出错的代码。对于非稳定代码的catch尽可能进行区分异常类型，再做对应的异常处理。 说明：对大段代码进行try-catch，使程序无法根据不同的异常做出正确的应激反应，也不利于定位问题，这是一种不负责任的表现。 正例：用户注册的场景中，如果用户输入非法字符，或用户名称已存在，或用户输入密码过于简单，在程序上作出分门别类的判断，并提示给用户。 【强制】捕获异常是为了处理它，不要捕获了却什么都不处理而抛弃之，如果不想处理它，请将该异常抛给它的调用者。最外层的业务使用者，必须处理异常，将其转化为用户可以理解的内容。 【强制】有try块放到了事务代码中，catch异常后，如果需要回滚事务，一定要注意手动回滚事务。 【强制】finally块必须对资源对象、流对象进行关闭，有异常也要做try-catch。 说明：如果JDK7及以上，可以使用try-with-resources方式。 【强制】不要在finally块中使用return。 说明：try块中的return语句执行成功后，并不马上返回，而是继续执行finally块中的语句，如果此处存在return语句，则在此直接返回，无情丢弃掉try块中的返回点。 反例： 123456789101112 private int x = 0; public int checkReturn() &#123; try &#123; // x等于1，此处不返回 return ++x; &#125; finally &#123; // 返回的结果是2 return ++x; &#125; &#125;复制代码 【强制】捕获异常与抛异常，必须是完全匹配，或者捕获异常是抛异常的父类。 说明：如果预期对方抛的是绣球，实际接到的是铅球，就会产生意外情况。 【强制】在调用RPC、二方包、或动态生成类的相关方法时，捕捉异常必须使用Throwable类来进行拦截。 说明：通过反射机制来调用方法，如果找不到方法，抛出NoSuchMethodException。什么情况会抛出NoSuchMethodError呢？二方包在类冲突时，仲裁机制可能导致引入非预期的版本使类的方法签名不匹配，或者在字节码修改框架（比如：ASM）动态创建或修改类时，修改了相应的方法签名。这些情况，即使代码编译期是正确的，但在代码运行期时，会抛出NoSuchMethodError。 【推荐】方法的返回值可以为null，不强制返回空集合，或者空对象等，必须添加注释充分说明什么情况下会返回null值。 说明：本手册明确防止NPE是调用者的责任。即使被调用方法返回空集合或者空对象，对调用者来说，也并非高枕无忧，必须考虑到远程调用失败、序列化失败、运行时异常等场景返回null的情况。 【推荐】防止NPE，是程序员的基本修养，注意NPE产生的场景： 1） 返回类型为基本数据类型，return包装数据类型的对象时，自动拆箱有可能产生NPE。 反例：public int f() { return Integer对象}， 如果为null，自动解箱抛NPE。 2） 数据库的查询结果可能为null。 3） 集合里的元素即使isNotEmpty，取出的数据元素也可能为null。 4） 远程调用返回对象时，一律要求进行空指针判断，防止NPE。 5） 对于Session中获取的数据，建议进行NPE检查，避免空指针。 6） 级联调用obj.getA().getB().getC()；一连串调用，易产生NPE。 正例：使用JDK8的Optional类来防止NPE问题。 【推荐】定义时区分unchecked / checked 异常，避免直接抛出new RuntimeException()，更不允许抛出Exception或者Throwable，应使用有业务含义的自定义异常。推荐业界已定义过的自定义异常，如：DAOException / ServiceException等。 【参考】对于公司外的http/api开放接口必须使用“错误码”；而应用内部推荐异常抛出；跨应用间RPC调用优先考虑使用Result方式，封装isSuccess()方法、“错误码”、“错误简短信息”。 说明：关于RPC方法返回方式使用Result方式的理由： 1）使用抛异常返回方式，调用方如果没有捕获到就会产生运行时错误。 2）如果不加栈信息，只是new自定义异常，加入自己的理解的error message，对于调用端解决问题的帮助不会太多。如果加了栈信息，在频繁调用出错的情况下，数据序列化和传输的性能损耗也是问题。 【参考】避免出现重复的代码（Don’t Repeat Yourself），即DRY原则。 说明：随意复制和粘贴代码，必然会导致代码的重复，在以后需要修改时，需要修改所有的副本，容易遗漏。必要时抽取共性方法，或者抽象公共类，甚至是组件化。 正例：一个类中有多个public方法，都需要进行数行相同的参数校验操作，这个时候请抽取： private boolean checkParam(DTO dto) {…} 作者：小杰要吃蛋链接：https://juejin.cn/post/6844904128959741965来源：掘金著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。","tags":[{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"},{"name":"基础","slug":"基础","permalink":"https://lywlefan.github.io/tags/基础/"}]},{"title":"Java并发编程","date":"2020-07-17T16:00:00.000Z","path":"2020/07/18/软件研发/后端/基础巩固/java/并发/Java并发编程/","text":"基础知识为什么要使用并发编程 提升多核CPU的利用率：一般来说一台主机上的会有多个CPU核心，我们可以创建多个线程，理论上讲操作系统可以将多个线程分配给不同的CPU去执行，每个CPU执行一个线程，这样就提高了CPU的使用效率，如果使用单线程就只能有一个CPU核心被使用。 比如当我们在网上购物时，为了提升响应速度，需要拆分，减库存，生成订单等等这些操作，就可以进行拆分利用多线程的技术完成。面对复杂业务模型，并行程序会比串行程序更适应业务需求，而并发编程更能吻合这种业务拆分 。 简单来说就是： 充分利用多核CPU的计算能力； 方便进行业务拆分，提升应用性能 多线程应用场景 例如: 迅雷多线程下载、数据库连接池、分批发送短信等。 并发编程有什么缺点 并发编程的目的就是为了能提高程序的执行效率，提高程序运行速度，但是并发编程并不总是能提高程序运行速度的，而且并发编程可能会遇到很多问题，比如：内存泄漏、上下文切换、线程安全、死锁等问题。 并发编程三个必要因素是什么？ 原子性：原子，即一个不可再被分割的颗粒。原子性指的是一个或多个操作要么全部执行成功要么全部执行失败。 可见性：一个线程对共享变量的修改,另一个线程能够立刻看到。（synchronized,volatile） 有序性：程序执行的顺序按照代码的先后顺序执行。（处理器可能会对指令进行重排序） 在 Java 程序中怎么保证多线程的运行安全？ 出现线程安全问题的原因一般都是三个原因： 线程切换带来的原子性问题 解决办法：使用多线程之间同步synchronized或使用锁(lock)。 缓存导致的可见性问题 解决办法：synchronized、volatile、LOCK，可以解决可见性问题 编译优化带来的有序性问题 解决办法：Happens-Before 规则可以解决有序性问题 并行和并发有什么区别？ 并发：多个任务在同一个 CPU 核上，按细分的时间片轮流(交替)执行，从逻辑上来看那些任务是同时执行。 并行：单位时间内，多个处理器或多核处理器同时处理多个任务，是真正意义上的“同时进行”。 串行：有n个任务，由一个线程按顺序执行。由于任务、方法都在一个线程执行所以不存在线程不安全情况，也就不存在临界区的问题。 做一个形象的比喻： 并发 = 俩个人用一台电脑。 并行 = 俩个人分配了俩台电脑。 串行 = 俩个人排队使用一台电脑。 什么是多线程 多线程：多线程是指程序中包含多个执行流，即在一个程序中可以同时运行多个不同的线程来执行不同的任务。 多线程的好处 可以提高 CPU 的利用率。在多线程程序中，一个线程必须等待的时候，CPU 可以运行其它的线程而不是等待，这样就大大提高了程序的效率。也就是说允许单个程序创建多个并行执行的线程来完成各自的任务。 多线程的劣势： 线程也是程序，所以线程需要占用内存，线程越多占用内存也越多； 多线程需要协调和管理，所以需要 CPU 时间跟踪线程； 线程之间对共享资源的访问会相互影响，必须解决竞用共享资源的问题。 线程和进程区别 什么是线程和进程? 进程 一个在内存中运行的应用程序。 每个正在系统上运行的程序都是一个进程 线程 进程中的一个执行任务（控制单元）， 它负责在程序里独立执行。 1一个进程至少有一个线程，一个进程可以运行多个线程，多个线程可共享数据。 进程与线程的区别 根本区别：进程是操作系统资源分配的基本单位，而线程是处理器任务调度和执行的基本单位 资源开销：每个进程都有独立的代码和数据空间（程序上下文），程序之间的切换会有较大的开销；线程可以看做轻量级的进程，同一类线程共享代码和数据空间，每个线程都有自己独立的运行栈和程序计数器（PC），线程之间切换的开销小。 包含关系：如果一个进程内有多个线程，则执行过程不是一条线的，而是多条线（线程）共同完成的；线程是进程的一部分，所以线程也被称为轻权进程或者轻量级进程。 内存分配：同一进程的线程共享本进程的地址空间和资源，而进程与进程之间的地址空间和资源是相互独立的 影响关系：一个进程崩溃后，在保护模式下不会对其他进程产生影响，但是一个线程崩溃有可能导致整个进程都死掉。所以多进程要比多线程健壮。 执行过程：每个独立的进程有程序运行的入口、顺序执行序列和程序出口。但是线程不能独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制，两者均可并发执行 什么是上下文切换? 多线程编程中一般线程的个数都大于 CPU 核心的个数，而一个 CPU 核心在任意时刻只能被一个线程使用，为了让这些线程都能得到有效执行，CPU 采取的策略是为每个线程分配时间片并轮转的形式。当一个线程的时间片用完的时候就会重新处于就绪状态让给其他线程使用，这个过程就属于一次上下文切换。 概括来说就是：当前任务在执行完 CPU 时间片切换到另一个任务之前会先保存自己的状态，以便下次再切换回这个任务时，可以再加载这个任务的状态。任务从保存到再加载的过程就是一次上下文切换。 上下文切换通常是计算密集型的。也就是说，它需要相当可观的处理器时间，在每秒几十上百次的切换中，每次切换都需要纳秒量级的时间。所以，上下文切换对系统来说意味着消耗大量的 CPU 时间，事实上，可能是操作系统中时间消耗最大的操作。 Linux 相比与其他操作系统（包括其他类 Unix 系统）有很多的优点，其中有一项就是，其上下文切换和模式切换的时间消耗非常少。 守护线程和用户线程有什么区别呢？ 用户 (User) 线程：运行在前台，执行具体的任务，如程序的主线程、连接网络的子线程等都是用户线程 守护 (Daemon) 线程：运行在后台，为其他前台线程服务。也可以说守护线程是 JVM 中非守护线程的 “佣人”。一旦所有用户线程都结束运行，守护线程会随 JVM 一起结束工作 如何在 Windows 和 Linux 上查找哪个线程cpu利用率最高？ windows上面用任务管理器看，linux下可以用 top 这个工具看。 找出cpu耗用厉害的进程pid， 终端执行top命令，然后按下shift+p (shift+m是找出消耗内存最高)查找出cpu利用最厉害的pid号 根据上面第一步拿到的pid号，top -H -p pid 。然后按下shift+p，查找出cpu利用率最厉害的线程号，比如top -H -p 1328 将获取到的线程号转换成16进制，去百度转换一下就行 使用jstack工具将进程信息打印输出，jstack pid号 &gt; /tmp/t.dat，比如jstack 31365 &gt; /tmp/t.dat 编辑/tmp/t.dat文件，查找线程号对应的信息 1或者直接使用JDK自带的工具查看“jconsole” 、“visualVm”，这都是JDK自带的，可以直接在JDK的bin目录下找到直接使用 什么是线程死锁 死锁是指两个或两个以上的进程（线程）在执行过程中，由于竞争资源或者由于彼此通信而造成的一种阻塞的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程（线程）称为死锁进程（线程）。 多个线程同时被阻塞，它们中的一个或者全部都在等待某个资源被释放。由于线程被无限期地阻塞，因此程序不可能正常终止。 如下图所示，线程 A 持有资源 2，线程 B 持有资源 1，他们同时都想申请对方的资源，所以这两个线程就会互相等待而进入死锁状态。 形成死锁的四个必要条件是什么 互斥条件：在一段时间内某资源只由一个进程占用。如果此时还有其它进程请求资源，就只能等待，直至占有资源的进程用毕释放。 占有且等待条件：指进程已经保持至少一个资源，但又提出了新的资源请求，而该资源已被其它进程占有，此时请求进程阻塞，但又对自己已获得的其它资源保持不放。 不可抢占条件：别人已经占有了某项资源，你不能因为自己也需要该资源，就去把别人的资源抢过来。 循环等待条件：若干进程之间形成一种头尾相接的循环等待资源关系。（比如一个进程集合，A在等B，B在等C，C在等A） 如何避免线程死锁 避免一个线程同时获得多个锁 避免一个线程在锁内同时占用多个资源，尽量保证每个锁只占用一个资源 尝试使用定时锁，使用lock.tryLock(timeout)来替代使用内部锁机制 创建线程的四种方式 继承 Thread 类； 123456public class MyThread extends Thread &#123;@Overridepublic void run() &#123; System.out.println(Thread.currentThread().getName() + &quot; run()方法正在执行...&quot;);&#125;复制代码 实现 Runnable 接口； 123456public class MyRunnable implements Runnable &#123;@Overridepublic void run() &#123; System.out.println(Thread.currentThread().getName() + &quot; run()方法执行中...&quot;);&#125;复制代码 实现 Callable 接口； 1234567public class MyCallable implements Callable&lt;Integer&gt; &#123;@Overridepublic Integer call() &#123; System.out.println(Thread.currentThread().getName() + &quot; call()方法执行中...&quot;); return 1;&#125;复制代码 使用匿名内部类方式 1234567891011121314public class CreateRunnable &#123; public static void main(String[] args) &#123; //创建多线程创建开始 Thread thread = new Thread(new Runnable() &#123; public void run() &#123; for (int i = 0; i &lt; 10; i++) &#123; System.out.println(&quot;i:&quot; + i); &#125; &#125; &#125;); thread.start(); &#125;&#125;复制代码 说一下 runnable 和 callable 有什么区别相同点： 都是接口 都可以编写多线程程序 都采用Thread.start()启动线程 主要区别： Runnable 接口 run 方法无返回值；Callable 接口 call 方法有返回值，是个泛型，和Future、FutureTask配合可以用来获取异步执行的结果 Runnable 接口 run 方法只能抛出运行时异常，且无法捕获处理；Callable 接口 call 方法允许抛出异常，可以获取异常信息 注：Callalbe接口支持返回执行结果，需要调用FutureTask.get()得到，此方法会阻塞主进程的继续往下执行，如果不调用不会阻塞。 线程的 run()和 start()有什么区别？ 每个线程都是通过某个特定Thread对象所对应的方法run()来完成其操作的，run()方法称为线程体。通过调用Thread类的start()方法来启动一个线程。 start() 方法用于启动线程，run() 方法用于执行线程的运行时代码。run() 可以重复调用，而 start() 只能调用一次。 start()方法来启动一个线程，真正实现了多线程运行。调用start()方法无需等待run方法体代码执行完毕，可以直接继续执行其他的代码； 此时线程是处于就绪状态，并没有运行。 然后通过此Thread类调用方法run()来完成其运行状态， run()方法运行结束， 此线程终止。然后CPU再调度其它线程。 run()方法是在本线程里的，只是线程里的一个函数，而不是多线程的。 如果直接调用run()，其实就相当于是调用了一个普通函数而已，直接待用run()方法必须等待run()方法执行完毕才能执行下面的代码，所以执行路径还是只有一条，根本就没有线程的特征，所以在多线程执行时要使用start()方法而不是run()方法。 为什么我们调用 start() 方法时会执行 run() 方法，为什么我们不能直接调用 run() 方法？这是另一个非常经典的 java 多线程面试问题，而且在面试中会经常被问到。很简单，但是很多人都会答不上来！ new 一个 Thread，线程进入了新建状态。调用 start() 方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。 start() 会执行线程的相应准备工作，然后自动执行 run() 方法的内容，这是真正的多线程工作。 而直接执行 run() 方法，会把 run 方法当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。 总结： 调用 start 方法方可启动线程并使线程进入就绪状态，而 run 方法只是 thread 的一个普通方法调用，还是在主线程里执行。 什么是 Callable 和 Future? Callable 接口类似于 Runnable，从名字就可以看出来了，但是 Runnable 不会返回结果，并且无法抛出返回结果的异常，而 Callable 功能更强大一些，被线程执行后，可以返回值，这个返回值可以被 Future 拿到，也就是说，Future 可以拿到异步执行任务的返回值。 Future 接口表示异步任务，是一个可能还没有完成的异步任务的结果。所以说 Callable用于产生结果，Future 用于获取结果。 什么是 FutureTask FutureTask 表示一个异步运算的任务。FutureTask 里面可以传入一个 Callable 的具体实现类，可以对这个异步运算的任务的结果进行等待获取、判断是否已经完成、取消任务等操作。只有当运算完成的时候结果才能取回，如果运算尚未完成 get 方法将会阻塞。一个 FutureTask 对象可以对调用了 Callable 和 Runnable 的对象进行包装，由于 FutureTask 也是Runnable 接口的实现类，所以 FutureTask 也可以放入线程池中。 线程的状态 新建(new)：新创建了一个线程对象。 就绪（可运行状态）(runnable)：线程对象创建后，当调用线程对象的 start()方法，该线程处于就绪状态，等待被线程调度选中，获取cpu的使用权。 运行(running)：可运行状态(runnable)的线程获得了cpu时间片（timeslice），执行程序代码。注：就绪状态是进入到运行状态的唯一入口，也就是说，线程要想进入运行状态执行，首先必须处于就绪状态中； 阻塞(block)：处于运行状态中的线程由于某种原因，暂时放弃对 CPU的使用权，停止执行，此时进入阻塞状态，直到其进入到就绪状态，才 有机会再次被 CPU 调用以进入到运行状态。 阻塞的情况分三种： (一). 等待阻塞：运行状态中的线程执行 wait()方法，JVM会把该线程放入等待队列(waitting queue)中，使本线程进入到等待阻塞状态； (二). 同步阻塞：线程在获取 synchronized 同步锁失败(因为锁被其它线程所占用)，，则JVM会把该线程放入锁池(lock pool)中，线程会进入同步阻塞状态； (三). 其他阻塞: 通过调用线程的 sleep()或 join()或发出了 I/O 请求时，线程会进入到阻塞状态。当 sleep()状态超时、join()等待线程终止或者超时、或者 I/O 处理完毕时，线程重新转入就绪状态。 死亡(dead)(结束)：线程run()、main()方法执行结束，或者因异常退出了run()方法，则该线程结束生命周期。死亡的线程不可再次复生。 Java 中用到的线程调度算法是什么？ 计算机通常只有一个 CPU，在任意时刻只能执行一条机器指令，每个线程只有获得CPU 的使用权才能执行指令。所谓多线程的并发运行，其实是指从宏观上看，各个线程轮流获得 CPU 的使用权，分别执行各自的任务。在运行池中，会有多个处于就绪状态的线程在等待 CPU，JAVA 虚拟机的一项任务就是负责线程的调度，线程调度是指按照特定机制为多个线程分配 CPU 的使用权。（Java是由JVM中的线程计数器来实现线程调度） 有两种调度模型：分时调度模型和抢占式调度模型。 分时调度模型是指让所有的线程轮流获得 cpu 的使用权，并且平均分配每个线程占用的 CPU 的时间片这个也比较好理解。 Java虚拟机采用抢占式调度模型，是指优先让可运行池中优先级高的线程占用CPU，如果可运行池中的线程优先级相同，那么就随机选择一个线程，使其占用CPU。处于运行状态的线程会一直运行，直至它不得不放弃 CPU。 线程的调度策略1线程调度器选择优先级最高的线程运行，但是，如果发生以下情况，就会终止线程的运行： （1）线程体中调用了 yield 方法让出了对 cpu 的占用权利 （2）线程体中调用了 sleep 方法使线程进入睡眠状态 （3）线程由于 IO 操作受到阻塞 （4）另外一个更高优先级线程出现 （5）在支持时间片的系统中，该线程的时间片用完 什么是线程调度器(Thread Scheduler)和时间分片(Time Slicing )？ 线程调度器是一个操作系统服务，它负责为 Runnable 状态的线程分配 CPU 时间。一旦我们创建一个线程并启动它，它的执行便依赖于线程调度器的实现。 时间分片是指将可用的 CPU 时间分配给可用的 Runnable 线程的过程。分配 CPU 时间可以基于线程优先级或者线程等待的时间。 线程调度并不受到 Java 虚拟机控制，所以由应用程序来控制它是更好的选择（也就是说不要让你的程序依赖于线程的优先级）。 请说出与线程同步以及线程调度相关的方法。 （1） wait()：使一个线程处于等待（阻塞）状态，并且释放所持有的对象的锁； （2）sleep()：使一个正在运行的线程处于睡眠状态，是一个静态方法，调用此方法要处理 InterruptedException 异常； （3）notify()：唤醒一个处于等待状态的线程，当然在调用此方法的时候，并不能确切的唤醒某一个等待状态的线程，而是由 JVM 确定唤醒哪个线程，而且与优先级无关； （4）notityAll()：唤醒所有处于等待状态的线程，该方法并不是将对象的锁给所有线程，而是让它们竞争，只有获得锁的线程才能进入就绪状态； sleep() 和 wait() 有什么区别？1两者都可以暂停线程的执行 类的不同：sleep() 是 Thread线程类的静态方法，wait() 是 Object类的方法。 是否释放锁：sleep() 不释放锁；wait() 释放锁。 用途不同：Wait 通常被用于线程间交互/通信，sleep 通常被用于暂停执行。 用法不同：wait() 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 notify() 或者 notifyAll() 方法。sleep() 方法执行完成后，线程会自动苏醒。或者可以使用wait(long timeout)超时后线程会自动苏醒。 你是如何调用 wait() 方法的？使用 if 块还是循环？为什么？ 处于等待状态的线程可能会收到错误警报和伪唤醒，如果不在循环中检查等待条件，程序就会在没有满足结束条件的情况下退出。 wait() 方法应该在循环调用，因为当线程获取到 CPU 开始执行的时候，其他条件可能还没有满足，所以在处理前，循环检测条件是否满足会更好。下面是一段标准的使用 wait 和 notify 方法的代码： 123456789synchronized (monitor) &#123; // 判断条件谓词是否得到满足 while(!locked) &#123; // 等待唤醒 monitor.wait(); &#125; // 处理其他的业务逻辑&#125;复制代码 为什么线程通信的方法 wait(), notify()和 notifyAll()被定义在 Object 类里？ 因为Java所有类的都继承了Object，Java想让任何对象都可以作为锁，并且 wait()，notify()等方法用于等待对象的锁或者唤醒线程，在 Java 的线程中并没有可供任何对象使用的锁，所以任意对象调用方法一定定义在Object类中。 有的人会说，既然是线程放弃对象锁，那也可以把wait()定义在Thread类里面啊，新定义的线程继承于Thread类，也不需要重新定义wait()方法的实现。然而，这样做有一个非常大的问题，一个线程完全可以持有很多锁，你一个线程放弃锁的时候，到底要放弃哪个锁？当然了，这种设计并不是不能实现，只是管理起来更加复杂。 为什么 wait(), notify()和 notifyAll()必须在同步方法或者同步块中被调用？ 当一个线程需要调用对象的 wait()方法的时候，这个线程必须拥有该对象的锁，接着它就会释放这个对象锁并进入等待状态直到其他线程调用这个对象上的 notify()方法。同样的，当一个线程需要调用对象的 notify()方法时，它会释放这个对象的锁，以便其他在等待的线程就可以得到这个对象锁。由于所有的这些方法都需要线程持有对象的锁，这样就只能通过同步来实现，所以他们只能在同步方法或者同步块中被调用。 Thread 类中的 yield 方法有什么作用？ 使当前线程从执行状态（运行状态）变为可执行态（就绪状态）。 当前线程到了就绪状态，那么接下来哪个线程会从就绪状态变成执行状态呢？可能是当前线程，也可能是其他线程，看系统的分配了。 为什么 Thread 类的 sleep()和 yield ()方法是静态的？ Thread 类的 sleep()和 yield()方法将在当前正在执行的线程上运行。所以在其他处于等待状态的线程上调用这些方法是没有意义的。这就是为什么这些方法是静态的。它们可以在当前正在执行的线程中工作，并避免程序员错误的认为可以在其他非运行线程调用这些方法。 线程的 sleep()方法和 yield()方法有什么区别？ （1） sleep()方法给其他线程运行机会时不考虑线程的优先级，因此会给低优先级的线程以运行的机会；yield()方法只会给相同优先级或更高优先级的线程以运行的机会； （2） 线程执行 sleep()方法后转入阻塞（blocked）状态，而执行 yield()方法后转入就绪（ready）状态； （3）sleep()方法声明抛出 InterruptedException，而 yield()方法没有声明任何异常； （4）sleep()方法比 yield()方法（跟操作系统 CPU 调度相关）具有更好的可移植性，通常不建议使用yield()方法来控制并发线程的执行。 如何停止一个正在运行的线程？ 在java中有以下3种方法可以终止正在运行的线程： 使用退出标志，使线程正常退出，也就是当run方法完成后线程终止。 使用stop方法强行终止，但是不推荐这个方法，因为stop和suspend及resume一样都是过期作废的方法。 使用interrupt方法中断线程。 Java 中 interrupted 和 isInterrupted 方法的区别？ interrupt：用于中断线程。调用该方法的线程的状态为将被置为”中断”状态。 注意：线程中断仅仅是置线程的中断状态位，不会停止线程。需要用户自己去监视线程的状态为并做处理。支持线程中断的方法（也就是线程中断后会抛出interruptedException 的方法）就是在监视线程的中断状态，一旦线程的中断状态被置为“中断状态”，就会抛出中断异常。 interrupted：是静态方法，查看当前中断信号是true还是false并且清除中断信号。如果一个线程被中断了，第一次调用 interrupted 则返回 true，第二次和后面的就返回 false 了。 isInterrupted：是可以返回当前中断信号是true还是false，与interrupt最大的差别 什么是阻塞式方法？ 阻塞式方法是指程序会一直等待该方法完成期间不做其他事情，ServerSocket 的accept()方法就是一直等待客户端连接。这里的阻塞是指调用结果返回之前，当前线程会被挂起，直到得到结果之后才会返回。此外，还有异步和非阻塞式方法在任务完成前就返回。 Java 中你怎样唤醒一个阻塞的线程？ 首先 ，wait()、notify() 方法是针对对象的，调用任意对象的 wait()方法都将导致线程阻塞，阻塞的同时也将释放该对象的锁，相应地，调用任意对象的 notify()方法则将随机解除该对象阻塞的线程，但它需要重新获取该对象的锁，直到获取成功才能往下执行； 其次，wait、notify 方法必须在 synchronized 块或方法中被调用，并且要保证同步块或方法的锁对象与调用 wait、notify 方法的对象是同一个，如此一来在调用 wait 之前当前线程就已经成功获取某对象的锁，执行 wait 阻塞后当前线程就将之前获取的对象锁释放。 notify() 和 notifyAll() 有什么区别？ 如果线程调用了对象的 wait()方法，那么线程便会处于该对象的等待池中，等待池中的线程不会去竞争该对象的锁。 notifyAll() 会唤醒所有的线程，notify() 只会唤醒一个线程。 notifyAll() 调用后，会将全部线程由等待池移到锁池，然后参与锁的竞争，竞争成功则继续执行，如果不成功则留在锁池等待锁被释放后再次参与竞争。而 notify()只会唤醒一个线程，具体唤醒哪一个线程由虚拟机控制。 如何在两个线程间共享数据？ 在两个线程间共享变量即可实现共享。 1一般来说，共享变量要求变量本身是线程安全的，然后在线程内使用的时候，如果有对共享变量的复合操作，那么也得保证复合操作的线程安全性。 Java 如何实现多线程之间的通讯和协作？ 可以通过中断 和 共享变量的方式实现线程间的通讯和协作 比如说最经典的生产者-消费者模型：当队列满时，生产者需要等待队列有空间才能继续往里面放入商品，而在等待的期间内，生产者必须释放对临界资源（即队列）的占用权。因为生产者如果不释放对临界资源的占用权，那么消费者就无法消费队列中的商品，就不会让队列有空间，那么生产者就会一直无限等待下去。因此，一般情况下，当队列满时，会让生产者交出对临界资源的占用权，并进入挂起状态。然后等待消费者消费了商品，然后消费者通知生产者队列有空间了。同样地，当队列空时，消费者也必须等待，等待生产者通知它队列中有商品了。这种互相通信的过程就是线程间的协作。 Java中线程通信协作的最常见方式： 一.syncrhoized加锁的线程的Object类的wait()/notify()/notifyAll() 二.ReentrantLock类加锁的线程的Condition类的await()/signal()/signalAll() 线程间直接的数据交换： 三.通过管道进行线程间通信：字节流、字符流 同步方法和同步块，哪个是更好的选择？ 同步块是更好的选择，因为它不会锁住整个对象（当然你也可以让它锁住整个对象）。同步方法会锁住整个对象，哪怕这个类中有多个不相关联的同步块，这通常会导致他们停止执行并需要等待获得这个对象上的锁。 同步块更要符合开放调用的原则，只在需要锁住的代码块锁住相应的对象，这样从侧面来说也可以避免死锁。 1请知道一条原则：同步的范围越小越好。 什么是线程同步和线程互斥，有哪几种实现方式？ 当一个线程对共享的数据进行操作时，应使之成为一个”原子操作“，即在没有完成相关操作之前，不允许其他线程打断它，否则，就会破坏数据的完整性，必然会得到错误的处理结果，这就是线程的同步。 在多线程应用中，考虑不同线程之间的数据同步和防止死锁。当两个或多个线程之间同时等待对方释放资源的时候就会形成线程之间的死锁。为了防止死锁的发生，需要通过同步来实现线程安全。 线程互斥是指对于共享的进程系统资源，在各单个线程访问时的排它性。当有若干个线程都要使用某一共享资源时，任何时刻最多只允许一个线程去使用，其它要使用该资源的线程必须等待，直到占用资源者释放该资源。线程互斥可以看成是一种特殊的线程同步。 线程间的同步方法大体可分为两类：用户模式和内核模式。顾名思义，内核模式就是指利用系统内核对象的单一性来进行同步，使用时需要切换内核态与用户态，而用户模式就是不需要切换到内核态，只在用户态完成操作。 用户模式下的方法有：原子操作（例如一个单一的全局变量），临界区。内核模式下的方法有：事件，信号量，互斥量。 实现线程同步的方法 同步代码方法：sychronized 关键字修饰的方法 同步代码块：sychronized 关键字修饰的代码块 使用特殊变量域volatile实现线程同步：volatile关键字为域变量的访问提供了一种免锁机制 使用重入锁实现线程同步：reentrantlock类是可冲入、互斥、实现了lock接口的锁他与sychronized方法具有相同的基本行为和语义 在监视器(Monitor)内部，是如何做线程同步的？程序应该做哪种级别的同步？ 在 java 虚拟机中，监视器和锁在Java虚拟机中是一块使用的。监视器监视一块同步代码块，确保一次只有一个线程执行同步代码块。每一个监视器都和一个对象引用相关联。线程在获取锁之前不允许执行同步代码。 一旦方法或者代码块被 synchronized 修饰，那么这个部分就放入了监视器的监视区域，确保一次只能有一个线程执行该部分的代码，线程在获取锁之前不允许执行该部分的代码 另外 java 还提供了显式监视器( Lock )和隐式监视器( synchronized )两种锁方案 如果你提交任务时，线程池队列已满，这时会发生什么 有俩种可能： （1）如果使用的是无界队列 LinkedBlockingQueue，也就是无界队列的话，没关系，继续添加任务到阻塞队列中等待执行，因为 LinkedBlockingQueue 可以近乎认为是一个无穷大的队列，可以无限存放任务 （2）如果使用的是有界队列比如 ArrayBlockingQueue，任务首先会被添加到ArrayBlockingQueue 中，ArrayBlockingQueue 满了，会根据maximumPoolSize 的值增加线程数量，如果增加了线程数量还是处理不过来，ArrayBlockingQueue 继续满，那么则会使用拒绝策略RejectedExecutionHandler 处理满了的任务，默认是 AbortPolicy 什么叫线程安全？servlet 是线程安全吗? 线程安全是编程中的术语，指某个方法在多线程环境中被调用时，能够正确地处理多个线程之间的共享变量，使程序功能正确完成。 Servlet 不是线程安全的，servlet 是单实例多线程的，当多个线程同时访问同一个方法，是不能保证共享变量的线程安全性的。 Struts2 的 action 是多实例多线程的，是线程安全的，每个请求过来都会 new 一个新的 action 分配给这个请求，请求完成后销毁。 SpringMVC 的 Controller 是线程安全的吗？不是的，和 Servlet 类似的处理流程。 Struts2 好处是不用考虑线程安全问题；Servlet 和 SpringMVC 需要考虑线程安全问题，但是性能可以提升不用处理太多的 gc，可以使用 ThreadLocal 来处理多线程的问题。 在 Java 程序中怎么保证多线程的运行安全？ 方法一：使用安全类，比如 java.util.concurrent 下的类，使用原子类AtomicInteger 方法二：使用自动锁 synchronized。 方法三：使用手动锁 Lock。 手动锁 Java 示例代码如下： 1234567891011Lock lock = new ReentrantLock();lock. lock();try &#123; System. out. println(&quot;获得锁&quot;);&#125; catch (Exception e) &#123; // TODO: handle exception&#125; finally &#123; System. out. println(&quot;释放锁&quot;); lock. unlock();&#125;复制代码 你对线程优先级的理解是什么？ 每一个线程都是有优先级的，一般来说，高优先级的线程在运行时会具有优先权，但这依赖于线程调度的实现，这个实现是和操作系统相关的(OS dependent)。我们可以定义线程的优先级，但是这并不能保证高优先级的线程会在低优先级的线程前执行。线程优先级是一个 int 变量(从 1-10)，1 代表最低优先级，10 代表最高优先级。 Java 的线程优先级调度会委托给操作系统去处理，所以与具体的操作系统优先级有关，如非特别需要，一般无需设置线程优先级。 当然，如果你真的想设置优先级可以通过setPriority()方法设置，但是设置了不一定会该变，这个是不准确的 线程类的构造方法、静态块是被哪个线程调用的 这是一个非常刁钻和狡猾的问题。请记住：线程类的构造方法、静态块是被 new这个线程类所在的线程所调用的，而 run 方法里面的代码才是被线程自身所调用的。 如果说上面的说法让你感到困惑，那么我举个例子，假设 Thread2 中 new 了Thread1，main 函数中 new 了 Thread2，那么： （1）Thread2 的构造方法、静态块是 main 线程调用的，Thread2 的 run()方法是Thread2 自己调用的 （2）Thread1 的构造方法、静态块是 Thread2 调用的，Thread1 的 run()方法是Thread1 自己调用的 Java 中怎么获取一份线程 dump 文件？你如何在 Java 中获取线程堆栈？ Dump文件是进程的内存镜像。可以把程序的执行状态通过调试器保存到dump文件中。 在 Linux 下，你可以通过命令 kill -3 PID （Java 进程的进程 ID）来获取 Java应用的 dump 文件。 在 Windows 下，你可以按下 Ctrl + Break 来获取。这样 JVM 就会将线程的 dump 文件打印到标准输出或错误文件中，它可能打印在控制台或者日志文件中，具体位置依赖应用的配置。 一个线程运行时发生异常会怎样？ 如果异常没有被捕获该线程将会停止执行。Thread.UncaughtExceptionHandler是用于处理未捕获异常造成线程突然中断情况的一个内嵌接口。当一个未捕获异常将造成线程中断的时候，JVM 会使用 Thread.getUncaughtExceptionHandler()来查询线程的 UncaughtExceptionHandler 并将线程和异常作为参数传递给 handler 的 uncaughtException()方法进行处理。 Java 线程数过多会造成什么异常？ 线程的生命周期开销非常高 消耗过多的 CPU 资源如果可运行的线程数量多于可用处理器的数量，那么有线程将会被闲置。大量空闲的线程会占用许多内存，给垃圾回收器带来压力，而且大量的线程在竞争 CPU资源时还将产生其他性能的开销。 降低稳定性JVM 在可创建线程的数量上存在一个限制，这个限制值将随着平台的不同而不同，并且承受着多个因素制约，包括 JVM 的启动参数、Thread 构造函数中请求栈的大小，以及底层操作系统对线程的限制等。如果破坏了这些限制，那么可能抛出OutOfMemoryError 异常。 多线程的常用方法 方法 名 描述 sleep() 强迫一个线程睡眠Ｎ毫秒 isAlive() 判断一个线程是否存活。 join() 等待线程终止。 activeCount() 程序中活跃的线程数。 enumerate() 枚举程序中的线程。 currentThread() 得到当前线程。 isDaemon() 一个线程是否为守护线程。 setDaemon() 设置一个线程为守护线程。 setName() 为线程设置一个名称。 wait() 强迫一个线程等待。 notify() 通知一个线程继续运行。 setPriority() 设置一个线程的优先级。 并发理论Java中垃圾回收有什么目的？什么时候进行垃圾回收？ 垃圾回收是在内存中存在没有引用的对象或超过作用域的对象时进行的。 垃圾回收的目的是识别并且丢弃应用不再使用的对象来释放和重用资源。 线程之间如何通信及线程之间如何同步 在并发编程中，我们需要处理两个关键问题：线程之间如何通信及线程之间如何同步。通信是指线程之间以如何来交换信息。一般线程之间的通信机制有两种：共享内存和消息传递。 Java的并发采用的是共享内存模型，Java线程之间的通信总是隐式进行，整个通信过程对程序员完全透明。如果编写多线程程序的Java程序员不理解隐式进行的线程之间通信的工作机制，很可能会遇到各种奇怪的内存可见性问题。 Java内存模型 共享内存模型指的就是Java内存模型(简称JMM)，JMM决定一个线程对共享变量的写入时,能对另一个线程可见。从抽象的角度来看，JMM定义了线程和主内存之间的抽象关系：线程之间的共享变量存储在主内存（main memory）中，每个线程都有一个私有的本地内存（local memory），本地内存中存储了该线程以读/写共享变量的副本。本地内存是JMM的一个抽象概念，并不真实存在。它涵盖了缓存，写缓冲区，寄存器以及其他的硬件和编译器优化。 从上图来看，线程A与线程B之间如要通信的话，必须要经历下面2个步骤： 首先，线程A把本地内存A中更新过的共享变量刷新到主内存中去。 然后，线程B到主内存中去读取线程A之前已更新过的共享变量。 下面通过示意图来说明线程之间的通信 在这里插入图片描述 总结：什么是Java内存模型：java内存模型简称jmm，定义了一个线程对另一个线程可见。共享变量存放在主内存中，每个线程都有自己的本地内存，当多个线程同时访问一个数据的时候，可能本地内存没有及时刷新到主内存，所以就会发生线程安全问题。 如果对象的引用被置为null，垃圾收集器是否会立即释放对象占用的内存？ 不会，在下一个垃圾回调周期中，这个对象将是被可回收的。 也就是说并不会立即被垃圾收集器立刻回收，而是在下一次垃圾回收时才会释放其占用的内存。 finalize()方法什么时候被调用？析构函数(finalization)的目的是什么？ 1.垃圾回收器（garbage colector）决定回收某对象时，就会运行该对象的finalize()方法； finalize是Object类的一个方法，该方法在Object类中的声明protected void finalize() throws Throwable { } 在垃圾回收器执行时会调用被回收对象的finalize()方法，可以覆盖此方法来实现对其资源的回收。注意：一旦垃圾回收器准备释放对象占用的内存，将首先调用该对象的finalize()方法，并且下一次垃圾回收动作发生时，才真正回收对象占用的内存空间 GC本来就是内存回收了，应用还需要在finalization做什么呢？ 答案是大部分时候，什么都不用做(也就是不需要重载)。只有在某些很特殊的情况下，比如你调用了一些native的方法(一般是C写的)，可以要在finaliztion里去调用C的释放函数。 Finalizetion主要用来释放被对象占用的资源（不是指内存，而是指其他资源，比如文件(File Handle)、端口(ports)、数据库连接(DB Connection)等）。然而，它不能真正有效地工作。 什么是重排序 程序执行的顺序按照代码的先后顺序执行。 一般来说处理器为了提高程序运行效率，可能会对输入代码进行优化，进行重新排序（重排序），它不保证程序中各个语句的执行先后顺序同代码中的顺序一致，但是它会保证程序最终执行结果和代码顺序执行的结果是一致的。 12345int a = 5; //语句1int r = 3; //语句2a = a + 2; //语句3r = a*a; //语句4复制代码 则因为重排序，他还可能执行顺序为（这里标注的是语句的执行顺序） 2-1-3-4，1-3-2-4 但绝不可能 2-1-4-3，因为这打破了依赖关系。 显然重排序对单线程运行是不会有任何问题，但是多线程就不一定了，所以我们在多线程编程时就得考虑这个问题了。 重排序实际执行的指令步骤 编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。 指令级并行的重排序。现代处理器采用了指令级并行技术（ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。 内存系统的重排序。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。 这些重排序对于单线程没问题，但是多线程都可能会导致多线程程序出现内存可见性问题。 重排序遵守的规则 as-if-serial： 不管怎么排序，结果不能改变 不存在数据依赖的可以被编译器和处理器重排序 一个操作依赖两个操作，这两个操作如果不存在依赖可以重排序 单线程根据此规则不会有问题，但是重排序后多线程会有问题 as-if-serial规则和happens-before规则的区别 as-if-serial语义保证单线程内程序的执行结果不被改变，happens-before关系保证正确同步的多线程程序的执行结果不被改变。 as-if-serial语义给编写单线程程序的程序员创造了一个幻境：单线程程序是按程序的顺序来执行的。happens-before关系给编写正确同步的多线程程序的程序员创造了一个幻境：正确同步的多线程程序是按happens-before指定的顺序来执行的。 as-if-serial语义和happens-before这么做的目的，都是为了在不改变程序执行结果的前提下，尽可能地提高程序执行的并行度。 并发关键字 synchronized ？ 在 Java 中，synchronized 关键字是用来控制线程同步的，就是在多线程的环境下，控制 synchronized 代码段不被多个线程同时执行。synchronized 可以修饰类、方法、变量。 另外，在 Java 早期版本中，synchronized属于重量级锁，效率低下，因为监视器锁（monitor）是依赖于底层的操作系统的 Mutex Lock 来实现的，Java 的线程是映射到操作系统的原生线程之上的。如果要挂起或者唤醒一个线程，都需要操作系统帮忙完成，而操作系统实现线程之间的切换时需要从用户态转换到内核态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，这也是为什么早期的 synchronized 效率低的原因。庆幸的是在 Java 6 之后 Java 官方对从 JVM 层面对synchronized 较大优化，所以现在的 synchronized 锁效率也优化得很不错了。JDK1.6对锁的实现引入了大量的优化，如自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁、轻量级锁等技术来减少锁操作的开销。 说说自己是怎么使用 synchronized 关键字，在项目中用到了吗synchronized关键字最主要的三种使用方式： 修饰实例方法: 作用于当前对象实例加锁，进入同步代码前要获得当前对象实例的锁 修饰静态方法: 也就是给当前类加锁，会作用于类的所有对象实例，因为静态成员不属于任何一个实例对象，是类成员（ static 表明这是该类的一个静态资源，不管new了多少个对象，只有一份）。所以如果一个线程A调用一个实例对象的非静态 synchronized 方法，而线程B需要调用这个实例对象所属类的静态 synchronized 方法，是允许的，不会发生互斥现象，因为访问静态 synchronized 方法占用的锁是当前类的锁，而访问非静态 synchronized 方法占用的锁是当前实例对象锁。 修饰代码块: 指定加锁对象，对给定对象加锁，进入同步代码库前要获得给定对象的锁。 1总结： synchronized 关键字加到 static 静态方法和 synchronized(class)代码块上都是是给 Class 类上锁。synchronized 关键字加到实例方法上是给对象实例上锁。尽量不要使用 synchronized(String a) 因为JVM中，字符串常量池具有缓存功能！ 单例模式了解吗？给我解释一下双重检验锁方式实现单例模式！”双重校验锁实现对象单例（线程安全） 说明： 双锁机制的出现是为了解决前面同步问题和性能问题，看下面的代码，简单分析下确实是解决了多线程并行进来不会出现重复new对象，而且也实现了懒加载 1234567891011121314151617public class Singleton &#123; private volatile static Singleton uniqueInstance; private Singleton() &#123;&#125; public static Singleton getUniqueInstance() &#123; //先判断对象是否已经实例过，没有实例化过才进入加锁代码 if (uniqueInstance == null) &#123; //类对象加锁 synchronized (Singleton.class) &#123; if (uniqueInstance == null) &#123; uniqueInstance = new Singleton(); &#125; &#125; &#125; return uniqueInstance; &#125;复制代码 } 1另外，需要注意 uniqueInstance 采用 volatile 关键字修饰也是很有必要。 uniqueInstance 采用 volatile 关键字修饰也是很有必要的， uniqueInstance = new Singleton(); 这段代码其实是分为三步执行： 为 uniqueInstance 分配内存空间 初始化 uniqueInstance 将 uniqueInstance 指向分配的内存地址 12但是由于 JVM 具有指令重排的特性，执行顺序有可能变成 1-&gt;3-&gt;2。指令重排在单线程环境下不会出现问题，但是在多线程环境下会导致一个线程获得还没有初始化的实例。例如，线程 T1 执行了 1 和 3，此时 T2 调用 getUniqueInstance() 后发现 uniqueInstance 不为空，因此返回 uniqueInstance，但此时 uniqueInstance 还未被初始化。使用 volatile 可以禁止 JVM 的指令重排，保证在多线程环境下也能正常运行。 说一下 synchronized 底层实现原理？ Synchronized的语义底层是通过一个monitor（监视器锁）的对象来完成， 每个对象有一个监视器锁(monitor)。每个Synchronized修饰过的代码当它的monitor被占用时就会处于锁定状态并且尝试获取monitor的所有权 ，过程： 1、如果monitor的进入数为0，则该线程进入monitor，然后将进入数设置为1，该线程即为monitor的所有者。 2、如果线程已经占有该monitor，只是重新进入，则进入monitor的进入数加1. 3、如果其他线程已经占用了monitor，则该线程进入阻塞状态，直到monitor的进入数为0，再重新尝试获取monitor的所有权。 1synchronized是可以通过 反汇编指令 javap命令，查看相应的字节码文件。 synchronized可重入的原理 重入锁是指一个线程获取到该锁之后，该线程可以继续获得该锁。底层原理维护一个计数器，当线程获取该锁时，计数器加一，再次获得该锁时继续加一，释放锁时，计数器减一，当计数器值为0时，表明该锁未被任何线程所持有，其它线程可以竞争获取锁。 什么是自旋 很多 synchronized 里面的代码只是一些很简单的代码，执行时间非常快，此时等待的线程都加锁可能是一种不太值得的操作，因为线程阻塞涉及到用户态和内核态切换的问题。既然 synchronized 里面的代码执行得非常快，不妨让等待锁的线程不要被阻塞，而是在 synchronized 的边界做忙循环，这就是自旋。如果做了多次循环发现还没有获得锁，再阻塞，这样可能是一种更好的策略。 忙循环：就是程序员用循环让一个线程等待，不像传统方法wait(), sleep() 或 yield() 它们都放弃了CPU控制，而忙循环不会放弃CPU，它就是在运行一个空循环。这么做的目的是为了保留CPU缓存，在多核系统中，一个等待线程醒来的时候可能会在另一个内核运行，这样会重建缓存。为了避免重建缓存和减少等待重建的时间就可以使用它了。 多线程中 synchronized 锁升级的原理是什么？ synchronized 锁升级原理：在锁对象的对象头里面有一个 threadid 字段，在第一次访问的时候 threadid 为空，jvm 让其持有偏向锁，并将 threadid 设置为其线程 id，再次进入的时候会先判断 threadid 是否与其线程 id 一致，如果一致则可以直接使用此对象，如果不一致，则升级偏向锁为轻量级锁，通过自旋循环一定次数来获取锁，执行一定次数之后，如果还没有正常获取到要使用的对象，此时就会把锁从轻量级升级为重量级锁，此过程就构成了 synchronized 锁的升级。 1锁的升级的目的：锁升级是为了减低了锁带来的性能消耗。在 Java 6 之后优化 synchronized 的实现方式，使用了偏向锁升级为轻量级锁再升级到重量级锁的方式，从而减低了锁带来的性能消耗。 偏向锁，顾名思义，它会偏向于第一个访问锁的线程，如果在运行过程中，同步锁只有一个线程访问，不存在多线程争用的情况，则线程是不需要触发同步的，减少加锁／解锁的一些CAS操作（比如等待队列的一些CAS操作），这种情况下，就会给线程加一个偏向锁。 如果在运行过程中，遇到了其他线程抢占锁，则持有偏向锁的线程会被挂起，JVM会消除它身上的偏向锁，将锁恢复到标准的轻量级锁。 轻量级锁是由偏向所升级来的，偏向锁运行在一个线程进入同步块的情况下，当第二个线程加入锁争用的时候，轻量级锁就会升级为重量级锁； 重量级锁是synchronized ，是 Java 虚拟机中最为基础的锁实现。在这种状态下，Java 虚拟机会阻塞加锁失败的线程，并且在目标锁被释放的时候，唤醒这些线程。 线程 B 怎么知道线程 A 修改了变量 （1）volatile 修饰变量 （2）synchronized 修饰修改变量的方法 （3）wait/notify （4）while 轮询 当一个线程进入一个对象的 synchronized 方法 A 之后，其它线程是否可进入此对象的 synchronized 方法 B？ 不能。其它线程只能访问该对象的非同步方法，同步方法则不能进入。因为非静态方法上的 synchronized 修饰符要求执行方法时要获得对象的锁，如果已经进入A 方法说明对象锁已经被取走，那么试图进入 B 方法的线程就只能在等锁池（注意不是等待池哦）中等待对象的锁。 synchronized、volatile、CAS 比较 （1）synchronized 是悲观锁，属于抢占式，会引起其他线程阻塞。 （2）volatile 提供多线程共享变量可见性和禁止指令重排序优化。 （3）CAS 是基于冲突检测的乐观锁（非阻塞） synchronized 和 Lock 有什么区别？ 首先synchronized是Java内置关键字，在JVM层面，Lock是个Java类； synchronized 可以给类、方法、代码块加锁；而 lock 只能给代码块加锁。 synchronized 不需要手动获取锁和释放锁，使用简单，发生异常会自动释放锁，不会造成死锁；而 lock 需要自己加锁和释放锁，如果使用不当没有 unLock()去释放锁就会造成死锁。 通过 Lock 可以知道有没有成功获取锁，而 synchronized 却无法办到。 synchronized 和 ReentrantLock 区别是什么？ synchronized 是和 if、else、for、while 一样的关键字，ReentrantLock 是类，这是二者的本质区别。既然 ReentrantLock 是类，那么它就提供了比synchronized 更多更灵活的特性，可以被继承、可以有方法、可以有各种各样的类变量 synchronized 早期的实现比较低效，对比 ReentrantLock，大多数场景性能都相差较大，但是在 Java 6 中对 synchronized 进行了非常多的改进。 相同点：两者都是可重入锁 两者都是可重入锁。“可重入锁”概念是：自己可以再次获取自己的内部锁。比如一个线程获得了某个对象的锁，此时这个对象锁还没有释放，当其再次想要获取这个对象的锁的时候还是可以获取的，如果不可锁重入的话，就会造成死锁。同一个线程每次获取锁，锁的计数器都自增1，所以要等到锁的计数器下降为0时才能释放锁。 主要区别如下： ReentrantLock 使用起来比较灵活，但是必须有释放锁的配合动作； ReentrantLock 必须手动获取与释放锁，而 synchronized 不需要手动释放和开启锁； ReentrantLock 只适用于代码块锁，而 synchronized 可以修饰类、方法、变量等。 二者的锁机制其实也是不一样的。ReentrantLock 底层调用的是 Unsafe 的park 方法加锁，synchronized 操作的应该是对象头中 mark word Java中每一个对象都可以作为锁，这是synchronized实现同步的基础： 普通同步方法，锁是当前实例对象 静态同步方法，锁是当前类的class对象 同步方法块，锁是括号里面的对象 volatile 关键字的作用 对于可见性，Java 提供了 volatile 关键字来保证可见性和禁止指令重排。 volatile 提供 happens-before 的保证，确保一个线程的修改能对其他线程是可见的。当一个共享变量被 volatile 修饰时，它会保证修改的值会立即被更新到主内存中，当有其他线程需要读取时，它会去内存中读取新值。 从实践角度而言，volatile 的一个重要作用就是和 CAS 结合，保证了原子性，详细的可以参见 java.util.concurrent.atomic 包下的类，比如 AtomicInteger。 volatile 常用于多线程环境下的单次操作(单次读或者单次写)。 Java 中能创建 volatile 数组吗？ 能，Java 中可以创建 volatile 类型数组，不过只是一个指向数组的引用，而不是整个数组。意思是，如果改变引用指向的数组，将会受到 volatile 的保护，但是如果多个线程同时改变数组的元素，volatile 标示符就不能起到之前的保护作用了。 volatile 变量和 atomic 变量有什么不同？ volatile 变量可以确保先行关系，即写操作会发生在后续的读操作之前, 但它并不能保证原子性。例如用 volatile 修饰 count 变量，那么 count++ 操作就不是原子性的。 而 AtomicInteger 类提供的 atomic 方法可以让这种操作具有原子性如getAndIncrement()方法会原子性的进行增量操作把当前值加一，其它数据类型和引用变量也可以进行相似操作。 volatile 能使得一个非原子操作变成原子操作吗？ 关键字volatile的主要作用是使变量在多个线程间可见，但无法保证原子性，对于多个线程访问同一个实例变量需要加锁进行同步。 虽然volatile只能保证可见性不能保证原子性，但用volatile修饰long和double可以保证其操作原子性。 所以从Oracle Java Spec里面可以看到： 对于64位的long和double，如果没有被volatile修饰，那么对其操作可以不是原子的。在操作的时候，可以分成两步，每次对32位操作。 如果使用volatile修饰long和double，那么其读写都是原子操作 对于64位的引用地址的读写，都是原子操作 在实现JVM时，可以自由选择是否把读写long和double作为原子操作 推荐JVM实现为原子操作 synchronized 和 volatile 的区别是什么？ synchronized 表示只有一个线程可以获取作用对象的锁，执行代码，阻塞其他线程。 volatile 表示变量在 CPU 的寄存器中是不确定的，必须从主存中读取。保证多线程环境下变量的可见性；禁止指令重排序。 区别 volatile 是变量修饰符；synchronized 可以修饰类、方法、变量。 volatile 仅能实现变量的修改可见性，不能保证原子性；而 synchronized 则可以保证变量的修改可见性和原子性。 volatile 不会造成线程的阻塞；synchronized 可能会造成线程的阻塞。 volatile标记的变量不会被编译器优化；synchronized标记的变量可以被编译器优化。 volatile关键字是线程同步的轻量级实现，所以volatile性能肯定比synchronized关键字要好。但是volatile关键字只能用于变量而synchronized关键字可以修饰方法以及代码块。synchronized关键字在JavaSE1.6之后进行了主要包括为了减少获得锁和释放锁带来的性能消耗而引入的偏向锁和轻量级锁以及其它各种优化之后执行效率有了显著提升，实际开发中使用 synchronized 关键字的场景还是更多一些。 final不可变对象，它对写并发应用有什么帮助？ 不可变对象(Immutable Objects)即对象一旦被创建它的状态（对象的数据，也即对象属性值）就不能改变，反之即为可变对象(Mutable Objects)。 不可变对象的类即为不可变类(Immutable Class)。Java 平台类库中包含许多不可变类，如 String、基本类型的包装类、BigInteger 和 BigDecimal 等。 只有满足如下状态，一个对象才是不可变的； 它的状态不能在创建后再被修改； 所有域都是 final 类型；并且，它被正确创建（创建期间没有发生 this 引用的逸出）。 1不可变对象保证了对象的内存可见性，对不可变对象的读取不需要进行额外的同步手段，提升了代码执行效率。 Lock 接口和synchronized 对比同步它有什么优势？ Lock 接口比同步方法和同步块提供了更具扩展性的锁操作。他们允许更灵活的结构，可以具有完全不同的性质，并且可以支持多个相关类的条件对象。 它的优势有： （1）可以使锁更公平 （2）可以使线程在等待锁的时候响应中断 （3）可以让线程尝试获取锁，并在无法获取锁的时候立即返回或者等待一段时间 （4）可以在不同的范围，以不同的顺序获取和释放锁 整体上来说 Lock 是 synchronized 的扩展版，Lock 提供了无条件的、可轮询的(tryLock 方法)、定时的(tryLock 带参方法)、可中断的(lockInterruptibly)、可多条件队列的(newCondition 方法)锁操作。另外 Lock 的实现类基本都支持非公平锁(默认)和公平锁，synchronized 只支持非公平锁，当然，在大部分情况下，非公平锁是高效的选择。 乐观锁和悲观锁的理解及如何实现，有哪些实现方式？ 悲观锁：总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。再比如 Java 里面的同步原语 synchronized 关键字的实现也是悲观锁。 乐观锁：顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。乐观锁适用于多读的应用类型，这样可以提高吞吐量，像数据库提供的类似于 write_condition 机制，其实都是提供的乐观锁。在 Java中 java.util.concurrent.atomic 包下面的原子变量类就是使用了乐观锁的一种实现方式 CAS 实现的。 什么是 CAS CAS 是 compare and swap 的缩写，即我们所说的比较交换。 cas 是一种基于锁的操作，而且是乐观锁。在 java 中锁分为乐观锁和悲观锁。悲观锁是将资源锁住，等一个之前获得锁的线程释放锁之后，下一个线程才可以访问。而乐观锁采取了一种宽泛的态度，通过某种方式不加锁来处理资源，比如通过给记录加 version 来获取数据，性能较悲观锁有很大的提高。 CAS 操作包含三个操作数 —— 内存位置（V）、预期原值（A）和新值(B)。如果内存地址里面的值和 A 的值是一样的，那么就将内存里面的值更新成 B。CAS是通过无限循环来获取数据的，若果在第一轮循环中，a 线程获取地址里面的值被b 线程修改了，那么 a 线程需要自旋，到下次循环才有可能机会执行。 1java.util.concurrent.atomic 包下的类大多是使用 CAS 操作来实现的(AtomicInteger,AtomicBoolean,AtomicLong) CAS 的会产生什么问题？ 1、ABA 问题： 比如说一个线程 one 从内存位置 V 中取出 A，这时候另一个线程 two 也从内存中取出 A，并且 two 进行了一些操作变成了 B，然后 two 又将 V 位置的数据变成 A，这时候线程 one 进行 CAS 操作发现内存中仍然是 A，然后 one 操作成功。尽管线程 one 的 CAS 操作成功，但可能存在潜藏的问题。从 Java1.5 开始 JDK 的 atomic包里提供了一个类 AtomicStampedReference 来解决 ABA 问题。 2、循环时间长开销大： 对于资源竞争严重（线程冲突严重）的情况，CAS 自旋的概率会比较大，从而浪费更多的 CPU 资源，效率低于 synchronized。 3、只能保证一个共享变量的原子操作： 当对一个共享变量执行操作时，我们可以使用循环 CAS 的方式来保证原子操作，但是对多个共享变量操作时，循环 CAS 就无法保证操作的原子性，这个时候就可以用锁。 什么是原子类 java.util.concurrent.atomic包：是原子类的小工具包，支持在单个变量上解除锁的线程安全编程 原子变量类相当于一种泛化的 volatile 变量，能够支持原子的和有条件的读-改-写操作。 比如：AtomicInteger 表示一个int类型的值，并提供了 get 和 set 方法，这些 Volatile 类型的int变量在读取和写入上有着相同的内存语义。它还提供了一个原子的 compareAndSet 方法（如果该方法成功执行，那么将实现与读取/写入一个 volatile 变量相同的内存效果），以及原子的添加、递增和递减等方法。AtomicInteger 表面上非常像一个扩展的 Counter 类，但在发生竞争的情况下能提供更高的可伸缩性，因为它直接利用了硬件对并发的支持。 1简单来说就是原子类来实现CAS无锁模式的算法 原子类的常用类 AtomicBoolean AtomicInteger AtomicLong AtomicReference 说一下 Atomic的原理？ Atomic包中的类基本的特性就是在多线程环境下，当有多个线程同时对单个（包括基本类型及引用类型）变量进行操作时，具有排他性，即当多个线程同时对该变量的值进行更新时，仅有一个线程能成功，而未成功的线程可以向自旋锁一样，继续尝试，一直等到执行成功。 死锁与活锁的区别，死锁与饥饿的区别？ 死锁：是指两个或两个以上的进程（或线程）在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。 活锁：任务或者执行者没有被阻塞，由于某些条件没有满足，导致一直重复尝试，失败，尝试，失败。 活锁和死锁的区别在于，处于活锁的实体是在不断的改变状态，这就是所谓的“活”， 而处于死锁的实体表现为等待；活锁有可能自行解开，死锁则不能。 饥饿：一个或者多个线程因为种种原因无法获得所需要的资源，导致一直无法执行的状态。 Java 中导致饥饿的原因： 1、高优先级线程吞噬所有的低优先级线程的 CPU 时间。 2、线程被永久堵塞在一个等待进入同步块的状态，因为其他线程总是能在它之前持续地对该同步块进行访问。 3、线程在等待一个本身也处于永久等待完成的对象(比如调用这个对象的 wait 方法)，因为其他线程总是被持续地获得唤醒。 线程池什么是线程池？ Java中的线程池是运用场景最多的并发框架，几乎所有需要异步或并发执行任务的程序都可以使用线程池。在开发过程中，合理地使用线程池能够带来许多好处。 降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。 提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行。 提高线程的可管理性。线程是稀缺资源，如果无限制地创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一分配、调优和监控。但是，要做到合理利用 线程池作用？ 线程池是为突然大量爆发的线程设计的，通过有限的几个固定线程为大量的操作服务，减少了创建和销毁线程所需的时间，从而提高效率。 如果一个线程所需要执行的时间非常长的话，就没必要用线程池了(不是不能作长时间操作，而是不宜。本来降低线程创建和销毁，结果你那么久我还不好控制还不如直接创建线程)，况且我们还不能控制线程池中线程的开始、挂起、和中止。 线程池有什么优点？ 降低资源消耗：重用存在的线程，减少对象创建销毁的开销。 提高响应速度。可有效的控制最大并发线程数，提高系统资源的使用率，同时避免过多资源竞争，避免堵塞。当任务到达时，任务可以不需要的等到线程创建就能立即执行。 提高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。 附加功能：提供定时执行、定期执行、单线程、并发数控制等功能。 什么是ThreadPoolExecutor？ ThreadPoolExecutor就是线程池 ThreadPoolExecutor其实也是JAVA的一个类，我们一般通过Executors工厂类的方法，通过传入不同的参数，就可以构造出适用于不同应用场景下的ThreadPoolExecutor（线程池） 构造参数图： 在这里插入图片描述 1构造参数参数介绍： 12345678corePoolSize 核心线程数量maximumPoolSize 最大线程数量keepAliveTime 线程保持时间，N个时间单位unit 时间单位（比如秒，分）workQueue 阻塞队列threadFactory 线程工厂handler 线程池拒绝策略复制代码 什么是Executors？ Executors框架实现的就是线程池的功能。 Executors工厂类中提供的newCachedThreadPool、newFixedThreadPool 、newScheduledThreadPool 、newSingleThreadExecutor 等方法其实也只是ThreadPoolExecutor的构造函数参数不同而已。通过传入不同的参数，就可以构造出适用于不同应用场景下的线程池， Executor工厂类如何创建线程池图： 在这里插入图片描述 线程池四种创建方式？ Java通过Executors（jdk1.5并发包）提供四种线程池，分别为： newCachedThreadPool创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。 newFixedThreadPool 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。 newScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行。 newSingleThreadExecutor 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。 在 Java 中 Executor 和 Executors 的区别？ Executors 工具类的不同方法按照我们的需求创建了不同的线程池，来满足业务的需求。 Executor 接口对象能执行我们的线程任务。 ExecutorService 接口继承了 Executor 接口并进行了扩展，提供了更多的方法我们能获得任务执行的状态并且可以获取任务的返回值。 使用 ThreadPoolExecutor 可以创建自定义线程池。 四种构建线程池的区别及特点？1. newCachedThreadPool 特点：newCachedThreadPool创建一个可缓存线程池，如果当前线程池的长度超过了处理的需要时，它可以灵活的回收空闲的线程，当需要增加时， 它可以灵活的添加新的线程，而不会对池的长度作任何限制 缺点：他虽然可以无线的新建线程，但是容易造成堆外内存溢出，因为它的最大值是在初始化的时候设置为 Integer.MAX_VALUE，一般来说机器都没那么大内存给它不断使用。当然知道可能出问题的点，就可以去重写一个方法限制一下这个最大值 总结：线程池为无限大，当执行第二个任务时第一个任务已经完成，会复用执行第一个任务的线程，而不用每次新建线程。 代码示例： 12345678910111213141516171819202122232425package com.lijie;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;public class TestNewCachedThreadPool &#123; public static void main(String[] args) &#123; // 创建无限大小线程池，由jvm自动回收 ExecutorService newCachedThreadPool = Executors.newCachedThreadPool(); for (int i = 0; i &lt; 10; i++) &#123; final int temp = i; newCachedThreadPool.execute(new Runnable() &#123; public void run() &#123; try &#123; Thread.sleep(100); &#125; catch (Exception e) &#123; &#125; System.out.println(Thread.currentThread().getName() + &quot;,i==&quot; + temp); &#125; &#125;); &#125; &#125;&#125;复制代码 2.newFixedThreadPool 特点：创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。定长线程池的大小最好根据系统资源进行设置。 缺点：线程数量是固定的，但是阻塞队列是无界队列。如果有很多请求积压，阻塞队列越来越长，容易导致OOM（超出内存空间） 总结：请求的挤压一定要和分配的线程池大小匹配，定线程池的大小最好根据系统资源进行设置。如Runtime.getRuntime().availableProcessors() 1Runtime.getRuntime().availableProcessors()方法是查看电脑CPU核心数量） 代码示例： 1234567891011121314151617181920package com.lijie;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;public class TestNewFixedThreadPool &#123; public static void main(String[] args) &#123; ExecutorService newFixedThreadPool = Executors.newFixedThreadPool(3); for (int i = 0; i &lt; 10; i++) &#123; final int temp = i; newFixedThreadPool.execute(new Runnable() &#123; public void run() &#123; System.out.println(Thread.currentThread().getName() + &quot;,i==&quot; + temp); &#125; &#125;); &#125; &#125;&#125;复制代码 3.newScheduledThreadPool 特点：创建一个固定长度的线程池，而且支持定时的以及周期性的任务执行，类似于Timer（Timer是Java的一个定时器类） 缺点：由于所有任务都是由同一个线程来调度，因此所有任务都是串行执行的，同一时间只能有一个任务在执行，前一个任务的延迟或异常都将会影响到之后的任务（比如：一个任务出错，以后的任务都无法继续）。 代码示例： 12345678910111213141516171819202122package com.lijie;import java.util.concurrent.Executors;import java.util.concurrent.ScheduledExecutorService;import java.util.concurrent.TimeUnit;public class TestNewScheduledThreadPool &#123; public static void main(String[] args) &#123; //定义线程池大小为3 ScheduledExecutorService newScheduledThreadPool = Executors.newScheduledThreadPool(3); for (int i = 0; i &lt; 10; i++) &#123; final int temp = i; newScheduledThreadPool.schedule(new Runnable() &#123; public void run() &#123; System.out.println(&quot;i:&quot; + temp); &#125; &#125;, 3, TimeUnit.SECONDS);//这里表示延迟3秒执行。 &#125; &#125;&#125;复制代码 4.newSingleThreadExecutor 特点：创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，如果这个唯一的线程因为异常结束，那么会有一个新的线程来替代它，他必须保证前一项任务执行完毕才能执行后一项。保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。 缺点：缺点的话，很明显，他是单线程的，高并发业务下有点无力 总结：保证所有任务按照指定顺序执行的，如果这个唯一的线程因为异常结束，那么会有一个新的线程来替代它 代码示例： 123456789101112131415161718192021222324package com.lijie;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;public class TestNewSingleThreadExecutor &#123; public static void main(String[] args) &#123; ExecutorService newSingleThreadExecutor = Executors.newSingleThreadExecutor(); for (int i = 0; i &lt; 10; i++) &#123; final int index = i; newSingleThreadExecutor.execute(new Runnable() &#123; public void run() &#123; System.out.println(Thread.currentThread().getName() + &quot; index:&quot; + index); try &#123; Thread.sleep(200); &#125; catch (Exception e) &#123; &#125; &#125; &#125;); &#125; &#125;&#125;复制代码 线程池都有哪些状态？ RUNNING：这是最正常的状态，接受新的任务，处理等待队列中的任务。 SHUTDOWN：不接受新的任务提交，但是会继续处理等待队列中的任务。 STOP：不接受新的任务提交，不再处理等待队列中的任务，中断正在执行任务的线程。 TIDYING：所有的任务都销毁了，workCount 为 0，线程池的状态在转换为 TIDYING 状态时，会执行钩子方法 terminated()。 TERMINATED：terminated()方法结束后，线程池的状态就会变成这个。 线程池中 submit() 和 execute() 方法有什么区别？ 相同点： 相同点就是都可以开启线程执行池中的任务。 不同点： 接收参数：execute()只能执行 Runnable 类型的任务。submit()可以执行 Runnable 和 Callable 类型的任务。 返回值：submit()方法可以返回持有计算结果的 Future 对象，而execute()没有 异常处理：submit()方便Exception处理 什么是线程组，为什么在 Java 中不推荐使用？ ThreadGroup 类，可以把线程归属到某一个线程组中，线程组中可以有线程对象，也可以有线程组，组中还可以有线程，这样的组织结构有点类似于树的形式。 线程组和线程池是两个不同的概念，他们的作用完全不同，前者是为了方便线程的管理，后者是为了管理线程的生命周期，复用线程，减少创建销毁线程的开销。 为什么不推荐使用线程组？因为使用有很多的安全隐患吧，没有具体追究，如果需要使用，推荐使用线程池。 ThreadPoolExecutor饱和策略有哪些？1如果当前同时运行的线程数量达到最大线程数量并且队列也已经被放满了任时，ThreadPoolTaskExecutor 定义一些策略: ThreadPoolExecutor.AbortPolicy：抛出 RejectedExecutionException来拒绝新任务的处理。 ThreadPoolExecutor.CallerRunsPolicy：调用执行自己的线程运行任务。您不会任务请求。但是这种策略会降低对于新任务提交速度，影响程序的整体性能。另外，这个策略喜欢增加队列容量。如果您的应用程序可以承受此延迟并且你不能任务丢弃任何一个任务请求的话，你可以选择这个策略。 ThreadPoolExecutor.DiscardPolicy：不处理新任务，直接丢弃掉。 ThreadPoolExecutor.DiscardOldestPolicy： 此策略将丢弃最早的未处理的任务请求。 如何自定义线程线程池? 先看ThreadPoolExecutor（线程池）这个类的构造参数 构造参数参数介绍： 123456789corePoolSize 核心线程数量maximumPoolSize 最大线程数量keepAliveTime 线程保持时间，N个时间单位unit 时间单位（比如秒，分）workQueue 阻塞队列threadFactory 线程工厂handler 线程池拒绝策略复制代码 代码示例： 1234567891011121314151617181920212223242526272829303132package com.lijie;import java.util.concurrent.ArrayBlockingQueue;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;public class Test001 &#123; public static void main(String[] args) &#123; //创建线程池 ThreadPoolExecutor executor = new ThreadPoolExecutor(1, 2, 60L, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(3)); for (int i = 1; i &lt;= 6; i++) &#123; TaskThred t1 = new TaskThred(&quot;任务&quot; + i); //executor.execute(t1);是执行线程方法 executor.execute(t1); &#125; //executor.shutdown()不再接受新的任务，并且等待之前提交的任务都执行完再关闭，阻塞队列中的任务不会再执行。 executor.shutdown(); &#125;&#125;class TaskThred implements Runnable &#123; private String taskName; public TaskThred(String taskName) &#123; this.taskName = taskName; &#125; public void run() &#123; System.out.println(Thread.currentThread().getName() + taskName); &#125;&#125;复制代码 线程池的执行原理？ 提交一个任务到线程池中，线程池的处理流程如下： 判断线程池里的核心线程是否都在执行任务，如果不是（核心线程空闲或者还有核心线程没有被创建）则创建一个新的工作线程来执行任务。如果核心线程都在执行任务，则进入下个流程。 线程池判断工作队列是否已满，如果工作队列没有满，则将新提交的任务存储在这个工作队列里。如果工作队列满了，则进入下个流程。 判断线程池里的线程是否都处于工作状态，如果没有，则创建一个新的工作线程来执行任务。如果已经满了，则交给饱和策略来处理这个任务。 如何合理分配线程池大小? 要合理的分配线程池的大小要根据实际情况来定，简单的来说的话就是根据CPU密集和IO密集来分配 什么是CPU密集 CPU密集的意思是该任务需要大量的运算，而没有阻塞，CPU一直全速运行。 CPU密集任务只有在真正的多核CPU上才可能得到加速(通过多线程)，而在单核CPU上，无论你开几个模拟的多线程，该任务都不可能得到加速，因为CPU总的运算能力就那样。 什么是IO密集 IO密集型，即该任务需要大量的IO，即大量的阻塞。在单线程上运行IO密集型的任务会导致浪费大量的CPU运算能力浪费在等待。所以在IO密集型任务中使用多线程可以大大的加速程序运行，即时在单核CPU上，这种加速主要就是利用了被浪费掉的阻塞时间。 分配CPU和IO密集： CPU密集型时，任务可以少配置线程数，大概和机器的cpu核数相当，这样可以使得每个线程都在执行任务 IO密集型时，大部分线程都阻塞，故需要多配置线程数，2*cpu核数 精确来说的话的话： 从以下几个角度分析任务的特性： 任务的性质：CPU密集型任务、IO密集型任务、混合型任务。 任务的优先级：高、中、低。 任务的执行时间：长、中、短。 任务的依赖性：是否依赖其他系统资源，如数据库连接等。 可以得出一个结论： 线程等待时间比CPU执行时间比例越高，需要越多线程。 线程CPU执行时间比等待时间比例越高，需要越少线程。 并发容器你经常使用什么并发容器，为什么？ 答：Vector、ConcurrentHashMap、HasTable 一般软件开发中容器用的最多的就是HashMap、ArrayList，LinkedList ，等等 但是在多线程开发中就不能乱用容器，如果使用了未加锁（非同步）的的集合，你的数据就会非常的混乱。由此在多线程开发中需要使用的容器必须是加锁（同步）的容器。 什么是Vector Vector与ArrayList一样，也是通过数组实现的，不同的是它支持线程的同步，即某一时刻只有一个线程能够写Vector，避免多线程同时写而引起的不一致性，但实现同步需要很高的花费，访问它比访问ArrayList慢很多 （ArrayList是最常用的List实现类，内部是通过数组实现的，它允许对元素进行快速随机访问。当从ArrayList的中间位置插入或者删除元素时，需要对数组进行复制、移动、代价比较高。因此，它适合随机查找和遍历，不适合插入和删除。ArrayList的缺点是每个元素之间不能有间隔。） ArrayList和Vector有什么不同之处？ Vector方法带上了synchronized关键字，是线程同步的 ArrayList添加方法源码 Vector添加源码（加锁了synchronized关键字） 为什么HashTable是线程安全的？ 因为HasTable的内部方法都被synchronized修饰了，所以是线程安全的。其他的都和HashMap一样 HashMap添加方法的源码 HashTable添加方法的源码 用过ConcurrentHashMap，讲一下他和HashTable的不同之处？ ConcurrentHashMap是Java5中支持高并发、高吞吐量的线程安全HashMap实现。它由Segment数组结构和HashEntry数组结构组成。Segment数组在ConcurrentHashMap里扮演锁的角色，HashEntry则用于存储键-值对数据。一个ConcurrentHashMap里包含一个Segment数组，Segment的结构和HashMap类似，是一种数组和链表结构；一个Segment里包含一个HashEntry数组，每个HashEntry是一个链表结构的元素；每个Segment守护着一个HashEntry数组里的元素，当对HashEntry数组的数据进行修改时，必须首先获得它对应的Segment锁。 看不懂？？？很正常，我也看不懂 总结： HashTable就是实现了HashMap加上了synchronized，而ConcurrentHashMap底层采用分段的数组+链表实现，线程安全 ConcurrentHashMap通过把整个Map分为N个Segment，可以提供相同的线程安全，但是效率提升N倍，默认提升16倍。 并且读操作不加锁，由于HashEntry的value变量是 volatile的，也能保证读取到最新的值。 Hashtable的synchronized是针对整张Hash表的，即每次锁住整张表让线程独占，ConcurrentHashMap允许多个修改操作并发进行，其关键在于使用了锁分离技术 扩容：段内扩容（段内元素超过该段对应Entry数组长度的75%触发扩容，不会对整个Map进行扩容），插入前检测需不需要扩容，有效避免无效扩容 Collections.synchronized * 是什么？1注意：* 号代表后面是还有内容的 此方法是干什么的呢，他完完全全的可以把List、Map、Set接口底下的集合变成线程安全的集合 Collections.synchronized * ：原理是什么，我猜的话是代理模式：Java代理模式理解 Java 中 ConcurrentHashMap 的并发度是什么？ ConcurrentHashMap 把实际 map 划分成若干部分来实现它的可扩展性和线程安全。这种划分是使用并发度获得的，它是 ConcurrentHashMap 类构造函数的一个可选参数，默认值为 16，这样在多线程情况下就能避免争用。 在 JDK8 后，它摒弃了 Segment（锁段）的概念，而是启用了一种全新的方式实现,利用 CAS 算法。同时加入了更多的辅助变量来提高并发度，具体内容还是查看源码吧。 什么是并发容器的实现？ 何为同步容器：可以简单地理解为通过 synchronized 来实现同步的容器，如果有多个线程调用同步容器的方法，它们将会串行执行。比如 Vector，Hashtable，以及 Collections.synchronizedSet，synchronizedList 等方法返回的容器。可以通过查看 Vector，Hashtable 等这些同步容器的实现代码，可以看到这些容器实现线程安全的方式就是将它们的状态封装起来，并在需要同步的方法上加上关键字 synchronized。 并发容器使用了与同步容器完全不同的加锁策略来提供更高的并发性和伸缩性，例如在 ConcurrentHashMap 中采用了一种粒度更细的加锁机制，可以称为分段锁，在这种锁机制下，允许任意数量的读线程并发地访问 map，并且执行读操作的线程和写操作的线程也可以并发的访问 map，同时允许一定数量的写操作线程并发地修改 map，所以它可以在并发环境下实现更高的吞吐量。 Java 中的同步集合与并发集合有什么区别？ 同步集合与并发集合都为多线程和并发提供了合适的线程安全的集合，不过并发集合的可扩展性更高。在 Java1.5 之前程序员们只有同步集合来用且在多线程并发的时候会导致争用，阻碍了系统的扩展性。Java5 介绍了并发集合像ConcurrentHashMap，不仅提供线程安全还用锁分离和内部分区等现代技术提高了可扩展性。 SynchronizedMap 和 ConcurrentHashMap 有什么区别？ SynchronizedMap 一次锁住整张表来保证线程安全，所以每次只能有一个线程来访为 map。 ConcurrentHashMap 使用分段锁来保证在多线程下的性能。 ConcurrentHashMap 中则是一次锁住一个桶。ConcurrentHashMap 默认将hash 表分为 16 个桶，诸如 get，put，remove 等常用操作只锁当前需要用到的桶。 这样，原来只能一个线程进入，现在却能同时有 16 个写线程执行，并发性能的提升是显而易见的。 另外 ConcurrentHashMap 使用了一种不同的迭代方式。在这种迭代方式中，当iterator 被创建后集合再发生改变就不再是抛出ConcurrentModificationException，取而代之的是在改变时 new 新的数据从而不影响原有的数据，iterator 完成后再将头指针替换为新的数据 ，这样 iterator线程可以使用原来老的数据，而写线程也可以并发的完成改变。 CopyOnWriteArrayList 是什么? CopyOnWriteArrayList 是一个并发容器。有很多人称它是线程安全的，我认为这句话不严谨，缺少一个前提条件，那就是非复合场景下操作它是线程安全的。 CopyOnWriteArrayList(免锁容器)的好处之一是当多个迭代器同时遍历和修改这个列表时，不会抛出 ConcurrentModificationException。在CopyOnWriteArrayList 中，写入将导致创建整个底层数组的副本，而源数组将保留在原地，使得复制的数组在被修改时，读取操作可以安全地执行。 CopyOnWriteArrayList 的使用场景? 合适读多写少的场景。 CopyOnWriteArrayList 的缺点? 由于写操作的时候，需要拷贝数组，会消耗内存，如果原数组的内容比较多的情况下，可能导致 young gc 或者 full gc。 不能用于实时读的场景，像拷贝数组、新增元素都需要时间，所以调用一个 set 操作后，读取到数据可能还是旧的，虽然CopyOnWriteArrayList 能做到最终一致性,但是还是没法满足实时性要求。 由于实际使用中可能没法保证 CopyOnWriteArrayList 到底要放置多少数据，万一数据稍微有点多，每次 add/set 都要重新复制数组，这个代价实在太高昂了。在高性能的互联网应用中，这种操作分分钟引起故障。 CopyOnWriteArrayList 的设计思想? 读写分离，读和写分开 最终一致性 使用另外开辟空间的思路，来解决并发冲突 并发队列什么是并发队列： 消息队列很多人知道：消息队列是分布式系统中重要的组件，是系统与系统直接的通信 并发队列是什么：并发队列多个线程以有次序共享数据的重要组件 并发队列和并发集合的区别：1那就有可能要说了，我们并发集合不是也可以实现多线程之间的数据共享吗，其实也是有区别的： 队列遵循“先进先出”的规则，可以想象成排队检票，队列一般用来解决大数据量采集处理和显示的。 并发集合就是在多个线程中共享数据的 怎么判断并发队列是阻塞队列还是非阻塞队列 在并发队列上JDK提供了Queue接口，一个是以Queue接口下的BlockingQueue接口为代表的阻塞队列，另一个是高性能（无堵塞）队列。 阻塞队列和非阻塞队列区别 当队列阻塞队列为空的时，从队列中获取元素的操作将会被阻塞。 或者当阻塞队列是满时，往队列里添加元素的操作会被阻塞。 或者试图从空的阻塞队列中获取元素的线程将会被阻塞，直到其他的线程往空的队列插入新的元素。 试图往已满的阻塞队列中添加新元素的线程同样也会被阻塞，直到其他的线程使队列重新变得空闲起来 常用并发列队的介绍： 非堵塞队列： ArrayDeque, （数组双端队列） ArrayDeque （非堵塞队列）是JDK容器中的一个双端队列实现，内部使用数组进行元素存储，不允许存储null值，可以高效的进行元素查找和尾部插入取出，是用作队列、双端队列、栈的绝佳选择，性能比LinkedList还要好。 PriorityQueue, （优先级队列） PriorityQueue （非堵塞队列） 一个基于优先级的无界优先级队列。优先级队列的元素按照其自然顺序进行排序，或者根据构造队列时提供的 Comparator 进行排序，具体取决于所使用的构造方法。该队列不允许使用 null 元素也不允许插入不可比较的对象 ConcurrentLinkedQueue, （基于链表的并发队列） ConcurrentLinkedQueue （非堵塞队列）: 是一个适用于高并发场景下的队列，通过无锁的方式，实现了高并发状态下的高性能。ConcurrentLinkedQueue的性能要好于BlockingQueue接口，它是一个基于链接节点的无界线程安全队列。该队列的元素遵循先进先出的原则。该队列不允许null元素。 堵塞队列： DelayQueue, （基于时间优先级的队列，延期阻塞队列） DelayQueue是一个没有边界BlockingQueue实现，加入其中的元素必需实现Delayed接口。当生产者线程调用put之类的方法加入元素时，会触发Delayed接口中的compareTo方法进行排序，也就是说队列中元素的顺序是按到期时间排序的，而非它们进入队列的顺序。排在队列头部的元素是最早到期的，越往后到期时间赿晚。 ArrayBlockingQueue, （基于数组的并发阻塞队列） ArrayBlockingQueue是一个有边界的阻塞队列，它的内部实现是一个数组。有边界的意思是它的容量是有限的，我们必须在其初始化的时候指定它的容量大小，容量大小一旦指定就不可改变。ArrayBlockingQueue是以先进先出的方式存储数据 LinkedBlockingQueue, （基于链表的FIFO阻塞队列） LinkedBlockingQueue阻塞队列大小的配置是可选的，如果我们初始化时指定一个大小，它就是有边界的，如果不指定，它就是无边界的。说是无边界，其实是采用了默认大小为Integer.MAX_VALUE的容量 。它的内部实现是一个链表。 LinkedBlockingDeque, （基于链表的FIFO双端阻塞队列） LinkedBlockingDeque是一个由链表结构组成的双向阻塞队列，即可以从队列的两端插入和移除元素。双向队列因为多了一个操作队列的入口，在多线程同时入队时，也就减少了一半的竞争。 相比于其他阻塞队列，LinkedBlockingDeque多了addFirst、addLast、peekFirst、peekLast等方法，以first结尾的方法，表示插入、获取获移除双端队列的第一个元素。以last结尾的方法，表示插入、获取获移除双端队列的最后一个元素。 LinkedBlockingDeque是可选容量的，在初始化时可以设置容量防止其过度膨胀，如果不设置，默认容量大小为Integer.MAX_VALUE。 PriorityBlockingQueue, （带优先级的无界阻塞队列） priorityBlockingQueue是一个无界队列，它没有限制，在内存允许的情况下可以无限添加元素；它又是具有优先级的队列，是通过构造函数传入的对象来判断，传入的对象必须实现comparable接口。 SynchronousQueue （并发同步阻塞队列） SynchronousQueue是一个内部只能包含一个元素的队列。插入元素到队列的线程被阻塞，直到另一个线程从队列中获取了队列中存储的元素。同样，如果线程尝试获取元素并且当前不存在任何元素，则该线程将被阻塞，直到线程将元素插入队列。 将这个类称为队列有点夸大其词。这更像是一个点。 并发队列的常用方法1不管是那种列队，是那个类，当是他们使用的方法都是差不多的 方法名 描述 add() 在不超出队列长度的情况下插入元素，可以立即执行，成功返回true，如果队列满了就抛出异常。 offer() 在不超出队列长度的情况下插入元素的时候则可以立即在队列的尾部插入指定元素,成功时返回true，如果此队列已满，则返回false。 put() 插入元素的时候，如果队列满了就进行等待，直到队列可用。 take() 从队列中获取值，如果队列中没有值，线程会一直阻塞，直到队列中有值，并且该方法取得了该值。 poll(long timeout, TimeUnit unit) 在给定的时间里，从队列中获取值，如果没有取到会抛出异常。 remainingCapacity() 获取队列中剩余的空间。 remove(Object o) 从队列中移除指定的值。 contains(Object o) 判断队列中是否拥有该值。 drainTo(Collection c) 将队列中值，全部移除，并发设置到给定的集合中。 并发工具类常用的并发工具类有哪些？ CountDownLatch CountDownLatch 类位于java.util.concurrent包下，利用它可以实现类似计数器的功能。比如有一个任务A，它要等待其他3个任务执行完毕之后才能执行，此时就可以利用CountDownLatch来实现这种功能了。 CyclicBarrier (回环栅栏) CyclicBarrier它的作用就是会让所有线程都等待完成后才会继续下一步行动。 CyclicBarrier初始化时规定一个数目，然后计算调用了CyclicBarrier.await()进入等待的线程数。当线程数达到了这个数目时，所有进入等待状态的线程被唤醒并继续。 CyclicBarrier初始时还可带一个Runnable的参数， 此Runnable任务在CyclicBarrier的数目达到后，所有其它线程被唤醒前被执行。 Semaphore (信号量) Semaphore 是 synchronized 的加强版，作用是控制线程的并发数量（允许自定义多少线程同时访问）。就这一点而言，单纯的synchronized 关键字是实现不了的。 Semaphore是一种基于计数的信号量。它可以设定一个阈值，基于此，多个线程竞争获取许可信号，做自己的申请后归还，超过阈值后，线程申请许可信号将会被阻塞。Semaphore可以用来构建一些对象池，资源池之类的，比如数据库连接池，我们也可以创建计数为1的Semaphore，将其作为一种类似互斥锁的机制，这也叫二元信号量，表示两种互斥状态。它的用法如下： 作者：小杰要吃蛋链接：https://juejin.cn/post/6844904125755293710来源：掘金著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。","tags":[{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"},{"name":"基础","slug":"基础","permalink":"https://lywlefan.github.io/tags/基础/"}]},{"title":"Java基础相关问题","date":"2020-06-20T16:00:00.000Z","path":"2020/06/21/软件研发/后端/基础巩固/java/基础知识/java基础相关问题/","text":"Java概述何为编程 编程就是让计算机为解决某个问题而使用某种程序设计语言编写程序代码，并最终得到结果的过程。 为了使计算机能够理解人的意图，人类就必须要将需解决的问题的思路、方法、和手段通过计算机能够理解的形式告诉计算机，使得计算机能够根据人的指令一步一步去工作，完成某种特定的任务。这种人和计算机之间交流的过程就是编程。 什么是Java Java是一门面向对象编程语言，不仅吸收了C++语言的各种优点，还摒弃了C++里难以理解的多继承、指针等概念，因此Java语言具有功能强大和简单易用两个特征。Java语言作为静态面向对象编程语言的代表，极好地实现了面向对象理论，允许程序员以优雅的思维方式进行复杂的编程 。 jdk1.5之后的三大版本 Java SE（J2SE，Java 2 Platform Standard Edition，标准版） Java SE 以前称为 J2SE。它允许开发和部署在桌面、服务器、嵌入式环境和实时环境中使用的 Java 应用程序。Java SE 包含了支持 Java Web 服务开发的类，并为Java EE和Java ME提供基础。 Java EE（J2EE，Java 2 Platform Enterprise Edition，企业版） Java EE 以前称为 J2EE。企业版本帮助开发和部署可移植、健壮、可伸缩且安全的服务器端Java 应用程序。Java EE 是在 Java SE 的基础上构建的，它提供 Web 服务、组件模型、管理和通信 API，可以用来实现企业级的面向服务体系结构（service-oriented architecture，SOA）和 Web2.0应用程序。2018年2月，Eclipse 宣布正式将 JavaEE 更名为 JakartaEE Java ME（J2ME，Java 2 Platform Micro Edition，微型版） Java ME 以前称为 J2ME。Java ME 为在移动设备和嵌入式设备（比如手机、PDA、电视机顶盒和打印机）上运行的应用程序提供一个健壮且灵活的环境。Java ME 包括灵活的用户界面、健壮的安全模型、许多内置的网络协议以及对可以动态下载的连网和离线应用程序的丰富支持。基于 Java ME 规范的应用程序只需编写一次，就可以用于许多设备，而且可以利用每个设备的本机功能。 3 Jdk和Jre和JVM的区别1看Java官方的图片，Jdk中包括了Jre，Jre中包括了JVM JDK ：Jdk还包括了一些Jre之外的东西 ，就是这些东西帮我们编译Java代码的， 还有就是监控Jvm的一些工具 Java Development Kit是提供给Java开发人员使用的，其中包含了Java的开发工具，也包括了JRE。所以安装了JDK，就无需再单独安装JRE了。其中的开发工具：编译工具(javac.exe)，打包工具(jar.exe)等 JRE ：Jre大部分都是 C 和 C++ 语言编写的，他是我们在编译java时所需要的基础的类库 Java Runtime Environment包括Java虚拟机和Java程序所需的核心类库等。核心类库主要是java.lang包：包含了运行Java程序必不可少的系统类，如基本数据类型、基本数学函数、字符串处理、线程、异常处理类等，系统缺省加载这个包 如果想要运行一个开发好的Java程序，计算机中只需要安装JRE即可。 Jvm：在倒数第二层 由他可以在（最后一层的）各种平台上运行 Java Virtual Machine是Java虚拟机，Java程序需要运行在虚拟机上，不同的平台有自己的虚拟机，因此Java语言可以实现跨平台。 什么是跨平台性？原理是什么 所谓跨平台性，是指java语言编写的程序，一次编译后，可以在多个系统平台上运行。 实现原理：Java程序是通过java虚拟机在系统平台上运行的，只要该系统可以安装相应的java虚拟机，该系统就可以运行java程序。 Java语言有哪些特点 简单易学（Java语言的语法与C语言和C++语言很接近） 面向对象（封装，继承，多态） 平台无关性（Java虚拟机实现平台无关性） 支持网络编程并且很方便（Java语言诞生本身就是为简化网络编程设计的） 支持多线程（多线程机制使应用程序在同一时间并行执行多项任） 健壮性（Java语言的强类型机制、异常处理、垃圾的自动收集等） 安全性好 什么是字节码？采用字节码的最大好处是什么 字节码：Java源代码经过虚拟机编译器编译后产生的文件（即扩展为.class的文件），它不面向任何特定的处理器，只面向虚拟机。 采用字节码的好处： Java语言通过字节码的方式，在一定程度上解决了传统解释型语言执行效率低的问题，同时又保留了解释型语言可移植的特点。所以Java程序运行时比较高效，而且，由于字节码并不专对一种特定的机器，因此，Java程序无须重新编译便可在多种不同的计算机上运行。 先看下java中的编译器和解释器： Java中引入了虚拟机的概念，即在机器和编译程序之间加入了一层抽象的虚拟机器。这台虚拟的机器在任何平台上都提供给编译程序一个的共同的接口。编译程序只需要面向虚拟机，生成虚拟机能够理解的代码，然后由解释器来将虚拟机代码转换为特定系统的机器码执行。在Java中，这种供虚拟机理解的代码叫做字节码（即扩展为.class的文件），它不面向任何特定的处理器，只面向虚拟机。每一种平台的解释器是不同的，但是实现的虚拟机是相同的。Java源程序经过编译器编译后变成字节码，字节码由虚拟机解释执行，虚拟机将每一条要执行的字节码送给解释器，解释器将其翻译成特定机器上的机器码，然后在特定的机器上运行，这就是上面提到的Java的特点的编译与解释并存的解释。 Java源代码—-&gt;编译器—-&gt;jvm可执行的Java字节码(即虚拟指令)—-&gt;jvm—-&gt;jvm中解释器—–&gt;机器可执行的二进制机器码—-&gt;程序运行。 什么是Java程序的主类？应用程序和小程序的主类有何不同？ 一个程序中可以有多个类，但只能有一个类是主类。在Java应用程序中，这个主类是指包含main()方法的类。而在Java小程序中，这个主类是一个继承自系统类JApplet或Applet的子类。应用程序的主类不一定要求是public类，但小程序的主类要求必须是public类。主类是Java程序执行的入口点。 Java应用程序与小程序之间有那些差别？ 简单说应用程序是从主线程启动(也就是main()方法)。applet小程序没有main方法，主要是嵌在浏览器页面上运行(调用init()线程或者run()来启动)，嵌入浏览器这点跟flash的小游戏类似。 Java和C++的区别1我知道很多人没学过C++，但是面试官就是没事喜欢拿咱们Java和C++比呀！没办法！！！就算没学过C++，也要记下来！ 都是面向对象的语言，都支持封装、继承和多态 Java不提供指针来直接访问内存，程序内存更加安全 Java的类是单继承的，C++支持多重继承；虽然Java的类不可以多继承，但是接口可以多继承。 Java有自动内存管理机制，不需要程序员手动释放无用内存 Oracle JDK 和 OpenJDK 的对比 Oracle JDK版本将每三年发布一次，而OpenJDK版本每三个月发布一次； OpenJDK 是一个参考模型并且是完全开源的，而Oracle JDK是OpenJDK的一个实现，并不是完全开源的； Oracle JDK 比 OpenJDK 更稳定。OpenJDK和Oracle JDK的代码几乎相同，但Oracle JDK有更多的类和一些错误修复。因此，如果您想开发企业/商业软件，我建议您选择Oracle JDK，因为它经过了彻底的测试和稳定。某些情况下，有些人提到在使用OpenJDK 可能会遇到了许多应用程序崩溃的问题，但是，只需切换到Oracle JDK就可以解决问题； 在响应性和JVM性能方面，Oracle JDK与OpenJDK相比提供了更好的性能； Oracle JDK不会为即将发布的版本提供长期支持，用户每次都必须通过更新到最新版本获得支持来获取最新版本； Oracle JDK根据二进制代码许可协议获得许可，而OpenJDK根据GPL v2许可获得许可。 基础语法数据类型Java有哪些数据类型定义：Java语言是强类型语言，对于每一种数据都定义了明确的具体的数据类型，在内存中分配了不同大小的内存空间。 分类 基本数据类型 数值型 整数类型(byte,short,int,long) 浮点类型(float,double) 字符型(char) 布尔型(boolean) 引用数据类型 类(class) 接口(interface) 数组([]) Java基本数据类型图 switch 是否能作用在 byte 上，是否能作用在 long 上，是否能作用在 String 上 在 Java 5 以前，switch(expr)中，expr 只能是 byte、short、char、int。从 Java5 开始，Java 中引入了枚举类型，expr 也可以是 enum 类型，从 Java 7 开始，expr 还可以是字符串（String），但是长整型（long）在目前所有的版本中都是不可以的。 用最有效率的方法计算 2 乘以 8 2 &lt;&lt; 3（左移 3 位相当于乘以 2 的 3 次方，右移 3 位相当于除以 2 的 3 次方）。 Math.round(11.5) 等于多少？Math.round(-11.5)等于多少 Math.round(11.5)的返回值是 12，Math.round(-11.5)的返回值是-11。四舍五入的原理是在参数上加 0.5 然后进行下取整。 float f=3.4;是否正确 不正确。3.4 是双精度数，将双精度型（double）赋值给浮点型（float）属于下转型（down-casting，也称为窄化）会造成精度损失，因此需要强制类型转换float f =(float)3.4; 或者写成 float f =3.4F;。 short s1 = 1; s1 = s1 + 1;有错吗?short s1 = 1; s1 += 1;有错吗 对于 short s1 = 1; s1 = s1 + 1;由于 1 是 int 类型，因此 s1+1 运算结果也是 int型，需要强制转换类型才能赋值给 short 型。 而 short s1 = 1; s1 += 1;可以正确编译，因为 s1+= 1;相当于 s1 = (short(s1 + 1);其中有隐含的强制类型转换。 编码Java语言采用何种编码方案？有何特点？ Java语言采用Unicode编码标准，Unicode（标准码），它为每个字符制订了一个唯一的数值，因此在任何的语言，平台，程序都可以放心的使用。 注释什么Java注释定义：用于解释说明程序的文字 分类 单行注释 格式： // 注释文字 多行注释 格式： / 注释文字 / 文档注释 格式：/* 注释文字 / 作用 在程序中，尤其是复杂的程序中，适当地加入注释可以增加程序的可读性，有利于程序的修改、调试和交流。注释的内容在程序编译的时候会被忽视，不会产生目标代码，注释的部分不会对程序的执行结果产生任何影响。 1注意事项：多行和文档注释都不能嵌套使用。 访问修饰符访问修饰符 public,private,protected,以及不写（默认）时的区别 定义：Java中，可以使用访问修饰符来保护对类、变量、方法和构造方法的访问。Java 支持 4 种不同的访问权限。 分类 private : 在同一类内可见。使用对象：变量、方法。 注意：不能修饰类（外部类） default (即缺省，什么也不写，不使用任何关键字）: 在同一包内可见，不使用任何修饰符。使用对象：类、接口、变量、方法。 protected : 对同一包内的类和所有子类可见。使用对象：变量、方法。 注意：不能修饰类（外部类）。 public : 对所有类可见。使用对象：类、接口、变量、方法 访问修饰符图 运算符&amp;和&amp;&amp;的区别 &amp;运算符有两种用法：(1)按位与；(2)逻辑与。 &amp;&amp;运算符是短路与运算。逻辑与跟短路与的差别是非常巨大的，虽然二者都要求运算符左右两端的布尔值都是true 整个表达式的值才是 true。&amp;&amp;之所以称为短路运算，是因为如果&amp;&amp;左边的表达式的值是 false，右边的表达式会被直接短路掉，不会进行运算。 1注意：逻辑或运算符（|）和短路或运算符（||）的差别也是如此。 关键字Java 有没有 goto goto 是 Java 中的保留字，在目前版本的 Java 中没有使用。 final 有什么用？1用于修饰类、属性和方法； 被final修饰的类不可以被继承 被final修饰的方法不可以被重写 被final修饰的变量不可以被改变，被final修饰不可变的是变量的引用，而不是引用指向的内容，引用指向的内容是可以改变的 final finally finalize区别 final可以修饰类、变量、方法，修饰类表示该类不能被继承、修饰方法表示该方法不能被重写、修饰变量表 示该变量是一个常量不能被重新赋值。 finally一般作用在try-catch代码块中，在处理异常的时候，通常我们将一定要执行的代码方法finally代码块 中，表示不管是否出现异常，该代码块都会执行，一般用来存放一些关闭资源的代码。 finalize是一个方法，属于Object类的一个方法，而Object类是所有类的父类，该方法一般由垃圾回收器来调 用，当我们调用System.gc() 方法的时候，由垃圾回收器调用finalize()，回收垃圾，一个对象是否可回收的 最后判断。 this关键字的用法 this是自身的一个对象，代表对象本身，可以理解为：指向对象本身的一个指针。 this的用法在java中大体可以分为3种： 1.普通的直接引用，this相当于是指向当前对象本身。 2.形参与成员名字重名，用this来区分： 12345public Person(String name, int age) &#123; this.name = name; this.age = age;&#125;复制代码 3.引用本类的构造函数 12345678910111213141516class Person&#123; private String name; private int age; public Person() &#123; &#125; public Person(String name) &#123; this.name = name; &#125; public Person(String name, int age) &#123; this(name); this.age = age; &#125;&#125;复制代码 super关键字的用法 super可以理解为是指向自己超（父）类对象的一个指针，而这个超类指的是离自己最近的一个父类。 super也有三种用法： 1.普通的直接引用 与this类似，super相当于是指向当前对象的父类的引用，这样就可以用super.xxx来引用父类的成员。 2.子类中的成员变量或方法与父类中的成员变量或方法同名时，用super进行区分 1234567891011121314151617181920212223242526272829303132class Person&#123; protected String name; public Person(String name) &#123; this.name = name; &#125; &#125; class Student extends Person&#123; private String name; public Student(String name, String name1) &#123; super(name); this.name = name1; &#125; public void getInfo()&#123; System.out.println(this.name); //Child System.out.println(super.name); //Father &#125; &#125;public class Test &#123; public static void main(String[] args) &#123; Student s1 = new Student(&quot;Father&quot;,&quot;Child&quot;); s1.getInfo(); &#125;&#125;复制代码 3.引用父类构造函数 super（参数）：调用父类中的某一个构造函数（应该为构造函数中的第一条语句）。 this（参数）：调用本类中另一种形式的构造函数（应该为构造函数中的第一条语句）。 this与super的区别 super: 它引用当前对象的直接父类中的成员（用来访问直接父类中被隐藏的父类中成员数据或函数，基类与派生类中有相同成员定义时如：super.变量名 super.成员函数据名（实参） this：它代表当前对象名（在程序中易产生二义性之处，应使用this来指明当前对象；如果函数的形参与类中的成员数据同名，这时需用this来指明成员变量名） super()和this()类似,区别是，super()在子类中调用父类的构造方法，this()在本类内调用本类的其它构造方法。 super()和this()均需放在构造方法内第一行。 尽管可以用this调用一个构造器，但却不能调用两个。 this和super不能同时出现在一个构造函数里面，因为this必然会调用其它的构造函数，其它的构造函数必然也会有super语句的存在，所以在同一个构造函数里面有相同的语句，就失去了语句的意义，编译器也不会通过。 this()和super()都指的是对象，所以，均不可以在static环境中使用。包括：static变量,static方法，static语句块。 从本质上讲，this是一个指向本对象的指针, 然而super是一个Java关键字。 static存在的主要意义 static的主要意义是在于创建独立于具体对象的域变量或者方法。以致于即使没有创建对象，也能使用属性和调用方法！ static关键字还有一个比较关键的作用就是 用来形成静态代码块以优化程序性能。static块可以置于类中的任何地方，类中可以有多个static块。在类初次被加载的时候，会按照static块的顺序来执行每个static块，并且只会执行一次。 为什么说static块可以用来优化程序性能，是因为它的特性:只会在类加载的时候执行一次。因此，很多时候会将一些只需要进行一次的初始化操作都放在static代码块中进行。 static的独特之处 1、被static修饰的变量或者方法是独立于该类的任何对象，也就是说，这些变量和方法不属于任何一个实例对象，而是被类的实例对象所共享。 怎么理解 “被类的实例对象所共享” 这句话呢？就是说，一个类的静态成员，它是属于大伙的【大伙指的是这个类的多个对象实例，我们都知道一个类可以创建多个实例！】，所有的类对象共享的，不像成员变量是自个的【自个指的是这个类的单个实例对象】…我觉得我已经讲的很通俗了，你明白了咩？ 2、在该类被第一次加载的时候，就会去加载被static修饰的部分，而且只在类第一次使用时加载并进行初始化，注意这是第一次用就要初始化，后面根据需要是可以再次赋值的。 3、static变量值在类加载的时候分配空间，以后创建类对象的时候不会重新分配。赋值的话，是可以任意赋值的！ 4、被static修饰的变量或者方法是优先于对象存在的，也就是说当一个类加载完毕之后，即便没有创建对象，也可以去访问。 static应用场景 因为static是被类的实例对象所共享，因此如果某个成员变量是被所有对象所共享的，那么这个成员变量就应该定义为静态变量。 因此比较常见的static应用场景有： 1、修饰成员变量 2、修饰成员方法 3、静态代码块 4、修饰类【只能修饰内部类也就是静态内部类】 5、静态导包 static注意事项 1、静态只能访问静态。 2、非静态既可以访问非静态的，也可以访问静态的。 流程控制语句break ,continue ,return 的区别及作用 break 跳出总上一层循环，不再执行循环(结束当前的循环体) continue 跳出本次循环，继续执行下次循环(结束正在执行的循环 进入下一个循环条件) return 程序返回，不再执行下面的代码(结束当前的方法 直接返回) 在 Java 中，如何跳出当前的多重嵌套循环 在Java中，要想跳出多重循环，可以在外面的循环语句前定义一个标号，然后在里层循环体的代码中使用带有标号的break 语句，即可跳出外层循环。例如： 123456789101112public static void main(String[] args) &#123; ok: for (int i = 0; i &lt; 10; i++) &#123; for (int j = 0; j &lt; 10; j++) &#123; System.out.println(&quot;i=&quot; + i + &quot;,j=&quot; + j); if (j == 5) &#123; break ok; &#125; &#125; &#125;&#125;复制代码 面向对象面向对象概述面向对象和面向过程的区别 面向过程： 优点：性能比面向对象高，因为类调用时需要实例化，开销比较大，比较消耗资源;比如单片机、嵌入式开发、Linux/Unix等一般采用面向过程开发，性能是最重要的因素。 缺点：没有面向对象易维护、易复用、易扩展 面向对象： 优点：易维护、易复用、易扩展，由于面向对象有封装、继承、多态性的特性，可以设计出低耦合的系统，使系统更加灵活、更加易于维护 缺点：性能比面向过程低 123面向过程是具体化的，流程化的，解决一个问题，你需要一步一步的分析，一步一步的实现。面向对象是模型化的，你只需抽象出一个类，这是一个封闭的盒子，在这里你拥有数据也拥有解决问题的方法。需要什么功能直接使用就可以了，不必去一步一步的实现，至于这个功能是如何实现的，管我们什么事？我们会用就可以了。面向对象的底层其实还是面向过程，把面向过程抽象成类，然后封装，方便我们使用的就是面向对象了。 面向对象三大特性面向对象的特征有哪些方面面向对象的特征主要有以下几个方面： 抽象：抽象是将一类对象的共同特征总结出来构造类的过程，包括数据抽象和行为抽象两方面。抽象只关注对象有哪些属性和行为，并不关注这些行为的细节是什么。 封装把一个对象的属性私有化，同时提供一些可以被外界访问的属性的方法，如果属性不想被外界访问，我们大可不必提供方法给外界访问。但是如果一个类没有提供给外界访问的方法，那么这个类也没有什么意义了。 继承是使用已存在的类的定义作为基础建立新类的技术，新类的定义可以增加新的数据或新的功能，也可以用父类的功能，但不能选择性地继承父类。通过使用继承我们能够非常方便地复用以前的代码。 关于继承如下 3 点请记住： 子类拥有父类非 private 的属性和方法。 子类可以拥有自己属性和方法，即子类可以对父类进行扩展。 子类可以用自己的方式实现父类的方法。（以后介绍）。 多态：父类或接口定义的引用变量可以指向子类或具体实现类的实例对象。提高了程序的拓展性。在Java中有两种形式可以实现多态：继承（多个子类对同一方法的重写）和接口（实现接口并覆盖接口中同一方法）。 什么是多态机制？Java语言是如何实现多态的？ 所谓多态就是指程序中定义的引用变量所指向的具体类型和通过该引用变量发出的方法调用在编程时并不确定，而是在程序运行期间才确定，即一个引用变量倒底会指向哪个类的实例对象，该引用变量发出的方法调用到底是哪个类中实现的方法，必须在由程序运行期间才能决定。因为在程序运行时才确定具体的类，这样，不用修改源程序代码，就可以让引用变量绑定到各种不同的类实现上，从而导致该引用调用的具体方法随之改变，即不修改程序代码就可以改变程序运行时所绑定的具体代码，让程序可以选择多个运行状态，这就是多态性。 多态分为编译时多态和运行时多态。其中编辑时多态是静态的，主要是指方法的重载，它是根据参数列表的不同来区分不同的函数，通过编辑之后会变成两个不同的函数，在运行时谈不上多态。而运行时多态是动态的，它是通过动态绑定来实现的，也就是我们所说的多态性。 多态的实现 Java实现多态有三个必要条件：继承、重写、向上转型。 继承：在多态中必须存在有继承关系的子类和父类。 重写：子类对父类中某些方法进行重新定义，在调用这些方法时就会调用子类的方法。 向上转型：在多态中需要将子类的引用赋给父类对象，只有这样该引用才能够具备技能调用父类的方法和子类的方法。 12只有满足了上述三个条件，我们才能够在同一个继承结构中使用统一的逻辑实现代码处理不同的对象，从而达到执行不同的行为。对于Java而言，它多态的实现机制遵循一个原则：当超类对象引用变量引用子类对象时，被引用对象的类型而不是引用变量的类型决定了调用谁的成员方法，但是这个被调用的方法必须是在超类中定义过的，也就是说被子类覆盖的方法。 面向对象五大基本原则是什么（可选） 单一职责原则SRP(Single Responsibility Principle) 类的功能要单一，不能包罗万象，跟杂货铺似的。 开放封闭原则OCP(Open－Close Principle) 一个模块对于拓展是开放的，对于修改是封闭的，想要增加功能热烈欢迎，想要修改，哼，一万个不乐意。 里式替换原则LSP(the Liskov Substitution Principle LSP) 子类可以替换父类出现在父类能够出现的任何地方。比如你能代表你爸去你姥姥家干活。哈哈~~ 依赖倒置原则DIP(the Dependency Inversion Principle DIP) 高层次的模块不应该依赖于低层次的模块，他们都应该依赖于抽象。抽象不应该依赖于具体实现，具体实现应该依赖于抽象。就是你出国要说你是中国人，而不能说你是哪个村子的。比如说中国人是抽象的，下面有具体的xx省，xx市，xx县。你要依赖的抽象是中国人，而不是你是xx村的。 接口分离原则ISP(the Interface Segregation Principle ISP) 设计时采用多个与特定客户类有关的接口比采用一个通用的接口要好。就比如一个手机拥有打电话，看视频，玩游戏等功能，把这几个功能拆分成不同的接口，比在一个接口里要好的多。 类与接口抽象类和接口的对比 抽象类是用来捕捉子类的通用特性的。接口是抽象方法的集合。 从设计层面来说，抽象类是对类的抽象，是一种模板设计，接口是行为的抽象，是一种行为的规范。 相同点 接口和抽象类都不能实例化 都位于继承的顶端，用于被其他实现或继承 都包含抽象方法，其子类都必须覆写这些抽象方法 不同点 参数 抽象类 接口 声明 抽象类使用abstract关键字声明 接口使用interface关键字声明 实现 子类使用extends关键字来继承抽象类。如果子类不是抽象类的话，它需要提供抽象类中所有声明的方法的实现 子类使用implements关键字来实现接口。它需要提供接口中所有声明的方法的实现 构造器 抽象类可以有构造器 接口不能有构造器 访问修饰符 抽象类中的方法可以是任意访问修饰符 接口方法默认修饰符是public。并且不允许定义为 private 或者 protected 多继承 一个类最多只能继承一个抽象类 一个类可以实现多个接口 字段声明 抽象类的字段声明可以是任意的 接口的字段默认都是 static 和 final 的 备注：Java8中接口中引入默认方法和静态方法，以此来减少抽象类和接口之间的差异。 1现在，我们可以为接口提供默认实现的方法了，并且不用强制子类来实现它。 接口和抽象类各有优缺点，在接口和抽象类的选择上，必须遵守这样一个原则： 行为模型应该总是通过接口而不是抽象类定义，所以通常是优先选用接口，尽量少用抽象类。 选择抽象类的时候通常是如下情况：需要定义子类的行为，又要为子类提供通用的功能。 普通类和抽象类有哪些区别？ 普通类不能包含抽象方法，抽象类可以包含抽象方法。 抽象类不能直接实例化，普通类可以直接实例化。 抽象类能使用 final 修饰吗？ 不能，定义抽象类就是让其他类继承的，如果定义为 final 该类就不能被继承，这样彼此就会产生矛盾，所以 final 不能修饰抽象类 创建一个对象用什么关键字？对象实例与对象引用有何不同？ new关键字，new创建对象实例（对象实例在堆内存中），对象引用指向对象实例（对象引用存放在栈内存中）。一个对象引用可以指向0个或1个对象（一根绳子可以不系气球，也可以系一个气球）;一个对象可以有n个引用指向它（可以用n条绳子系住一个气球） 变量与方法成员变量与局部变量的区别有哪些 变量：在程序执行的过程中，在某个范围内其值可以发生改变的量。从本质上讲，变量其实是内存中的一小块区域 成员变量：方法外部，类内部定义的变量 局部变量：类的方法中的变量。 成员变量和局部变量的区别 作用域 成员变量：针对整个类有效。 局部变量：只在某个范围内有效。(一般指的就是方法,语句体内) 存储位置 成员变量：随着对象的创建而存在，随着对象的消失而消失，存储在堆内存中。 局部变量：在方法被调用，或者语句被执行的时候存在，存储在栈内存中。当方法调用完，或者语句结束后，就自动释放。 生命周期 成员变量：随着对象的创建而存在，随着对象的消失而消失 局部变量：当方法调用完，或者语句结束后，就自动释放。 初始值 成员变量：有默认初始值。 局部变量：没有默认初始值，使用前必须赋值。 在Java中定义一个不做事且没有参数的构造方法的作用 Java程序在执行子类的构造方法之前，如果没有用super()来调用父类特定的构造方法，则会调用父类中“没有参数的构造方法”。因此，如果父类中只定义了有参数的构造方法，而在子类的构造方法中又没有用super()来调用父类中特定的构造方法，则编译时将发生错误，因为Java程序在父类中找不到没有参数的构造方法可供执行。解决办法是在父类里加上一个不做事且没有参数的构造方法。 在调用子类构造方法之前会先调用父类没有参数的构造方法，其目的是？ 帮助子类做初始化工作。 一个类的构造方法的作用是什么？若一个类没有声明构造方法，改程序能正确执行吗？为什么？ 主要作用是完成对类对象的初始化工作。可以执行。因为一个类即使没有声明构造方法也会有默认的不带参数的构造方法。 构造方法有哪些特性？ 名字与类名相同； 没有返回值，但不能用void声明构造函数； 生成类的对象时自动执行，无需调用。 静态变量和实例变量区别 静态变量： 静态变量由于不属于任何实例对象，属于类的，所以在内存中只会有一份，在类的加载过程中，JVM只为静态变量分配一次内存空间。 实例变量： 每次创建对象，都会为每个对象分配成员变量内存空间，实例变量是属于实例对象的，在内存中，创建几次对象，就有几份成员变量。 静态变量与普通变量区别 static变量也称作静态变量，静态变量和非静态变量的区别是：静态变量被所有的对象所共享，在内存中只有一个副本，它当且仅当在类初次加载时会被初始化。而非静态变量是对象所拥有的，在创建对象的时候被初始化，存在多个副本，各个对象拥有的副本互不影响。 还有一点就是static成员变量的初始化顺序按照定义的顺序进行初始化。 静态方法和实例方法有何不同？1静态方法和实例方法的区别主要体现在两个方面： 在外部调用静态方法时，可以使用”类名.方法名”的方式，也可以使用”对象名.方法名”的方式。而实例方法只有后面这种方式。也就是说，调用静态方法可以无需创建对象。 静态方法在访问本类的成员时，只允许访问静态成员（即静态成员变量和静态方法），而不允许访问实例成员变量和实例方法；实例方法则无此限制 在一个静态方法内调用一个非静态成员为什么是非法的？ 由于静态方法可以不通过对象进行调用，因此在静态方法里，不能调用其他非静态变量，也不可以访问非静态变量成员。 什么是方法的返回值？返回值的作用是什么？ 方法的返回值是指我们获取到的某个方法体中的代码执行后产生的结果！（前提是该方法可能产生结果）。返回值的作用:接收出结果，使得它可以用于其他的操作！ 内部类什么是内部类？ 在Java中，可以将一个类的定义放在另外一个类的定义内部，这就是内部类。内部类本身就是类的一个属性，与其他属性定义方式一致。 内部类的分类有哪些1内部类可以分为四种：**成员内部类、局部内部类、匿名内部类和静态内部类**。 静态内部类 定义在类内部的静态类，就是静态内部类。 1234567891011public class Outer &#123; private static int radius = 1; static class StaticInner &#123; public void visit() &#123; System.out.println(&quot;visit outer static variable:&quot; + radius); &#125; &#125;&#125;复制代码 静态内部类可以访问外部类所有的静态变量，而不可访问外部类的非静态变量；静态内部类的创建方式，new 外部类.静态内部类()，如下： 123Outer.StaticInner inner = new Outer.StaticInner();inner.visit();复制代码 成员内部类 定义在类内部，成员位置上的非静态类，就是成员内部类。 12345678910111213public class Outer &#123; private static int radius = 1; private int count =2; class Inner &#123; public void visit() &#123; System.out.println(&quot;visit outer static variable:&quot; + radius); System.out.println(&quot;visit outer variable:&quot; + count); &#125; &#125;&#125;复制代码 成员内部类可以访问外部类所有的变量和方法，包括静态和非静态，私有和公有。成员内部类依赖于外部类的实例，它的创建方式外部类实例.new 内部类()，如下： 1234Outer outer = new Outer();Outer.Inner inner = outer.new Inner();inner.visit();复制代码 局部内部类 定义在方法中的内部类，就是局部内部类。 12345678910111213141516171819202122232425262728293031public class Outer &#123; private int out_a = 1; private static int STATIC_b = 2; public void testFunctionClass()&#123; int inner_c =3; class Inner &#123; private void fun()&#123; System.out.println(out_a); System.out.println(STATIC_b); System.out.println(inner_c); &#125; &#125; Inner inner = new Inner(); inner.fun(); &#125; public static void testStaticFunctionClass()&#123; int d =3; class Inner &#123; private void fun()&#123; // System.out.println(out_a); 编译错误，定义在静态方法中的局部类不可以访问外部类的实例变量 System.out.println(STATIC_b); System.out.println(d); &#125; &#125; Inner inner = new Inner(); inner.fun(); &#125;&#125;复制代码 定义在实例方法中的局部类可以访问外部类的所有变量和方法，定义在静态方法中的局部类只能访问外部类的静态变量和方法。局部内部类的创建方式，在对应方法内，new 内部类()，如下： 123456public static void testStaticFunctionClass()&#123; class Inner &#123; &#125; Inner inner = new Inner(); &#125;复制代码 匿名内部类 匿名内部类就是没有名字的内部类，日常开发中使用的比较多。 1234567891011121314151617public class Outer &#123; private void test(final int i) &#123; new Service() &#123; public void method() &#123; for (int j = 0; j &lt; i; j++) &#123; System.out.println(&quot;匿名内部类&quot; ); &#125; &#125; &#125;.method(); &#125; &#125; //匿名内部类必须继承或实现一个已有的接口 interface Service&#123; void method();&#125;复制代码 除了没有名字，匿名内部类还有以下特点： 匿名内部类必须继承一个抽象类或者实现一个接口。 匿名内部类不能定义任何静态成员和静态方法。 当所在的方法的形参需要被匿名内部类使用时，必须声明为 final。 匿名内部类不能是抽象的，它必须要实现继承的类或者实现的接口的所有抽象方法。 匿名内部类创建方式： 1234new 类/接口&#123; //匿名内部类实现部分&#125;复制代码 内部类的优点1我们为什么要使用内部类呢？因为它有以下优点： 一个内部类对象可以访问创建它的外部类对象的内容，包括私有数据！ 内部类不为同一包的其他类所见，具有很好的封装性； 内部类有效实现了“多重继承”，优化 java 单继承的缺陷。 匿名内部类可以很方便的定义回调。 内部类有哪些应用场景 一些多算法场合 解决一些非面向对象的语句块。 适当使用内部类，使得代码更加灵活和富有扩展性。 当某个类除了它的外部类，不再被其他的类使用时。 局部内部类和匿名内部类访问局部变量的时候，为什么变量必须要加上final？ 局部内部类和匿名内部类访问局部变量的时候，为什么变量必须要加上final呢？它内部原理是什么呢？先看这段代码： 123456789101112public class Outer &#123; void outMethod()&#123; final int a =10; class Inner &#123; void innerMethod()&#123; System.out.println(a); &#125; &#125; &#125;&#125;复制代码 以上例子，为什么要加final呢？是因为生命周期不一致， 局部变量直接存储在栈中，当方法执行结束后，非final的局部变量就被销毁。而局部内部类对局部变量的引用依然存在，如果局部内部类要调用局部变量时，就会出错。加了final，可以确保局部内部类使用的变量与外层的局部变量区分开，解决了这个问题。 内部类相关，看程序说出运行结果1234567891011121314151617181920public class Outer &#123; private int age = 12; class Inner &#123; private int age = 13; public void print() &#123; int age = 14; System.out.println(&quot;局部变量：&quot; + age); System.out.println(&quot;内部类变量：&quot; + this.age); System.out.println(&quot;外部类变量：&quot; + Outer.this.age); &#125; &#125; public static void main(String[] args) &#123; Outer.Inner in = new Outer().new Inner(); in.print(); &#125;&#125;复制代码 运行结果： 1234局部变量：14内部类变量：13外部类变量：12复制代码 重写与重载构造器（constructor）是否可被重写（override） 构造器不能被继承，因此不能被重写，但可以被重载。 重载（Overload）和重写（Override）的区别。重载的方法能否根据返回类型进行区分？ 方法的重载和重写都是实现多态的方式，区别在于前者实现的是编译时的多态性，而后者实现的是运行时的多态性。 重载：发生在同一个类中，方法名相同参数列表不同（参数类型不同、个数不同、顺序不同），与方法返回值和访问修饰符无关，即重载的方法不能根据返回类型进行区分 重写：发生在父子类中，方法名、参数列表必须相同，返回值小于等于父类，抛出的异常小于等于父类，访问修饰符大于等于父类（里氏代换原则）；如果父类方法访问修饰符为private则子类中就不是重写。 对象相等判断== 和 equals 的区别是什么 == : 它的作用是判断两个对象的地址是不是相等。即，判断两个对象是不是同一个对象。(基本数据类型 == 比较的是值，引用数据类型 == 比较的是内存地址) equals() : 它的作用也是判断两个对象是否相等。但它一般有两种使用情况： 情况1：类没有覆盖 equals() 方法。则通过 equals() 比较该类的两个对象时，等价于通过“==”比较这两个对象。 情况2：类覆盖了 equals() 方法。一般，我们都覆盖 equals() 方法来两个对象的内容相等；若它们的内容相等，则返回 true (即，认为这两个对象相等)。 举个例子： 123456789101112131415161718public class test1 &#123; public static void main(String[] args) &#123; String a = new String(&quot;ab&quot;); // a 为一个引用 String b = new String(&quot;ab&quot;); // b为另一个引用,对象的内容一样 String aa = &quot;ab&quot;; // 放在常量池中 String bb = &quot;ab&quot;; // 从常量池中查找 if (aa == bb) // true System.out.println(&quot;aa==bb&quot;); if (a == b) // false，非同一对象 System.out.println(&quot;a==b&quot;); if (a.equals(b)) // true System.out.println(&quot;aEQb&quot;); if (42 == 42.0) &#123; // true System.out.println(&quot;true&quot;); &#125; &#125;&#125;复制代码 说明： String中的equals方法是被重写过的，因为object的equals方法是比较的对象的内存地址，而String的equals方法比较的是对象的值。 当创建String类型的对象时，虚拟机会在常量池中查找有没有已经存在的值和要创建的值相同的对象，如果有就把它赋给当前引用。如果没有就在常量池中重新创建一个String对象。 hashCode 与 equals (重要) HashSet如何检查重复 两个对象的 hashCode() 相同，则 equals() 也一定为 true，对吗？ hashCode和equals方法的关系 面试官可能会问你：“你重写过 hashcode 和 equals 么，为什么重写equals时必须重写hashCode方法？” hashCode()介绍 hashCode() 的作用是获取哈希码，也称为散列码；它实际上是返回一个int整数。这个哈希码的作用是确定该对象在哈希表中的索引位置。hashCode() 定义在JDK的Object.java中，这就意味着Java中的任何类都包含有hashCode()函数。 散列表存储的是键值对(key-value)，它的特点是：能根据“键”快速的检索出对应的“值”。这其中就利用到了散列码！（可以快速找到所需要的对象） 为什么要有 hashCode 1我们以“HashSet 如何检查重复”为例子来说明为什么要有 hashCode： 当你把对象加入 HashSet 时，HashSet 会先计算对象的 hashcode 值来判断对象加入的位置，同时也会与其他已经加入的对象的 hashcode 值作比较，如果没有相符的hashcode，HashSet会假设对象没有重复出现。但是如果发现有相同 hashcode 值的对象，这时会调用 equals()方法来检查 hashcode 相等的对象是否真的相同。如果两者相同，HashSet 就不会让其加入操作成功。如果不同的话，就会重新散列到其他位置。（摘自我的Java启蒙书《Head first java》第二版）。这样我们就大大减少了 equals 的次数，相应就大大提高了执行速度。 hashCode()与equals()的相关规定 如果两个对象相等，则hashcode一定也是相同的 两个对象相等，对两个对象分别调用equals方法都返回true 两个对象有相同的hashcode值，它们也不一定是相等的 12因此，equals 方法被覆盖过，则 hashCode 方法也必须被覆盖hashCode() 的默认行为是对堆上的对象产生独特值。如果没有重写 hashCode()，则该 class 的两个对象无论如何都不会相等（即使这两个对象指向相同的数据） 对象的相等与指向他们的引用相等，两者有什么不同？ 对象的相等 比的是内存中存放的内容是否相等而 引用相等 比较的是他们指向的内存地址是否相等。 值传递当一个对象被当作参数传递到一个方法后，此方法可改变这个对象的属性，并可返回变化后的结果，那么这里到底是值传递还是引用传递 是值传递。Java 语言的方法调用只支持参数的值传递。当一个对象实例作为一个参数被传递到方法中时，参数的值就是对该对象的引用。对象的属性可以在被调用过程中被改变，但对对象引用的改变是不会影响到调用者的 为什么 Java 中只有值传递 首先回顾一下在程序设计语言中有关将参数传递给方法（或函数）的一些专业术语。按值调用(call by value)表示方法接收的是调用者提供的值，而按引用调用（call by reference)表示方法接收的是调用者提供的变量地址。一个方法可以修改传递引用所对应的变量值，而不能修改传递值调用所对应的变量值。 它用来描述各种程序设计语言（不只是Java)中方法参数传递方式。 Java程序设计语言总是采用按值调用。也就是说，方法得到的是所有参数值的一个拷贝，也就是说，方法不能修改传递给它的任何参数变量的内容。 下面通过 3 个例子来给大家说明 example 112345678910111213141516171819public static void main(String[] args) &#123; int num1 = 10; int num2 = 20; swap(num1, num2); System.out.println(&quot;num1 = &quot; + num1); System.out.println(&quot;num2 = &quot; + num2);&#125;public static void swap(int a, int b) &#123; int temp = a; a = b; b = temp; System.out.println(&quot;a = &quot; + a); System.out.println(&quot;b = &quot; + b);&#125;复制代码 结果： a = 20 b = 10 num1 = 10 num2 = 20 解析： 在swap方法中，a、b的值进行交换，并不会影响到 num1、num2。因为，a、b中的值，只是从 num1、num2 的复制过来的。也就是说，a、b相当于num1、num2 的副本，副本的内容无论怎么修改，都不会影响到原件本身。 1通过上面例子，我们已经知道了一个方法不能修改一个基本数据类型的参数，而对象引用作为参数就不一样，请看 example. example 2123456789101112 public static void main(String[] args) &#123; int[] arr = &#123; 1, 2, 3, 4, 5 &#125;; System.out.println(arr[0]); change(arr); System.out.println(arr[0]); &#125; public static void change(int[] array) &#123; // 将数组的第一个元素变为0 array[0] = 0; &#125;复制代码 结果： 1 0 解析： array 被初始化 arr 的拷贝也就是一个对象的引用，也就是说 array 和 arr 指向的时同一个数组对象。 因此，外部对引用对象的改变会反映到所对应的对象上。 12通过 example2 我们已经看到，实现一个改变对象参数状态的方法并不是一件难事。理由很简单，方法得到的是对象引用的拷贝，对象引用及其他的拷贝同时引用同一个对象。很多程序设计语言（特别是，C++和Pascal)提供了两种参数传递的方式：值调用和引用调用。有些程序员（甚至本书的作者）认为Java程序设计语言对对象采用的是引用调用，实际上，这种理解是不对的。由于这种误解具有一定的普遍性，所以下面给出一个反例来详细地阐述一下这个问题。 example 31234567891011121314151617181920public class Test &#123; public static void main(String[] args) &#123; // TODO Auto-generated method stub Student s1 = new Student(&quot;小张&quot;); Student s2 = new Student(&quot;小李&quot;); Test.swap(s1, s2); System.out.println(&quot;s1:&quot; + s1.getName()); System.out.println(&quot;s2:&quot; + s2.getName()); &#125; public static void swap(Student x, Student y) &#123; Student temp = x; x = y; y = temp; System.out.println(&quot;x:&quot; + x.getName()); System.out.println(&quot;y:&quot; + y.getName()); &#125;&#125;复制代码 结果： x:小李 y:小张 s1:小张 s2:小李 解析： 交换之前： 交换之后： 通过上面两张图可以很清晰的看出：方法并没有改变存储在变量 s1 和 s2 中的对象引用。swap方法的参数x和y被初始化为两个对象引用的拷贝，这个方法交换的是这两个拷贝 总结 Java程序设计语言对对象采用的不是引用调用，实际上，对象引用是按值传递的。 下面再总结一下Java中方法参数的使用情况： 一个方法不能修改一个基本数据类型的参数（即数值型或布尔型》 一个方法可以改变一个对象参数的状态。 一个方法不能让对象参数引用一个新的对象。 值传递和引用传递有什么区别 值传递：指的是在方法调用时，传递的参数是按值的拷贝传递，传递的是值的拷贝，也就是说传递后就互不相关了。 引用传递：指的是在方法调用时，传递的参数是按引用进行传递，其实传递的引用的地址，也就是变量所对应的内存空间的地址。传递的是值的引用，也就是说传递前和传递后都指向同一个引用（也就是同一个内存空间）。 Java包JDK 中常用的包有哪些 java.lang：这个是系统的基础类； java.io：这里面是所有输入输出有关的类，比如文件操作等； java.nio：为了完善 io 包中的功能，提高 io 包中性能而写的一个新包； java.net：这里面是与网络有关的类； java.util：这个是系统辅助类，特别是集合类； java.sql：这个是数据库操作的类。 import java和javax有什么区别 刚开始的时候 JavaAPI 所必需的包是 java 开头的包，javax 当时只是扩展 API 包来说使用。然而随着时间的推移，javax 逐渐的扩展成为 Java API 的组成部分。但是，将扩展从 javax 包移动到 java 包将是太麻烦了，最终会破坏一堆现有的代码。因此，最终决定 javax 包将成为标准API的一部分。 1所以，实际上java和javax没有区别。这都是一个名字。 IO流java 中 IO 流分为几种? 按照流的流向分，可以分为输入流和输出流； 按照操作单元划分，可以划分为字节流和字符流； 按照流的角色划分为节点流和处理流。 1Java Io流共涉及40多个类，这些类看上去很杂乱，但实际上很有规则，而且彼此之间存在非常紧密的联系， Java I0流的40多个类都是从如下4个抽象类基类中派生出来的。 InputStream/Reader: 所有的输入流的基类，前者是字节输入流，后者是字符输入流。 OutputStream/Writer: 所有输出流的基类，前者是字节输出流，后者是字符输出流。 1按操作方式分类结构图： 在这里插入图片描述 1按操作对象分类结构图： 在这里插入图片描述 BIO,NIO,AIO 有什么区别? 简答 BIO：Block IO 同步阻塞式 IO，就是我们平常使用的传统 IO，它的特点是模式简单使用方便，并发处理能力低。 NIO：Non IO 同步非阻塞 IO，是传统 IO 的升级，客户端和服务器端通过 Channel（通道）通讯，实现了多路复用。 AIO：Asynchronous IO 是 NIO 的升级，也叫 NIO2，实现了异步非堵塞 IO ，异步 IO 的操作基于事件和回调机制。 详细回答 BIO (Blocking I/O): 同步阻塞I/O模式，数据的读取写入必须阻塞在一个线程内等待其完成。在活动连接数不是特别高（小于单机1000）的情况下，这种模型是比较不错的，可以让每一个连接专注于自己的 I/O 并且编程模型简单，也不用过多考虑系统的过载、限流等问题。线程池本身就是一个天然的漏斗，可以缓冲一些系统处理不了的连接或请求。但是，当面对十万甚至百万级连接的时候，传统的 BIO 模型是无能为力的。因此，我们需要一种更高效的 I/O 处理模型来应对更高的并发量。 NIO (New I/O): NIO是一种同步非阻塞的I/O模型，在Java 1.4 中引入了NIO框架，对应 java.nio 包，提供了 Channel , Selector，Buffer等抽象。NIO中的N可以理解为Non-blocking，不单纯是New。它支持面向缓冲的，基于通道的I/O操作方法。 NIO提供了与传统BIO模型中的 Socket 和 ServerSocket 相对应的 SocketChannel 和 ServerSocketChannel 两种不同的套接字通道实现,两种通道都支持阻塞和非阻塞两种模式。阻塞模式使用就像传统中的支持一样，比较简单，但是性能和可靠性都不好；非阻塞模式正好与之相反。对于低负载、低并发的应用程序，可以使用同步阻塞I/O来提升开发速率和更好的维护性；对于高负载、高并发的（网络）应用，应使用 NIO 的非阻塞模式来开发 AIO (Asynchronous I/O): AIO 也就是 NIO 2。在 Java 7 中引入了 NIO 的改进版 NIO 2,它是异步非阻塞的IO模型。异步 IO 是基于事件和回调机制实现的，也就是应用操作之后会直接返回，不会堵塞在那里，当后台处理完成，操作系统会通知相应的线程进行后续的操作。AIO 是异步IO的缩写，虽然 NIO 在网络操作中，提供了非阻塞的方法，但是 NIO 的 IO 行为还是同步的。对于 NIO 来说，我们的业务线程是在 IO 操作准备好时，得到通知，接着就由这个线程自行进行 IO 操作，IO操作本身是同步的。查阅网上相关资料，我发现就目前来说 AIO 的应用还不是很广泛，Netty 之前也尝试使用过 AIO，不过又放弃了。 Files的常用方法都有哪些？ Files. exists()：检测文件路径是否存在。 Files. createFile()：创建文件。 Files. createDirectory()：创建文件夹。 Files. delete()：删除一个文件或目录。 Files. copy()：复制文件。 Files. move()：移动文件。 Files. size()：查看文件个数。 Files. read()：读取文件。 Files. write()：写入文件。 反射什么是反射机制？ JAVA反射机制是在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意一个方法和属性；这种动态获取的信息以及动态调用对象的方法的功能称为java语言的反射机制。 静态编译和动态编译 静态编译：在编译时确定类型，绑定对象 动态编译：运行时确定类型，绑定对象 反射机制优缺点 优点： 运行期类型的判断，动态加载类，提高代码灵活度。 缺点： 性能瓶颈：反射相当于一系列解释操作，通知 JVM 要做的事情，性能比直接的java代码要慢很多。 反射机制的应用场景有哪些？ 反射是框架设计的灵魂。 在我们平时的项目开发过程中，基本上很少会直接使用到反射机制，但这不能说明反射机制没有用，实际上有很多设计、开发都与反射机制有关，例如模块化的开发，通过反射去调用对应的字节码；动态代理设计模式也采用了反射机制，还有我们日常使用的 Spring／Hibernate 等框架也大量使用到了反射机制。 举例：①我们在使用JDBC连接数据库时使用Class.forName()通过反射加载数据库的驱动程序；②Spring框架也用到很多反射机制，最经典的就是xml的配置模式。Spring 通过 XML 配置模式装载 Bean 的过程：1) 将程序内所有 XML 或 Properties 配置文件加载入内存中; 2)Java类里面解析xml或properties里面的内容，得到对应实体类的字节码字符串以及相关的属性信息; 3)使用反射机制，根据这个字符串获得某个类的Class实例; 4)动态配置实例的属性 Java获取反射的三种方法1.通过new对象实现反射机制 2.通过路径实现反射机制 3.通过类名实现反射机制 123456789101112131415161718192021222324public class Student &#123; private int id; String name; protected boolean sex; public float score;&#125;public class Get &#123; //获取反射机制三种方式 public static void main(String[] args) throws ClassNotFoundException &#123; //方式一(通过建立对象) Student stu = new Student(); Class classobj1 = stu.getClass(); System.out.println(classobj1.getName()); //方式二（所在通过路径-相对路径） Class classobj2 = Class.forName(&quot;fanshe.Student&quot;); System.out.println(classobj2.getName()); //方式三（通过类名） Class classobj3 = Student.class; System.out.println(classobj3.getName()); &#125;&#125;复制代码 常用APIString相关字符型常量和字符串常量的区别 形式上: 字符常量是单引号引起的一个字符 字符串常量是双引号引起的若干个字符 含义上: 字符常量相当于一个整形值(ASCII值),可以参加表达式运算 字符串常量代表一个地址值(该字符串在内存中存放位置) 占内存大小 字符常量只占一个字节 字符串常量占若干个字节(至少一个字符结束标志) 什么是字符串常量池？ 字符串常量池位于堆内存中，专门用来存储字符串常量，可以提高内存的使用率，避免开辟多块空间存储相同的字符串，在创建字符串时 JVM 会首先检查字符串常量池，如果该字符串已经存在池中，则返回它的引用，如果不存在，则实例化一个字符串放到池中，并返回其引用。 String 是最基本的数据类型吗 不是。Java 中的基本数据类型只有 8 个 ：byte、short、int、long、float、double、char、boolean；除了基本类型（primitive type），剩下的都是引用类型（referencetype），Java 5 以后引入的枚举类型也算是一种比较特殊的引用类型。 12这是很基础的东西，但是很多初学者却容易忽视，Java 的 8 种基本数据类型中不包括 String，基本数据类型中用来描述文本数据的是 char，但是它只能表示单个字符，比如 ‘a’,‘好’ 之类的，如果要描述一段文本，就需要用多个 char 类型的变量，也就是一个 char 类型数组，比如“你好” 就是长度为2的数组 char\\[\\] chars = &#123;‘你’,‘好’&#125;;但是使用数组过于麻烦，所以就有了 String，String 底层就是一个 char 类型的数组，只是使用的时候开发者不需要直接操作底层数组，用更加简便的方式即可完成对字符串的使用。 String有哪些特性 不变性：String 是只读字符串，是一个典型的 immutable 对象，对它进行任何操作，其实都是创建一个新的对象，再把引用指向该对象。不变模式的主要作用在于当一个对象需要被多线程共享并频繁访问时，可以保证数据的一致性。 常量池优化：String 对象创建之后，会在字符串常量池中进行缓存，如果下次创建同样的对象时，会直接返回缓存的引用。 final：使用 final 来定义 String 类，表示 String 类不能被继承，提高了系统的安全性。 String为什么是不可变的吗？ 简单来说就是String类利用了final修饰的char类型数组存储字符，源码如下图所以： /* The value is used for character storage. / private final char value[]; String真的是不可变的吗？ 我觉得如果别人问这个问题的话，回答不可变就可以了。 下面只是给大家看两个有代表性的例子： 1 String不可变但不代表引用不可以变 1234String str = &quot;Hello&quot;;str = str + &quot; World&quot;;System.out.println(&quot;str=&quot; + str);复制代码 结果： str=Hello World 解析： 实际上，原来String的内容是不变的，只是str由原来指向”Hello”的内存地址转为指向”Hello World”的内存地址而已，也就是说多开辟了一块内存区域给”Hello World”字符串。 2.通过反射是可以修改所谓的“不可变”对象 12345678910111213141516171819// 创建字符串&quot;Hello World&quot;， 并赋给引用sString s = &quot;Hello World&quot;;System.out.println(&quot;s = &quot; + s); // Hello World// 获取String类中的value字段Field valueFieldOfString = String.class.getDeclaredField(&quot;value&quot;);// 改变value属性的访问权限valueFieldOfString.setAccessible(true);// 获取s对象上的value属性的值char[] value = (char[]) valueFieldOfString.get(s);// 改变value所引用的数组中的第5个字符value[5] = &apos;_&apos;;System.out.println(&quot;s = &quot; + s); // Hello_World复制代码 结果： s = Hello World s = Hello_World 解析： 用反射可以访问私有成员， 然后反射出String对象中的value属性， 进而改变通过获得的value引用改变数组的结构。但是一般我们不会这么做，这里只是简单提一下有这个东西。 是否可以继承 String 类 String 类是 final 类，不可以被继承。 String str=”i”与 String str=new String(“i”)一样吗？ 不一样，因为内存的分配方式不一样。String str=”i”的方式，java 虚拟机会将其分配到常量池中；而 String str=new String(“i”) 则会被分到堆内存中。 String s = new String(“xyz”);创建了几个字符串对象 两个对象，一个是静态区的”xyz”，一个是用new创建在堆上的对象。 String str1 = “hello”; //str1指向静态区 String str2 = new String(“hello”); //str2指向堆上的对象 String str3 = “hello”; String str4 = new String(“hello”); System.out.println(str1.equals(str2)); //true System.out.println(str2.equals(str4)); //true System.out.println(str1 == str3); //true System.out.println(str1 == str2); //false System.out.println(str2 == str4); //false System.out.println(str2 == “hello”); //false str2 = str1; System.out.println(str2 == “hello”); //true 如何将字符串反转？ 使用 StringBuilder 或者 stringBuffer 的 reverse() 方法。 示例代码： // StringBuffer reverse StringBuffer stringBuffer = new StringBuffer(); stringBuffer. append(“abcdefg”); System. out. println(stringBuffer. reverse()); // gfedcba // StringBuilder reverse StringBuilder stringBuilder = new StringBuilder(); stringBuilder. append(“abcdefg”); System. out. println(stringBuilder. reverse()); // gfedcba 数组有没有 length()方法？String 有没有 length()方法 数组没有 length()方法 ，有 length 的属性。String 有 length()方法。JavaScript中，获得字符串的长度是通过 length 属性得到的，这一点容易和 Java 混淆。 String 类的常用方法都有那些？ indexOf()：返回指定字符的索引。 charAt()：返回指定索引处的字符。 replace()：字符串替换。 trim()：去除字符串两端空白。 split()：分割字符串，返回一个分割后的字符串数组。 getBytes()：返回字符串的 byte 类型数组。 length()：返回字符串长度。 toLowerCase()：将字符串转成小写字母。 toUpperCase()：将字符串转成大写字符。 substring()：截取字符串。 equals()：字符串比较。 在使用 HashMap 的时候，用 String 做 key 有什么好处？ HashMap 内部实现是通过 key 的 hashcode 来确定 value 的存储位置，因为字符串是不可变的，所以当创建字符串时，它的 hashcode 被缓存下来，不需要再次计算，所以相比于其他对象更快。 String和StringBuffer、StringBuilder的区别是什么？String为什么是不可变的可变性 String类中使用字符数组保存字符串，private final char value[]，所以string对象是不可变的。StringBuilder与StringBuffer都继承自AbstractStringBuilder类，在AbstractStringBuilder中也是使用字符数组保存字符串，char[] value，这两种对象都是可变的。 线程安全性 String中的对象是不可变的，也就可以理解为常量，线程安全。AbstractStringBuilder是StringBuilder与StringBuffer的公共父类，定义了一些字符串的基本操作，如expandCapacity、append、insert、indexOf等公共方法。StringBuffer对方法加了同步锁或者对调用的方法加了同步锁，所以是线程安全的。StringBuilder并没有对方法进行加同步锁，所以是非线程安全的。 性能 每次对String 类型进行改变的时候，都会生成一个新的String对象，然后将指针指向新的String 对象。StringBuffer每次都会对StringBuffer对象本身进行操作，而不是生成新的对象并改变对象引用。相同情况下使用StirngBuilder 相比使用StringBuffer 仅能获得10%~15% 左右的性能提升，但却要冒多线程不安全的风险。 对于三者使用的总结 如果要操作少量的数据用 = String 单线程操作字符串缓冲区 下操作大量数据 = StringBuilder 多线程操作字符串缓冲区 下操作大量数据 = StringBuffer Date相关包装类相关自动装箱与拆箱 装箱：将基本类型用它们对应的引用类型包装起来； 拆箱：将包装类型转换为基本数据类型； int 和 Integer 有什么区别 Java 是一个近乎纯洁的面向对象编程语言，但是为了编程的方便还是引入了基本数据类型，但是为了能够将这些基本数据类型当成对象操作，Java 为每一个基本数据类型都引入了对应的包装类型（wrapper class），int 的包装类就是 Integer，从 Java 5 开始引入了自动装箱/拆箱机制，使得二者可以相互转换。 Java 为每个原始类型提供了包装类型： 原始类型: boolean，char，byte，short，int，long，float，double 包装类型：Boolean，Character，Byte，Short，Integer，Long，Float，Double Integer a= 127 与 Integer b = 127相等吗 对于对象引用类型：==比较的是对象的内存地址。 对于基本数据类型：==比较的是值。 1234567891011121314151617如果整型字面量的值在-128到127之间，那么自动装箱时不会new新的Integer对象，而是直接引用常量池中的Integer对象，超过范围 a1==b1的结果是falsepublic static void main(String[] args) &#123; Integer a = new Integer(3); Integer b = 3; // 将3自动装箱成Integer类型 int c = 3; System.out.println(a == b); // false 两个引用没有引用同一对象 System.out.println(a == c); // true a自动拆箱成int类型再和c比较 System.out.println(b == c); // true Integer a1 = 128; Integer b1 = 128; System.out.println(a1 == b1); // false Integer a2 = 127; Integer b2 = 127; System.out.println(a2 == b2); // true&#125; 作者：小杰要吃蛋链接：https://juejin.cn/post/6844904127059738631来源：掘金著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。","tags":[{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"},{"name":"基础","slug":"基础","permalink":"https://lywlefan.github.io/tags/基础/"}]},{"title":"java集合面试必问问题","date":"2020-06-20T16:00:00.000Z","path":"2020/06/21/软件研发/后端/基础巩固/java/集合/java集合面试必问问题/","text":"集合容器概述什么是集合 集合就是一个放数据的容器，准确的说是放数据对象引用的容器 集合类存放的都是对象的引用，而不是对象的本身 集合类型主要有3种：set(集）、list(列表）和map(映射)。 集合的特点 集合的特点主要有如下两点： 集合用于存储对象的容器，对象是用来封装数据，对象多了也需要存储集中式管理。 和数组对比对象的大小不确定。因为集合是可变长度的。数组需要提前定义大小 集合和数组的区别 数组是固定长度的；集合可变长度的。 数组可以存储基本数据类型，也可以存储引用数据类型；集合只能存储引用数据类型。 数组存储的元素必须是同一个数据类型；集合存储的对象可以是不同数据类型。 使用集合框架的好处 容量自增长； 提供了高性能的数据结构和算法，使编码更轻松，提高了程序速度和质量； 可以方便地扩展或改写集合，提高代码复用性和可操作性。 通过使用JDK自带的集合类，可以降低代码维护和学习新API成本。 常用的集合类有哪些？ Map接口和Collection接口是所有集合框架的父接口： Collection接口的子接口包括：Set接口和List接口 Map接口的实现类主要有：HashMap、TreeMap、Hashtable、ConcurrentHashMap以及Properties等 Set接口的实现类主要有：HashSet、TreeSet、LinkedHashSet等 List接口的实现类主要有：ArrayList、LinkedList、Stack以及Vector等 List，Set，Map三者的区别？ Java 容器分为 Collection 和 Map 两大类，Collection集合的子接口有Set、List、Queue三种子接口。我们比较常用的是Set、List，Map接口不是collection的子接口。 Collection集合主要有List和Set两大接口 List：一个有序（元素存入集合的顺序和取出的顺序一致）容器，元素可以重复，可以插入多个null元素，元素都有索引。常用的实现类有 ArrayList、LinkedList 和 Vector。 Set：一个无序（存入和取出顺序有可能不一致）容器，不可以存储重复元素，只允许存入一个null元素，必须保证元素唯一性。Set 接口常用实现类是 HashSet、LinkedHashSet 以及 TreeSet。 Map是一个键值对集合，存储键、值和之间的映射。 Key无序，唯一；value 不要求有序，允许重复。Map没有继承于Collection接口，从Map集合中检索元素时，只要给出键对象，就会返回对应的值对象。 Map 的常用实现类：HashMap、TreeMap、HashTable、LinkedHashMap、ConcurrentHashMap 集合框架底层数据结构 Collection List Arraylist： Object数组 Vector： Object数组 LinkedList： 双向循环链表 Set HashSet（无序，唯一）：基于 HashMap 实现的，底层采用 HashMap 来保存元素 LinkedHashSet： LinkedHashSet 继承与 HashSet，并且其内部是通过 LinkedHashMap 来实现的。有点类似于我们之前说的LinkedHashMap 其内部是基于 Hashmap 实现一样，不过还是有一点点区别的。 TreeSet（有序，唯一）： 红黑树(自平衡的排序二叉树。) Map HashMap： JDK1.8之前HashMap由数组+链表组成的，数组是HashMap的主体，链表则是主要为了解决哈希冲突而存在的（“拉链法”解决冲突）.JDK1.8以后在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为8）时，将链表转化为红黑树，以减少搜索时间 LinkedHashMap：LinkedHashMap 继承自 HashMap，所以它的底层仍然是基于拉链式散列结构即由数组和链表或红黑树组成。另外，LinkedHashMap 在上面结构的基础上，增加了一条双向链表，使得上面的结构可以保持键值对的插入顺序。同时通过对链表进行相应的操作，实现了访问顺序相关逻辑。 HashTable： 数组+链表组成的，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的 TreeMap： 红黑树（自平衡的排序二叉树） 哪些集合类是线程安全的？ Vector：就比Arraylist多了个 synchronized （线程安全），因为效率较低，现在已经不太建议使用。 hashTable：就比hashMap多了个synchronized (线程安全)，不建议使用。 ConcurrentHashMap：是Java5中支持高并发、高吞吐量的线程安全HashMap实现。它由Segment数组结构和HashEntry数组结构组成。Segment数组在ConcurrentHashMap里扮演锁的角色，HashEntry则用于存储键-值对数据。一个ConcurrentHashMap里包含一个Segment数组，Segment的结构和HashMap类似，是一种数组和链表结构；一个Segment里包含一个HashEntry数组，每个HashEntry是一个链表结构的元素；每个Segment守护着一个HashEntry数组里的元素，当对HashEntry数组的数据进行修改时，必须首先获得它对应的Segment锁。（推荐使用） … Java集合的快速失败机制 “fail-fast”？ 是java集合的一种错误检测机制，当多个线程对集合进行结构上的改变的操作时，有可能会产生 fail-fast 机制。 例如：假设存在两个线程（线程1、线程2），线程1通过Iterator在遍历集合A中的元素，在某个时候线程2修改了集合A的结构（是结构上面的修改，而不是简单的修改集合元素的内容），那么这个时候程序就会抛出 ConcurrentModificationException 异常，从而产生fail-fast机制。 原因：迭代器在遍历时直接访问集合中的内容，并且在遍历过程中使用一个 modCount 变量。集合在被遍历期间如果内容发生变化，就会改变modCount的值。每当迭代器使用hashNext()/next()遍历下一个元素之前，都会检测modCount变量是否为expectedmodCount值，是的话就返回遍历；否则抛出异常，终止遍历。 解决办法： 在遍历过程中，所有涉及到改变modCount值得地方全部加上synchronized。 使用CopyOnWriteArrayList来替换ArrayList 怎么确保一个集合不能被修改？ 可以使用 Collections. unmodifiableCollection(Collection c) 方法来创建一个只读集合，这样改变集合的任何操作都会抛出 Java. lang. UnsupportedOperationException 异常。 示例代码如下： 123456List&lt;String&gt; list = new ArrayList&lt;&gt;();list. add(&quot;x&quot;);Collection&lt;String&gt; clist = Collections. unmodifiableCollection(list);clist. add(&quot;y&quot;); // 运行时此行报错System. out. println(list. size());复制代码 Collection接口List接口迭代器 Iterator 是什么？ Iterator 接口提供遍历任何 Collection 的接口。我们可以从一个 Collection 中使用迭代器方法来获取迭代器实例。迭代器取代了 Java 集合框架中的 Enumeration，迭代器允许调用者在迭代过程中移除元素。 因为所有Collection接继承了Iterator迭代器 Iterator 怎么使用？有什么特点？ Iterator 使用代码如下： 1234567List&lt;String&gt; list = new ArrayList&lt;&gt;();Iterator&lt;String&gt; it = list. iterator();while(it. hasNext())&#123; String obj = it. next(); System. out. println(obj);&#125;复制代码 Iterator 的特点是只能单向遍历，但是更加安全，因为它可以确保，在当前遍历的集合元素被更改的时候，就会抛出 ConcurrentModificationException 异常。 如何边遍历边移除 Collection 中的元素？ 边遍历边修改 Collection 的唯一正确方式是使用 Iterator.remove() 方法，如下： 123456Iterator&lt;Integer&gt; it = list.iterator();while(it.hasNext())&#123; *// do something* it.remove();&#125;复制代码 一种最常见的错误代码如下： 1234for(Integer i : list)&#123; list.remove(i)&#125;复制代码 运行以上错误代码会报 ConcurrentModificationException 异常。这是因为当使用 foreach(for(Integer i : list)) 语句时，会自动生成一个iterator 来遍历该 list，但同时该 list 正在被 Iterator.remove() 修改。Java 一般不允许一个线程在遍历 Collection 时另一个线程修改它。 Iterator 和 ListIterator 有什么区别？ Iterator 可以遍历 Set 和 List 集合，而 ListIterator 只能遍历 List。 Iterator 只能单向遍历，而 ListIterator 可以双向遍历（向前/后遍历）。 ListIterator 实现 Iterator 接口，然后添加了一些额外的功能，比如添加一个元素、替换一个元素、获取前面或后面元素的索引位置。 遍历一个 List 有哪些不同的方式？每种方法的实现原理是什么？Java 中 List 遍历的最佳实践是什么？ 遍历方式有以下几种： for 循环遍历，基于计数器。在集合外部维护一个计数器，然后依次读取每一个位置的元素，当读取到最后一个元素后停止。 迭代器遍历，Iterator。Iterator 是面向对象的一个设计模式，目的是屏蔽不同数据集合的特点，统一遍历集合的接口。Java 在 Collections 中支持了 Iterator 模式。 foreach 循环遍历。foreach 内部也是采用了 Iterator 的方式实现，使用时不需要显式声明 Iterator 或计数器。优点是代码简洁，不易出错；缺点是只能做简单的遍历，不能在遍历过程中操作数据集合，例如删除、替换。 最佳实践：Java Collections 框架中提供了一个 RandomAccess 接口，用来标记 List 实现是否支持 Random Access。 如果一个数据集合实现了该接口，就意味着它支持 Random Access，按位置读取元素的平均时间复杂度为 O(1)，如ArrayList。 如果没有实现该接口，表示不支持 Random Access，如LinkedList。 推荐的做法就是，支持 Random Access 的列表可用 for 循环遍历，否则建议用 Iterator 或 foreach 遍历。 说一下 ArrayList 的优缺点 ArrayList的优点如下： ArrayList 底层以数组实现，是一种随机访问模式。ArrayList 实现了 RandomAccess 接口，因此查找的时候非常快。 ArrayList 在顺序添加一个元素的时候非常方便。 ArrayList 的缺点如下： 删除元素的时候，需要做一次元素复制操作。如果要复制的元素很多，那么就会比较耗费性能。 插入元素的时候，也需要做一次元素复制操作，缺点同上。 ArrayList 比较适合顺序添加、随机访问的场景。 如何实现数组和 List 之间的转换？ 数组转 List：使用 Arrays. asList(array) 进行转换。 List 转数组：使用 List 自带的 toArray() 方法。 代码示例： 12345678910// list to arrayList&lt;String&gt; list = new ArrayList&lt;String&gt;();list.add(&quot;123&quot;);list.add(&quot;456&quot;);list.toArray();// array to listString[] array = new String[]&#123;&quot;123&quot;,&quot;456&quot;&#125;;Arrays.asList(array);复制代码 ArrayList 和 LinkedList 的区别是什么？ 数据结构实现：ArrayList 是动态数组的数据结构实现，而 LinkedList 是双向链表的数据结构实现。 随机访问效率：ArrayList 比 LinkedList 在随机访问的时候效率要高，因为 LinkedList 是线性的数据存储方式，所以需要移动指针从前往后依次查找。 增加和删除效率：在非首尾的增加和删除操作，LinkedList 要比 ArrayList 效率要高，因为 ArrayList 增删操作要影响数组内的其他数据的下标。 内存空间占用：LinkedList 比 ArrayList 更占内存，因为 LinkedList 的节点除了存储数据，还存储了两个引用，一个指向前一个元素，一个指向后一个元素。 线程安全：ArrayList 和 LinkedList 都是不同步的，也就是不保证线程安全； 综合来说，在需要频繁读取集合中的元素时，更推荐使用 ArrayList，而在插入和删除操作较多时，更推荐使用 LinkedList。 LinkedList 的双向链表也叫双链表，是链表的一种，它的每个数据结点中都有两个指针，分别指向直接后继和直接前驱。所以，从双向链表中的任意一个结点开始，都可以很方便地访问它的前驱结点和后继结点。 ArrayList 和 Vector 的区别是什么？ 这两个类都实现了 List 接口（List 接口继承了 Collection 接口），他们都是有序集合 线程安全：Vector 使用了 Synchronized 来实现线程同步，是线程安全的，而 ArrayList 是非线程安全的。 性能：ArrayList 在性能方面要优于 Vector。 扩容：ArrayList 和 Vector 都会根据实际的需要动态的调整容量，只不过在 Vector 扩容每次会增加 1 倍，而 ArrayList 只会增加 50%。 Vector类的所有方法都是同步的。可以由两个线程安全地访问一个Vector对象、但是一个线程访问Vector的话代码要在同步操作上耗费大量的时间。 Arraylist不是同步的，所以在不需要保证线程安全时时建议使用Arraylist。 插入数据时，ArrayList、LinkedList、Vector谁速度较快？阐述 ArrayList、Vector、LinkedList 的存储性能和特性？ ArrayList和Vector 底层的实现都是使用数组方式存储数据。数组元素数大于实际存储的数据以便增加和插入元素，它们都允许直接按序号索引元素，但是插入元素要涉及数组元素移动等内存操作，所以索引数据快而插入数据慢。 Vector 中的方法由于加了 synchronized 修饰，因此 Vector 是线程安全容器，但性能上较ArrayList差。 LinkedList 使用双向链表实现存储，按序号索引数据需要进行前向或后向遍历，但插入数据时只需要记录当前项的前后项即可，所以 LinkedList 插入速度较快。 多线程场景下如何使用 ArrayList？ ArrayList 不是线程安全的，如果遇到多线程场景，可以通过 Collections 的 synchronizedList 方法将其转换成线程安全的容器后再使用。例如像下面这样： 12345678List&lt;String&gt; synchronizedList = Collections.synchronizedList(list);synchronizedList.add(&quot;aaa&quot;);synchronizedList.add(&quot;bbb&quot;);for (int i = 0; i &lt; synchronizedList.size(); i++) &#123; System.out.println(synchronizedList.get(i));&#125;复制代码 为什么 ArrayList 的 elementData 加上 transient 修饰？ ArrayList 中的数组定义如下： private transient Object[] elementData; 再看一下 ArrayList 的定义： 123public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable复制代码 可以看到 ArrayList 实现了 Serializable 接口，这意味着 ArrayList 支持序列化。transient 的作用是说不希望 elementData 数组被序列化，重写了 writeObject 实现： 12345678910111213private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException&#123; *// Write out element count, and any hidden stuff* int expectedModCount = modCount; s.defaultWriteObject(); *// Write out array length* s.writeInt(elementData.length); *// Write out all elements in the proper order.* for (int i=0; i&lt;size; i++) s.writeObject(elementData[i]); if (modCount != expectedModCount) &#123; throw new ConcurrentModificationException();&#125;复制代码 每次序列化时，先调用 defaultWriteObject() 方法序列化 ArrayList 中的非 transient 元素，然后遍历 elementData，只序列化已存入的元素，这样既加快了序列化的速度，又减小了序列化之后的文件大小。 List 和 Set 的区别 List , Set 都是继承自Collection 接口 List 特点：一个有序（元素存入集合的顺序和取出的顺序一致）容器，元素可以重复，可以插入多个null元素，元素都有索引。常用的实现类有 ArrayList、LinkedList 和 Vector。 Set 特点：一个无序（存入和取出顺序有可能不一致）容器，不可以存储重复元素，只允许存入一个null元素，必须保证元素唯一性。Set 接口常用实现类是 HashSet、LinkedHashSet 以及 TreeSet。 另外 List 支持for循环，也就是通过下标来遍历，也可以用迭代器，但是set只能用迭代，因为他无序，无法用下标来取得想要的值。 Set和List对比 Set：检索元素效率低下，删除和插入效率高，插入和删除不会引起元素位置改变。 List：和数组类似，List可以动态增长，查找元素效率高，插入删除元素效率低，因为会引起其他元素位置改变 Set接口说一下 HashSet 的实现原理？ HashSet 是基于 HashMap 实现的，HashSet的值存放于HashMap的key上，HashMap的value统一为present，因此 HashSet 的实现比较简单，相关 HashSet 的操作，基本上都是直接调用底层 HashMap 的相关方法来完成，HashSet 不允许重复的值。 HashSet如何检查重复？HashSet是如何保证数据不可重复的？ 向HashSet 中add ()元素时，判断元素是否存在的依据，不仅要比较hash值，同时还要结合equles 方法比较。 HashSet 中的add ()方法会使用HashMap 的put()方法。 HashMap 的 key 是唯一的，由源码可以看出 HashSet 添加进去的值就是作为HashMap 的key，并且在HashMap中如果K/V相同时，会用新的V覆盖掉旧的V，然后返回旧的V。所以不会重复（ HashMap 比较key是否相等是先比较hashcode 再比较equals ）。 以下是HashSet 部分源码： 123456789101112private static final Object PRESENT = new Object();private transient HashMap&lt;E,Object&gt; map;public HashSet() &#123; map = new HashMap&lt;&gt;();&#125;public boolean add(E e) &#123; // 调用HashMap的put方法,PRESENT是一个至始至终都相同的虚值 return map.put(e, PRESENT)==null;&#125;复制代码 hashCode（）与equals（）的相关规定： 如果两个对象相等，则hashcode一定也是相同的 hashCode是jdk根据对象的地址或者字符串或者数字算出来的int类型的数值 两个对象相等,对两个equals方法返回true 两个对象有相同的hashcode值，它们也不一定是相等的 综上，equals方法被覆盖过，则hashCode方法也必须被覆盖 hashCode()的默认行为是对堆上的对象产生独特值。如果没有重写hashCode()，则该class的两个对象无论如何都不会相等（即使这两个对象指向相同的数据）。 ==与equals的区别 ==是判断两个变量或实例是不是指向同一个内存空间 equals是判断两个变量或实例所指向的内存空间的值是不是相同 ==是指对内存地址进行比较 equals()是对字符串的内容进行比较 HashSet与HashMap的区别 HashMap HashSet 实现了Map接口 实现Set接口 存储键值对 仅存储对象 调用put（）向map中添加元素 调用add（）方法向Set中添加元素 HashMap使用键（Key）计算Hashcode HashSet使用成员对象来计算hashcode值，对于两个对象来说hashcode可能相同，所以equals()方法用来判断对象的相等性，如果两个对象不同的话，那么返回false HashMap相对于HashSet较快，因为它是使用唯一的键获取对象 HashSet较HashMap来说比较慢 Map接口什么是Hash算法 哈希算法是指把任意长度的二进制映射为固定长度的较小的二进制值，这个较小的二进制值叫做哈希值。 什么是链表 链表是可以将物理地址上不连续的数据连接起来，通过指针来对物理地址进行操作，实现增删改查等功能。 链表大致分为单链表和双向链表 单链表:每个节点包含两部分,一部分存放数据变量的data,另一部分是指向下一节点的next指针 ![在这里插入图片描述](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2020/4/13/17173551e72891e5~tplv-t2oaga2asx-watermark.awebp) 双向链表:除了包含单链表的部分,还增加的pre前一个节点的指针 ![在这里插入图片描述](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2020/4/13/17173551e73f80b0~tplv-t2oaga2asx-watermark.awebp) 链表的优点 插入删除速度快（因为有next指针指向其下一个节点，通过改变指针的指向可以方便的增加删除元素） 内存利用率高，不会浪费内存（可以使用内存中细小的不连续空间（大于node节点的大小），并且在需要空间的时候才创建空间） 大小没有固定，拓展很灵活。 链表的缺点 不能随机查找，必须从第一个开始遍历，查找效率低 说一下HashMap的实现原理？ HashMap概述： HashMap是基于哈希表的Map接口的非同步实现。此实现提供所有可选的映射操作，并允许使用null值和null键。此类不保证映射的顺序，特别是它不保证该顺序恒久不变。 HashMap的数据结构： 在Java编程语言中，最基本的结构就是两种，一个是数组，另外一个是模拟指针（引用），所有的数据结构都可以用这两个基本结构来构造的，HashMap也不例外。HashMap实际上是一个“链表散列”的数据结构，即数组和链表的结合体。 HashMap 基于 Hash 算法实现的 当我们往HashMap中put元素时，利用key的hashCode重新hash计算出当前对象的元素在数组中的下标 存储时，如果出现hash值相同的key，此时有两种情况。 ​ (1)如果key相同，则覆盖原始值； ​ (2)如果key不同（出现冲突），则将当前的key-value放入链表中 获取时，直接找到hash值对应的下标，在进一步判断key是否相同，从而找到对应值。 理解了以上过程就不难明白HashMap是如何解决hash冲突的问题，核心就是使用了数组的存储方式，然后将冲突的key的对象放入链表中，一旦发现冲突就在链表中做进一步的对比。 需要注意Jdk 1.8中对HashMap的实现做了优化，当链表中的节点数据超过八个之后，该链表会转为红黑树来提高查询效率，从原来的O(n)到O(logn) HashMap在JDK1.7和JDK1.8中有哪些不同？HashMap的底层实现 在Java中，保存数据有两种比较简单的数据结构：数组和链表。数组的特点是：寻址容易，插入和删除困难；链表的特点是：寻址困难，但插入和删除容易；\\所以我们将数组和链表结合在一起，发挥两者各自的优势，使用一种叫做**拉链法**的方式可以解决哈希冲突。 HashMap JDK1.8之前 JDK1.8之前采用的是拉链法。拉链法：将链表和数组相结合。也就是说创建一个链表数组，数组中每一格就是一个链表。若遇到哈希冲突，则将冲突的值加到链表中即可。 HashMap JDK1.8之后 相比于之前的版本，jdk1.8在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为8）时，将链表转化为红黑树，以减少搜索时间。 JDK1.7 VS JDK1.8 比较 JDK1.8主要解决或优化了一下问题： resize 扩容优化 引入了红黑树，目的是避免单条链表过长而影响查询效率，红黑树算法请参考 解决了多线程死循环问题，但仍是非线程安全的，多线程时可能会造成数据丢失问题。 不同 JDK 1.7 JDK 1.8 存储结构 数组 + 链表 数组 + 链表 + 红黑树 初始化方式 单独函数：inflateTable() 直接集成到了扩容函数resize()中 hash值计算方式 扰动处理 = 9次扰动 = 4次位运算 + 5次异或运算 扰动处理 = 2次扰动 = 1次位运算 + 1次异或运算 存放数据的规则 无冲突时，存放数组；冲突时，存放链表 无冲突时，存放数组；冲突 &amp; 链表长度 &lt; 8：存放单链表；冲突 &amp; 链表长度 &gt; 8：树化并存放红黑树 插入数据方式 头插法（先讲原位置的数据移到后1位，再插入数据到该位置） 尾插法（直接插入到链表尾部/红黑树） 扩容后存储位置的计算方式 全部按照原来方法进行计算（即hashCode -&gt;&gt; 扰动函数 -&gt;&gt; (h&amp;length-1)） 按照扩容后的规律计算（即扩容后的位置=原位置 or 原位置 + 旧容量） 什么是红黑树说道红黑树先讲什么是二叉树 二叉树简单来说就是 每一个节上可以关联俩个子节点 123456789大概就是这样子： a / \\ b c / \\ / \\ d e f g / \\ / \\ / \\ / \\ h i j k l m n o复制代码 红黑树 红黑树是一种特殊的二叉查找树。红黑树的每个结点上都有存储位表示结点的颜色，可以是红(Red)或黑(Black)。 img 红黑树的每个结点是黑色或者红色。当是不管怎么样他的根结点是黑色。每个叶子结点（叶子结点代表终结、结尾的节点）也是黑色 [注意：这里叶子结点，是指为空(NIL或NULL)的叶子结点！]。 如果一个结点是红色的，则它的子结点必须是黑色的。 每个结点到叶子结点NIL所经过的黑色结点的个数一样的。[确保没有一条路径会比其他路径长出俩倍，所以红黑树是相对接近平衡的二叉树的！] 红黑树的基本操作是添加、删除。在对红黑树进行添加或删除之后，都会用到旋转方法。为什么呢？道理很简单，添加或删除红黑树中的结点之后，红黑树的结构就发生了变化，可能不满足上面三条性质，也就不再是一颗红黑树了，而是一颗普通的树。而通过旋转和变色，可以使这颗树重新成为红黑树。简单点说，旋转和变色的目的是让树保持红黑树的特性。 HashMap的put方法的具体流程？ 当我们put的时候，首先计算 key的hash值，这里调用了 hash方法，hash方法实际是让key.hashCode()与key.hashCode()&gt;&gt;&gt;16进行异或操作，高16bit补0，一个数和0异或不变，所以 hash 函数大概的作用就是：高16bit不变，低16bit和高16bit做了一个异或，目的是减少碰撞。按照函数注释，因为bucket数组大小是2的幂，计算下标index = (table.length - 1) &amp; hash，如果不做 hash 处理，相当于散列生效的只有几个低 bit 位，为了减少散列的碰撞，设计者综合考虑了速度、作用、质量之后，使用高16bit和低16bit异或来简单处理减少碰撞，而且JDK8中用了复杂度 O（logn）的树结构来提升碰撞下的性能。 putVal方法执行流程图 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125;static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125;//实现Map.put和相关方法final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // 步骤①：tab为空则创建 // table未初始化或者长度为0，进行扩容 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 步骤②：计算index，并对null做处理 // (n - 1) &amp; hash 确定元素存放在哪个桶中，桶为空，新生成结点放入桶中(此时，这个结点是放在数组中) if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); // 桶中已经存在元素 else &#123; Node&lt;K,V&gt; e; K k; // 步骤③：节点key存在，直接覆盖value // 比较桶中第一个元素(数组中的结点)的hash值相等，key相等 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) // 将第一个元素赋值给e，用e来记录 e = p; // 步骤④：判断该链为红黑树 // hash值不相等，即key不相等；为红黑树结点 // 如果当前元素类型为TreeNode，表示为红黑树，putTreeVal返回待存放的node, e可能为null else if (p instanceof TreeNode) // 放入树中 e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); // 步骤⑤：该链为链表 // 为链表结点 else &#123; // 在链表最末插入结点 for (int binCount = 0; ; ++binCount) &#123; // 到达链表的尾部 //判断该链表尾部指针是不是空的 if ((e = p.next) == null) &#123; // 在尾部插入新结点 p.next = newNode(hash, key, value, null); //判断链表的长度是否达到转化红黑树的临界值，临界值为8 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st //链表结构转树形结构 treeifyBin(tab, hash); // 跳出循环 break; &#125; // 判断链表中结点的key值与插入的元素的key值是否相等 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) // 相等，跳出循环 break; // 用于遍历桶中的链表，与前面的e = p.next组合，可以遍历链表 p = e; &#125; &#125; //判断当前的key已经存在的情况下，再来一个相同的hash值、key值时，返回新来的value这个值 if (e != null) &#123; // 记录e的value V oldValue = e.value; // onlyIfAbsent为false或者旧值为null if (!onlyIfAbsent || oldValue == null) //用新值替换旧值 e.value = value; // 访问后回调 afterNodeAccess(e); // 返回旧值 return oldValue; &#125; &#125; // 结构性修改 ++modCount; // 步骤⑥：超过最大容量就扩容 // 实际大小大于阈值则扩容 if (++size &gt; threshold) resize(); // 插入后回调 afterNodeInsertion(evict); return null;&#125;复制代码 判断键值对数组table[i]是否为空或为null，否则执行resize()进行扩容； 根据键值key计算hash值得到插入的数组索引i，如果table[i]==null，直接新建节点添加，转向⑥，如果table[i]不为空，转向③； 判断table[i]的首个元素是否和key一样，如果相同直接覆盖value，否则转向④，这里的相同指的是hashCode以及equals； 判断table[i] 是否为treeNode，即table[i] 是否是红黑树，如果是红黑树，则直接在树中插入键值对，否则转向5； 遍历table[i]，判断链表长度是否大于8，大于8的话把链表转换为红黑树，在红黑树中执行插入操作，否则进行链表的插入操作；遍历过程中若发现key已经存在直接覆盖value即可； 插入成功后，判断实际存在的键值对数量size是否超多了最大容量threshold，如果超过，进行扩容。 HashMap的扩容操作是怎么实现的？ 在jdk1.8中，resize方法是在hashmap中的键值对大于阀值时或者初始化时，就调用resize方法进行扩容； 每次扩展的时候，都是扩展2倍； 扩展后Node对象的位置要么在原位置，要么移动到原偏移量两倍的位置。 在putVal()中，我们看到在这个函数里面使用到了2次resize()方法，resize()方法表示的在进行第一次初始化时会对其进行扩容，或者当该数组的实际大小大于其临界值值(第一次为12),这个时候在扩容的同时也会伴随的桶上面的元素进行重新分发，这也是JDK1.8版本的一个优化的地方，在1.7中，扩容之后需要重新去计算其Hash值，根据Hash值对其进行分发，但在1.8版本中，则是根据在同一个桶的位置中进行判断(e.hash &amp; oldCap)是否为0，重新进行hash分配后，该元素的位置要么停留在原始位置，要么移动到原始位置+增加的数组大小这个位置上 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table;//oldTab指向hash桶数组 int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123;//如果oldCap不为空的话，就是hash桶数组不为空 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123;//如果大于最大容量了，就赋值为整数最大的阀值 threshold = Integer.MAX_VALUE; return oldTab;//返回 &#125;//如果当前hash桶数组的长度在扩容后仍然小于最大容量 并且oldCap大于默认值16 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold 双倍扩容阀值threshold &#125; // 旧的容量为0，但threshold大于零，代表有参构造有cap传入，threshold已经被初始化成最小2的n次幂 // 直接将该值赋给新的容量 else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; // 无参构造创建的map，给出默认容量和threshold 16, 16*0.75 else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; // 新的threshold = 新的cap * 0.75 if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; // 计算出新的数组长度后赋给当前成员变量table @SuppressWarnings(&#123;&quot;rawtypes&quot;,&quot;unchecked&quot;&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap];//新建hash桶数组 table = newTab;//将新数组的值复制给旧的hash桶数组 // 如果原先的数组没有初始化，那么resize的初始化工作到此结束，否则进入扩容元素重排逻辑，使其均匀的分散 if (oldTab != null) &#123; // 遍历新数组的所有桶下标 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; // 旧数组的桶下标赋给临时变量e，并且解除旧数组中的引用，否则就数组无法被GC回收 oldTab[j] = null; // 如果e.next==null，代表桶中就一个元素，不存在链表或者红黑树 if (e.next == null) // 用同样的hash映射算法把该元素加入新的数组 newTab[e.hash &amp; (newCap - 1)] = e; // 如果e是TreeNode并且e.next!=null，那么处理树中元素的重排 else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); // e是链表的头并且e.next!=null，那么处理链表中元素重排 else &#123; // preserve order // loHead,loTail 代表扩容后不用变换下标，见注1 Node&lt;K,V&gt; loHead = null, loTail = null; // hiHead,hiTail 代表扩容后变换下标，见注1 Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; // 遍历链表 do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) // 初始化head指向链表当前元素e，e不一定是链表的第一个元素，初始化后loHead // 代表下标保持不变的链表的头元素 loHead = e; else // loTail.next指向当前e loTail.next = e; // loTail指向当前的元素e // 初始化后，loTail和loHead指向相同的内存，所以当loTail.next指向下一个元素时， // 底层数组中的元素的next引用也相应发生变化，造成lowHead.next.next..... // 跟随loTail同步，使得lowHead可以链接到所有属于该链表的元素。 loTail = e; &#125; else &#123; if (hiTail == null) // 初始化head指向链表当前元素e, 初始化后hiHead代表下标更改的链表头元素 hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); // 遍历结束, 将tail指向null，并把链表头放入新数组的相应下标，形成新的映射。 if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125;复制代码 HashMap是怎么解决哈希冲突的？ 答：在解决这个问题之前，我们首先需要知道什么是哈希冲突，而在了解哈希冲突之前我们还要知道什么是哈希才行； 什么是哈希？ Hash，一般翻译为“散列”，也有直接音译为“哈希”的， Hash就是指使用哈希算法是指把任意长度的二进制映射为固定长度的较小的二进制值，这个较小的二进制值叫做哈希值。 什么是哈希冲突？ 当两个不同的输入值，根据同一散列函数计算出相同的散列值的现象，我们就把它叫做碰撞（哈希碰撞）。 HashMap的数据结构 在Java中，保存数据有两种比较简单的数据结构：数组和链表。 数组的特点是：寻址容易，插入和删除困难； 链表的特点是：寻址困难，但插入和删除容易； 所以我们将数组和链表结合在一起，发挥两者各自的优势，就可以使用俩种方式：链地址法和开放地址法可以解决哈希冲突： 链表法就是将相同hash值的对象组织成一个链表放在hash值对应的槽位； 开放地址法是通过一个探测算法，当某个槽位已经被占据的情况下继续查找下一个可以使用的槽位。 但相比于hashCode返回的int类型，我们HashMap初始的容量大小DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4（即2的四次方16）要远小于int类型的范围，所以我们如果只是单纯的用hashCode取余来获取对应的bucket这将会大大增加哈希碰撞的概率，并且最坏情况下还会将HashMap变成一个单链表，所以我们还需要对hashCode作一定的优化 hash()函数 上面提到的问题，主要是因为如果使用hashCode取余，那么相当于参与运算的只有hashCode的低位，高位是没有起到任何作用的，所以我们的思路就是让hashCode取值出的高位也参与运算，进一步降低hash碰撞的概率，使得数据分布更平均，我们把这样的操作称为扰动，在JDK 1.8中的hash()函数如下： 12345static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);// 与自己右移16位进行异或运算（高低位异或）&#125;复制代码 这比在JDK 1.7中，更为简洁，相比在1.7中的4次位运算，5次异或运算（9次扰动），在1.8中，只进行了1次位运算和1次异或运算（2次扰动）； 总结 简单总结一下HashMap是使用了哪些方法来有效解决哈希冲突的： 链表法就是将相同hash值的对象组织成一个链表放在hash值对应的槽位； 开放地址法是通过一个探测算法，当某个槽位已经被占据的情况下继续查找下一个可以使用的槽位。 能否使用任何类作为 Map 的 key？可以使用任何类作为 Map 的 key，然而在使用之前，需要考虑以下几点： 如果类重写了 equals() 方法，也应该重写 hashCode() 方法。 类的所有实例需要遵循与 equals() 和 hashCode() 相关的规则。 如果一个类没有使用 equals()，不应该在 hashCode() 中使用它。 用户自定义 Key 类最佳实践是使之为不可变的，这样 hashCode() 值可以被缓存起来，拥有更好的性能。不可变的类也可以确保 hashCode() 和 equals() 在未来不会改变，这样就会解决与可变相关的问题了。 为什么HashMap中String、Integer这样的包装类适合作为K？ 答：String、Integer等包装类的特性能够保证Hash值的不可更改性和计算准确性，能够有效的减少Hash碰撞的几率 都是final类型，即不可变性，保证key的不可更改性，不会存在获取hash值不同的情况 内部已重写了equals()、hashCode()等方法，遵守了HashMap内部的规范（不清楚可以去上面看看putValue的过程），不容易出现Hash值计算错误的情况； 如果使用Object作为HashMap的Key，应该怎么办呢？ 答：重写 1hashCode() 和 1equals() 方法 重写hashCode()是因为需要计算存储数据的存储位置，需要注意不要试图从散列码计算中排除掉一个对象的关键部分来提高性能，这样虽然能更快但可能会导致更多的Hash碰撞； 重写equals()方法，需要遵守自反性、对称性、传递性、一致性以及对于任何非null的引用值x，x.equals(null)必须返回false的这几个特性，目的是为了保证key在哈希表中的唯一性； HashMap为什么不直接使用hashCode()处理后的哈希值直接作为table的下标？ 答：hashCode()方法返回的是int整数类型，其范围为-(2 ^ 31)~(2 ^ 31 - 1)，约有40亿个映射空间，而HashMap的容量范围是在16（初始化默认值）~2 ^ 30，HashMap通常情况下是取不到最大值的，并且设备上也难以提供这么多的存储空间，从而导致通过hashCode()计算出的哈希值可能不在数组大小范围内，进而无法匹配存储位置； 那怎么解决呢？ HashMap自己实现了自己的hash()方法，通过两次扰动使得它自己的哈希值高低位自行进行异或运算，降低哈希碰撞概率也使得数据分布更平均； 在保证数组长度为2的幂次方的时候，使用hash()运算之后的值与运算（&amp;）（数组长度 - 1）来获取数组下标的方式进行存储，这样一来是比取余操作更加有效率，二来也是因为只有当数组长度为2的幂次方时，h&amp;(length-1)才等价于h%length，三来解决了“哈希值与数组大小范围不匹配”的问题； HashMap 的长度为什么是2的幂次方 为了能让 HashMap 存取高效，尽量较少碰撞，也就是要尽量把数据分配均匀，每个链表/红黑树长度大致相同。这个实现就是把数据存到哪个链表/红黑树中的算法。 这个算法应该如何设计呢？ 我们首先可能会想到采用%取余的操作来实现。但是，重点来了：“取余(%)操作中如果除数是2的幂次则等价于与其除数减一的与(&amp;)操作（也就是说 hash%length==hash&amp;(length-1)的前提是 length 是2的 n 次方；）。” 并且 采用二进制位操作 &amp;，相对于%能够提高运算效率，这就解释了 HashMap 的长度为什么是2的幂次方。 那为什么是两次扰动呢？ 答：这样就是加大哈希值低位的随机性，使得分布更均匀，从而提高对应数组存储下标位置的随机性&amp;均匀性，最终减少Hash冲突，两次就够了，已经达到了高位低位同时参与运算的目的； HashMap 与 HashTable 有什么区别？ 线程安全： HashMap 是非线程安全的，HashTable 是线程安全的；HashTable 内部的方法基本都经过 synchronized 修饰。（如果你要保证线程安全的话就使用 ConcurrentHashMap ）； 效率： 因为线程安全的问题，HashMap 要比 HashTable 效率高一点。另外，HashTable 基本被淘汰，不要在代码中使用它；（如果你要保证线程安全的话就使用 ConcurrentHashMap ）； 对Null key 和Null value的支持： HashMap 中，null 可以作为键，这样的键只有一个，可以有一个或多个键所对应的值为 null。但是在 HashTable 中 put 进的键值只要有一个 null，直接抛NullPointerException。 初始容量大小和每次扩充容量大小的不同 ： 创建时如果不指定容量初始值，Hashtable 默认的初始大小为11，之后每次扩充，容量变为原来的2n+1。HashMap 默认的初始化大小为16。之后每次扩充，容量变为原来的2倍。 创建时如果给定了容量初始值，那么 Hashtable 会直接使用你给定的大小，而 HashMap 会将其扩充为2的幂次方大小。也就是说 HashMap 总是使用2的幂作为哈希表的大小，后面会介绍到为什么是2的幂次方。 底层数据结构： JDK1.8 以后的 HashMap 在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为8）时，将链表转化为红黑树，以减少搜索时间。Hashtable 没有这样的机制。 推荐使用：在 Hashtable 的类注释可以看到，Hashtable 是保留类不建议使用，推荐在单线程环境下使用 HashMap 替代，如果需要多线程使用则用 ConcurrentHashMap 替代。 什么是TreeMap 简介 TreeMap 是一个有序的key-value集合，它是通过红黑树实现的。 TreeMap基于红黑树（Red-Black tree）实现。该映射根据其键的自然顺序进行排序，或者根据创建映射时提供的 Comparator 进行排序，具体取决于使用的构造方法。 TreeMap是线程非同步的。 如何决定使用 HashMap 还是 TreeMap？ 对于在Map中插入、删除和定位元素这类操作，HashMap是最好的选择。然而，假如你需要对一个有序的key集合进行遍历，TreeMap是更好的选择。基于你的collection的大小，也许向HashMap中添加元素会更快，将map换为TreeMap进行有序key的遍历。 HashMap 和 ConcurrentHashMap 的区别 ConcurrentHashMap对整个桶数组进行了分割分段(Segment)，然后在每一个分段上都用lock锁进行保护，相对于HashTable的synchronized锁的粒度更精细了一些，并发性能更好，而HashMap没有锁机制，不是线程安全的。（JDK1.8之后ConcurrentHashMap启用了一种全新的方式实现,利用CAS算法。） HashMap的键值对允许有null，但是ConCurrentHashMap都不允许。 ConcurrentHashMap 和 Hashtable 的区别？ ConcurrentHashMap 和 Hashtable 的区别主要体现在实现线程安全的方式上不同。 底层数据结构： JDK1.7的 ConcurrentHashMap 底层采用 分段的数组+链表 实现，JDK1.8 采用的数据结构跟HashMap1.8的结构一样，数组+链表/红黑二叉树。Hashtable 和 JDK1.8 之前的 HashMap 的底层数据结构类似都是采用 数组+链表 的形式，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的； 实现线程安全的方式 ： 在JDK1.7的时候，ConcurrentHashMap（分段锁） 对整个桶数组进行了分割分段(Segment)，每一把锁只锁容器其中一部分数据，多线程访问容器里不同数据段的数据，就不会存在锁竞争，提高并发访问率。（默认分配16个Segment，比Hashtable效率提高16倍。） 到了 JDK1.8 的时候已经摒弃了Segment的概念，而是直接用 Node 数组+链表+红黑树的数据结构来实现，并发控制使用 synchronized 和 CAS 来操作。（JDK1.6以后 对 synchronized锁做了很多优化） 整个看起来就像是优化过且线程安全的 HashMap，虽然在JDK1.8中还能看到 Segment 的数据结构，但是已经简化了属性，只是为了兼容旧版本； ② Hashtable(同一把锁) :使用 synchronized 来保证线程安全，效率非常低下。当一个线程访问同步方法时，其他线程也访问同步方法，可能会进入阻塞或轮询状态，如使用 put 添加元素，另一个线程不能使用 put 添加元素，也不能使用 get，竞争会越来越激烈效率越低。 两者的对比图： 1、HashTable: 2、 JDK1.7的ConcurrentHashMap： 3、JDK1.8的ConcurrentHashMap（TreeBin: 红黑二叉树节点 Node: 链表节点）： 答：ConcurrentHashMap 结合了 HashMap 和 HashTable 二者的优势。HashMap 没有考虑同步，HashTable 考虑了同步的问题使用了synchronized 关键字，所以 HashTable 在每次同步执行时都要锁住整个结构。 ConcurrentHashMap 锁的方式是稍微细粒度的。 ConcurrentHashMap 底层具体实现知道吗？实现原理是什么？JDK1.7 首先将数据分为一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据时，其他段的数据也能被其他线程访问。 在JDK1.7中，ConcurrentHashMap采用Segment + HashEntry的方式进行实现，结构如下： 一个 ConcurrentHashMap 里包含一个 Segment 数组。Segment 的结构和HashMap类似，是一种数组和链表结构，一个 Segment 包含一个 HashEntry 数组，每个 HashEntry 是一个链表结构的元素，每个 Segment 守护着一个HashEntry数组里的元素，当对 HashEntry 数组的数据进行修改时，必须首先获得对应的 Segment的锁。 该类包含两个静态内部类 HashEntry 和 Segment ；前者用来封装映射表的键值对，后者用来充当锁的角色； Segment 是一种可重入的锁 ReentrantLock，每个 Segment 守护一个HashEntry 数组里得元素，当对 HashEntry 数组的数据进行修改时，必须首先获得对应的 Segment 锁。 JDK1.8 在JDK1.8中，放弃了Segment臃肿的设计，取而代之的是采用Node + CAS + Synchronized来保证并发安全进行实现，synchronized只锁定当前链表或红黑二叉树的首节点，这样只要hash不冲突，就不会产生并发，效率又提升N倍。 结构如下： 附加源码，有需要的可以看看 插入元素过程（建议去看看源码）： 如果相应位置的Node还没有初始化，则调用CAS插入相应的数据； 12345else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; // no lock when adding to empty bin&#125;复制代码 如果相应位置的Node不为空，且当前该节点不处于移动状态，则对该节点加synchronized锁，如果该节点的hash不小于0，则遍历链表更新节点或插入新节点； 1234567891011121314151617181920if (fh &gt;= 0) &#123; binCount = 1; for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &#125; Node&lt;K,V&gt; pred = e; if ((e = e.next) == null) &#123; pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125;&#125;复制代码 如果该节点是TreeBin类型的节点，说明是红黑树结构，则通过putTreeVal方法往红黑树中插入节点；如果binCount不为0，说明put操作对数据产生了影响，如果当前链表的个数达到8个，则通过treeifyBin方法转化为红黑树，如果oldVal不为空，说明是一次更新操作，没有对元素个数产生影响，则直接返回旧值； 如果插入的是一个新节点，则执行addCount()方法尝试更新元素个数baseCount； 辅助工具类Array 和 ArrayList 有何区别？ Array 可以存储基本数据类型和对象，ArrayList 只能存储对象。 Array 是指定固定大小的，而 ArrayList 大小是自动扩展的。 Array 内置方法没有 ArrayList 多，比如 addAll、removeAll、iteration 等方法只有 ArrayList 有。 1对于基本类型数据，集合使用自动装箱来减少编码工作量。但是，当处理固定大小的基本数据类型的时候，这种方式相对比较慢。 如何实现 Array 和 List 之间的转换？ Array 转 List： Arrays. asList(array) ； List 转 Array：List 的 toArray() 方法。 comparable 和 comparator的区别？ comparable接口实际上是出自java.lang包，它有一个 compareTo(Object obj)方法用来排序 comparator接口实际上是出自 java.util 包，它有一个compare(Object obj1, Object obj2)方法用来排序 一般我们需要对一个集合使用自定义排序时，我们就要重写compareTo方法或compare方法，当我们需要对某一个集合实现两种排序方式，比如一个song对象中的歌名和歌手名分别采用一种排序方法的话，我们可以重写compareTo方法和使用自制的Comparator方法或者以两个Comparator来实现歌名排序和歌星名排序，第二种代表我们只能使用两个参数版的Collections.sort(). Collection 和 Collections 有什么区别？ java.util.Collection 是一个集合接口（集合类的一个顶级接口）。它提供了对集合对象进行基本操作的通用接口方法。Collection接口在Java 类库中有很多具体的实现。Collection接口的意义是为各种具体的集合提供了最大化的统一操作方式，其直接继承接口有List与Set。 Collections则是集合类的一个工具类/帮助类，其中提供了一系列静态方法，用于对集合中元素进行排序、搜索以及线程安全等各种操作。 TreeMap 和 TreeSet 在排序时如何比较元素？Collections 工具类中的 sort()方法如何比较元素？ TreeSet 要求存放的对象所属的类必须实现 Comparable 接口，该接口提供了比较元素的 compareTo()方法，当插入元素时会回调该方法比较元素的大小。TreeMap 要求存放的键值对映射的键必须实现 Comparable 接口从而根据键对元素进 行排 序。 Collections 工具类的 sort 方法有两种重载的形式， 第一种要求传入的待排序容器中存放的对象比较实现 Comparable 接口以实现元素的比较； ？ comparable接口实际上是出自java.lang包，它有一个 compareTo(Object obj)方法用来排序 comparator接口实际上是出自 java.util 包，它有一个compare(Object obj1, Object obj2)方法用来排序 一般我们需要对一个集合使用自定义排序时，我们就要重写compareTo方法或compare方法，当我们需要对某一个集合实现两种排序方式，比如一个song对象中的歌名和歌手名分别采用一种排序方法的话，我们可以重写compareTo方法和使用自制的Comparator方法或者以两个Comparator来实现歌名排序和歌星名排序，第二种代表我们只能使用两个参数版的Collections.sort(). Collection 和 Collections 有什么区别？ java.util.Collection 是一个集合接口（集合类的一个顶级接口）。它提供了对集合对象进行基本操作的通用接口方法。Collection接口在Java 类库中有很多具体的实现。Collection接口的意义是为各种具体的集合提供了最大化的统一操作方式，其直接继承接口有List与Set。 Collections则是集合类的一个工具类/帮助类，其中提供了一系列静态方法，用于对集合中元素进行排序、搜索以及线程安全等各种操作。 TreeMap 和 TreeSet 在排序时如何比较元素？Collections 工具类中的 sort()方法如何比较元素？ TreeSet 要求存放的对象所属的类必须实现 Comparable 接口，该接口提供了比较元素的 compareTo()方法，当插入元素时会回调该方法比较元素的大小。TreeMap 要求存放的键值对映射的键必须实现 Comparable 接口从而根据键对元素进 行排 序。 Collections 工具类的 sort 方法有两种重载的形式， 第一种要求传入的待排序容器中存放的对象比较实现 Comparable 接口以实现元素的比较； 第二种不强制性的要求容器中的元素必须可比较，但是要求传入第二个参数，参数是Comparator 接口的子类型（需要重写 compare 方法实现元素的比较），相当于一个临时定义的排序规则，其实就是通过接口注入比较元素大小的算法，也是对回调模式的应用（Java 中对函数式编程的支持）。 作者：小杰要吃蛋链接：https://juejin.cn/post/6844904125939843079来源：掘金著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。","tags":[{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"},{"name":"基础","slug":"基础","permalink":"https://lywlefan.github.io/tags/基础/"}]},{"title":"Hive中导入JSON数据","date":"2020-04-28T16:00:00.000Z","path":"2020/04/29/软件研发/后端/大数据/存储/hive/Hive中导入JSON数据/","text":"导入步骤遇到问题创建表失败错误代码1FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. org/apache/hadoop/hive/serde2/SerDe 解决方法方法一 参考文档 官方文档 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"大数据","slug":"大数据","permalink":"https://lywlefan.github.io/tags/大数据/"},{"name":"hive","slug":"hive","permalink":"https://lywlefan.github.io/tags/hive/"}]},{"title":"Hive数据类型","date":"2020-04-02T16:00:00.000Z","path":"2020/04/03/软件研发/后端/大数据/存储/hive/Hive数据类型/","text":"基本数据类型TINYINT1byte有符号整数 SMALINT2byte有符号整数 INT4byte有符号整数 BIGINT8BYTE有符号整数 Boolean布尔类型 FLOAT单精度浮点数 DOUBLE双精度浮点数 STRING字符序列 TIMESTAMPBINARY字节数组 特殊数据类型STRUCT和C语言中的对象类型,可以通过”点”符号访问元素内容. MAP键值对集合类型 ARRAY数组类型 参考文档 官方文档 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"大数据","slug":"大数据","permalink":"https://lywlefan.github.io/tags/大数据/"},{"name":"hive","slug":"hive","permalink":"https://lywlefan.github.io/tags/hive/"}]},{"title":"Hive的CLi骚操作","date":"2020-04-02T16:00:00.000Z","path":"2020/04/03/软件研发/后端/大数据/存储/hive/Hive的CLi骚操作/","text":"常规操作只使用一次的命令-e1$ hive -e &quot;select * from wdc_user limit 10&quot;; 结果: 1234567891011121314151617181920212223Java HotSpot(TM) 64-Bit Server VM warning: Using the ParNew young collector with the Serial old collector is deprecated and will likely be removed in a future releaseJava HotSpot(TM) 64-Bit Server VM warning: Using the ParNew young collector with the Serial old collector is deprecated and will likely be removed in a future releaseSLF4J: Class path contains multiple SLF4J bindings.SLF4J: Found binding in [jar:file:/usr/local/hive/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]SLF4J: Found binding in [jar:file:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]Hive Session ID = 4902a4f1-0aee-4180-8a22-d9823f02d861Logging initialized using configuration in file:/usr/local/hive/conf/hive-log4j2.properties Async: trueHive Session ID = 930029de-4073-4c2d-a4f1-a878db67317dOK5d64d63c83dee22d49f2b58b 622301196904031721 A 朱红 610300594339 C1 陕C A 0 2010-06-22 00:00:00 15d64d63c83dee22d49f2b598 622201198608251221 A 刘蝉与 610113332820 C1 陕A A 0 2011-06-22 00:00:00 15d64d63c83dee22d49f2b608 610321197608153421 A 强亚林 610303321601 E 陕C A 0 2011-06-22 00:00:00 15d64d63c83dee22d49f2b5f1 610121199101300021 A 赵欣 610112321208 C1 陕A A 0 2014-06-22 00:00:00 15d64d63c83dee22d49f2b5f8 610526199001203121 A 杨亚荣 610112321313 C1 陕A A 0 2014-06-22 00:00:00 15d64d63c83dee22d49f2b5e3 610321198708253651 A 段建维 610300596604 C1D 陕C A 0 2011-06-22 00:00:00 15d64d63c83dee22d49f2b5f3 622301199110088471 A 严金学 610112321189 C1 陕A A 0 2014-06-22 00:00:00 15d64d63c83dee22d49f2b5cb 370725199311303771 A 孟豪 610112321197 C1 陕A A 0 2014-06-22 00:00:00 15d64d63c83dee22d49f2b631 610623197809161611 A 李延平 610623034843 B2D 陕J A 0 2004-06-22 00:00:00 15d64d63c83dee22d49f2b5a4 130406199508080321 A 刘醒晗 610113382523 C1 陕A A 0 2017-06-22 00:00:00 1Time taken: 2.262 seconds, Fetched: 10 row(s) 加入 -S加入-S表示开启了静默模式,不会显示一些无关紧要的信息。 1$ hive -S -e &quot;select * from wdc_user limit 10&quot;; 结果: 12345678910111213141516171819Java HotSpot(TM) 64-Bit Server VM warning: Using the ParNew young collector with the Serial old collector is deprecated and will likely be removed in a future releaseJava HotSpot(TM) 64-Bit Server VM warning: Using the ParNew young collector with the Serial old collector is deprecated and will likely be removed in a future releaseSLF4J: Class path contains multiple SLF4J bindings.SLF4J: Found binding in [jar:file:/usr/local/hive/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]SLF4J: Found binding in [jar:file:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]Hive Session ID = afac4c67-4c85-4112-943e-8102a50d8629Hive Session ID = 36bf8d3c-9291-4196-822e-b15cc8add3435d64d63c83dee22d49f2b58b 622301196904031721 A 朱红 610300594339 C1 陕C A 0 2010-06-22 00:00:00 15d64d63c83dee22d49f2b598 622201198608251221 A 刘蝉与 610113332820 C1 陕A A 0 2011-06-22 00:00:00 15d64d63c83dee22d49f2b608 610321197608153421 A 强亚林 610303321601 E 陕C A 0 2011-06-22 00:00:00 15d64d63c83dee22d49f2b5f1 610121199101300021 A 赵欣 610112321208 C1 陕A A 0 2014-06-22 00:00:00 15d64d63c83dee22d49f2b5f8 610526199001203121 A 杨亚荣 610112321313 C1 陕A A 0 2014-06-22 00:00:00 15d64d63c83dee22d49f2b5e3 610321198708253651 A 段建维 610300596604 C1D 陕C A 0 2011-06-22 00:00:00 15d64d63c83dee22d49f2b5f3 622301199110088471 A 严金学 610112321189 C1 陕A A 0 2014-06-22 00:00:00 15d64d63c83dee22d49f2b5cb 370725199311303771 A 孟豪 610112321197 C1 陕A A 0 2014-06-22 00:00:00 15d64d63c83dee22d49f2b631 610623197809161611 A 李延平 610623034843 B2D 陕J A 0 2004-06-22 00:00:00 15d64d63c83dee22d49f2b5a4 130406199508080321 A 刘醒晗 610113382523 C1 陕A A 0 2017-06-22 00:00:00 1 模糊查询1$ hive -S -e &quot;set&quot; | grep warehouse; 当我们记不清那个属性名的时候,我们可以通过上面的方式进行查询。 从文件中执行Hive查询执行脚本1hive -f /path/data.hql hiverc文件用处当启动cli的时候,hive会自动在hom目录下寻找.hiverc的文件,然后执行相关命令之后进入cli。 所以，对于频繁操作的命令，我们可以加入到这个文件中。 自动补全TAB输入部分字母，然后按TAB实现自动补全。 执行shell命令执行shell命令不需要推出，直接在前面加！即可。 在hive中执行dfs命令1hive&gt; dfs -ls /; hive中的注释在命令前面加”–”即可。 显示字段命令1hive -e set hive.cli.print.header=true; 参考文档 官方文档 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"大数据","slug":"大数据","permalink":"https://lywlefan.github.io/tags/大数据/"},{"name":"hive","slug":"hive","permalink":"https://lywlefan.github.io/tags/hive/"}]},{"title":"java的IO流相关问题","date":"2020-03-31T16:00:00.000Z","path":"2020/04/01/软件研发/后端/基础巩固/java/流/java流相关问题/","text":"BIO、NIO、AIO、Netty什么是IO Java中I/O是以流为基础进行数据的输入输出的，所有数据被串行化(所谓串行化就是数据要按顺序进行输入输出)写入输出流。简单来说就是java通过io流方式和外部设备进行交互。 在Java类库中，IO部分的内容是很庞大的，因为它涉及的领域很广泛：标准输入输出，文件的操作，网络上的数据传输流，字符串流，对象流等等等。 比如程序从服务器上下载图片，就是通过流的方式从网络上以流的方式到程序中，在到硬盘中 在了解不同的IO之前先了解：同步与异步，阻塞与非阻塞的区别 同步，一个任务的完成之前不能做其他操作，必须等待（等于在打电话） 异步，一个任务的完成之前，可以进行其他操作（等于在聊QQ） 阻塞，是相对于CPU来说的， 挂起当前线程，不能做其他操作只能等待 非阻塞,，无须挂起当前线程，可以去执行其他操作 什么是BIO BIO：同步并阻塞，服务器实现一个连接一个线程，即客户端有连接请求时服务器端就需要启动一个线程进行处理，没处理完之前此线程不能做其他操作（如果是单线程的情况下，我传输的文件很大呢？），当然可以通过线程池机制改善。BIO方式适用于连接数目比较小且固定的架构，这种方式对服务器资源要求比较高，并发局限于应用中，JDK1.4以前的唯一选择，但程序直观简单易理解。 什么是NIO NIO:同步非阻塞，服务器实现一个连接一个线程，即客户端发送的连接请求都会注册到多路复用器上，多路复用器轮询到连接有I/O请求时才启动一个线程进行处理。NIO方式适用于连接数目多且连接比较短（轻操作）的架构，比如聊天服务器，并发局限于应用中，编程比较复杂，JDK1.4之后开始支持。 什么是AIO AIO：异步非阻塞，服务器实现模式为一个有效请求一个线程，客户端的I/O请求都是由操作系统先完成了再通知服务器应用去启动线程进行处理，AIO方式使用于连接数目多且连接比较长（重操作）的架构，比如相册服务器，充分调用操作系统参与并发操作，编程比较复杂，JDK1.7之后开始支持。. AIO属于NIO包中的类实现，其实IO主要分为BIO和NIO，AIO只是附加品，解决IO不能异步的实现 在以前很少有Linux系统支持AIO，Windows的IOCP就是该AIO模型。但是现在的服务器一般都是支持AIO操作 什么Netty Netty是由JBOSS提供的一个Java开源框架。Netty提供异步的、事件驱动的网络应用程序框架和工具，用以快速开发高性能、高可靠性的网络服务器和客户端程序。 Netty 是一个基于NIO的客户、服务器端编程框架，使用Netty 可以确保你快速和简单的开发出一个网络应用，例如实现了某种协议的客户，服务端应用。Netty相当简化和流线化了网络应用的编程开发过程，例如，TCP和UDP的socket服务开发。 Netty是由NIO演进而来，使用过NIO编程的用户就知道NIO编程非常繁重，Netty是能够能跟好的使用NIO BIO和NIO、AIO的区别 BIO是阻塞的，NIO是非阻塞的. BIO是面向流的，只能单向读写，NIO是面向缓冲的, 可以双向读写 使用BIO做Socket连接时，由于单向读写，当没有数据时，会挂起当前线程，阻塞等待，为防止影响其它连接,，需要为每个连接新建线程处理.，然而系统资源是有限的,，不能过多的新建线程，线程过多带来线程上下文的切换，从来带来更大的性能损耗，因此需要使用NIO进行BIO多路复用，使用一个线程来监听所有Socket连接，使用本线程或者其他线程处理连接 AIO是非阻塞 以异步方式发起 I/O 操作。当 I/O 操作进行时可以去做其他操作，由操作系统内核空间提醒IO操作已完成（不懂的可以往下看） IO流的分类 按照读写的单位大小来分： 字符流：以字符为单位，每次次读入或读出是16位数据。其只能读取字符类型数据。 (Java代码接收数据为一般为char数组，也可以是别的) 字节流：以字节为单位，每次次读入或读出是8位数据。可以读任何类型数据，图片、文件、音乐视频等。 (Java代码接收数据只能为byte数组) 按照实际IO操作来分： 输出流：从内存读出到文件。只能进行写操作。 输入流：从文件读入到内存。只能进行读操作。 注意：输出流可以帮助我们创建文件，而输入流不会。 按照读写时是否直接与硬盘，内存等节点连接分： 节点流：直接与数据源相连，读入或读出。 处理流：也叫包装流，是对一个对于已存在的流的连接进行封装，通过所封装的流的功能调用实现数据读写。如添加个Buffering缓冲区。（意思就是有个缓存区，等于软件和mysql中的redis） 注意：为什么要有处理流？主要作用是在读入或写出时，对数据进行缓存，以减少I/O的次数，以便下次更好更快的读写文件，才有了处理流。 什么是内核空间 我们的应用程序是不能直接访问硬盘的，我们程序没有权限直接访问，但是操作系统（Windows、Linux……）会给我们一部分权限较高的内存空间，他叫内核空间，和我们的实际硬盘空间是有区别的 五种IO模型 注意：我这里的用户空间就是应用程序空间 1.阻塞BIO（blocking I/O） A拿着一支鱼竿在河边钓鱼，并且一直在鱼竿前等，在等的时候不做其他的事情，十分专心。只有鱼上钩的时，才结束掉等的动作，把鱼钓上来。 在内核将数据准备好之前，系统调用会一直等待所有的套接字，默认的是阻塞方式。 2.非阻塞NIO（noblocking I/O） B也在河边钓鱼，但是B不想将自己的所有时间都花费在钓鱼上，在等鱼上钩这个时间段中，B也在做其他的事情（一会看看书，一会读读报纸，一会又去看其他人的钓鱼等），但B在做这些事情的时候，每隔一个固定的时间检查鱼是否上钩。一旦检查到有鱼上钩，就停下手中的事情，把鱼钓上来。 B在检查鱼竿是否有鱼，是一个轮询的过程。 3.异步AIO（asynchronous I/O） C也想钓鱼，但C有事情，于是他雇来了D、E、F，让他们帮他等待鱼上钩，一旦有鱼上钩，就打电话给C，C就会将鱼钓上去。 当应用程序请求数据时，内核一方面去取数据报内容返回，另一方面将程序控制权还给应用进程，应用进程继续处理其他事情，是一种非阻塞的状态。 4.信号驱动IO（signal blocking I/O） G也在河边钓鱼，但与A、B、C不同的是，G比较聪明，他给鱼竿上挂一个铃铛，当有鱼上钩的时候，这个铃铛就会被碰响，G就会将鱼钓上来。 信号驱动IO模型，应用进程告诉内核：当数据报准备好的时候，给我发送一个信号，对SIGIO信号进行捕捉，并且调用我的信号处理函数来获取数据报。 5.IO多路转接（I/O multiplexing） H同样也在河边钓鱼，但是H生活水平比较好，H拿了很多的鱼竿，一次性有很多鱼竿在等，H不断的查看每个鱼竿是否有鱼上钩。增加了效率，减少了等待的时间。 IO多路转接是多了一个select函数，select函数有一个参数是文件描述符集合，对这些文件描述符进行循环监听，当某个文件描述符就绪时，就对这个文件描述符进行处理。 IO多路转接是属于阻塞IO，但可以对多个文件描述符进行阻塞监听，所以效率较阻塞IO的高。 什么是比特(Bit),什么是字节(Byte),什么是字符(Char),它们长度是多少,各有什么区别 Bit最小的二进制单位 ，是计算机的操作部分取值0或者1 Byte是计算机中存储数据的单元，是一个8位的二进制数，（计算机内部，一个字节可表示一个英文字母，两个字节可表示一个汉字。） 取值（-128-127） Char是用户的可读写的最小单位，他只是抽象意义上的一个符号。如‘5’，‘中’，‘￥’ 等等等等。在java里面由16位bit组成Char 取值（0-65535） Bit 是最小单位 计算机他只能认识0或者1 Byte是8个字节 是给计算机看的 字符 是看到的东西 一个字符=二个字节 什么叫对象序列化，什么是反序列化，实现对象序列化需要做哪些工作 对象序列化，将对象以二进制的形式保存在硬盘上 反序列化；将二进制的文件转化为对象读取 实现serializable接口，不想让字段放在硬盘上就加transient 在实现序列化接口是时候一般要生成一个serialVersionUID字段,它叫做什么,一般有什么用 如果用户没有自己声明一个serialVersionUID,接口会默认生成一个serialVersionUID 但是强烈建议用户自定义一个serialVersionUID,因为默认的serialVersinUID对于class的细节非常敏感，反序列化时可能会导致InvalidClassException这个异常。 （比如说先进行序列化，然后在反序列化之前修改了类，那么就会报错。因为修改了类，对应的SerialversionUID也变化了，而序列化和反序列化就是通过对比其SerialversionUID来进行的，一旦SerialversionUID不匹配，反序列化就无法成功。 怎么生成SerialversionUID 可序列化类可以通过声明名为 “serialVersionUID” 的字段（该字段必须是静态 (static)、最终 (final) 的 long 型字段）显式声明其自己的 serialVersionUID 两种显示的生成方式（当你一个类实现了Serializable接口，如果没有显示的定义serialVersionUID，Eclipse会提供这个提示功能告诉你去定义 。在Eclipse中点击类中warning的图标一下，Eclipse就会自动给定两种生成的方式。 BufferedReader属于哪种流,它主要是用来做什么的,它里面有那些经典的方法 属于处理流中的缓冲流，可以将读取的内容存在内存里面，有readLine（）方法 Java中流类的超类主要有那些？ 超类代表顶端的父类（都是抽象类） java.io.InputStream java.io.OutputStream java.io.Reader java.io.Writer 为什么图片、视频、音乐、文件等 都是要字节流来读取 这个很基础，你看看你电脑文件的属性就好了，CPU规定了计算机存储文件都是按字节算的 IO的常用类和方法，以及如何使用注意，如果懂IO的普通文件读写操作可以直接点击此处跳过，直接看网络操作IO编程，那个才是重点，点击即会跳转 前面讲了那么多废话，现在我们开始进入主题，后面很长，从开始的文件操作到后面的网络IO操作都会有例子： 在这里插入图片描述 注意，如果懂IO的普通文件读写操作可以直接点击此处跳过，直接看网络操作IO编程，那个才是重点，点击即会跳转 IO基本操作讲解 这里的基本操作就是普通的读取操作，如果想要跟深入的了解不同的IO开发场景必须先了解IO的基本操作 1 按字符流读取文件1.1 按字符流的·节点流方式读取 如果我们要取的数据基本单位是字符，那么用（字符流）这种方法读取文件就比较适合。比如：读取test.txt文件 注释： 字符流：以字符为单位，每次次读入或读出是16位数据。其只能读取字符类型数据。 (Java代码接收数据为一般为char数组，也可以是别的) 字节流：以字节为单位，每次次读入或读出是8位数据。可以读任何类型数据，图片、文件、音乐视频等。 (Java代码接收数据只能为byte数组) FileReader 类：（字符输入流） 注意：new FileReader(“D:\\test.txt”);//文件必须存在 1234567891011121314151617181920212223package com.test.io;import java.io.FileReader;import java.io.IOException;public class TestFileReader &#123; public static void main(String[] args) throws IOException &#123; int num=0; //字符流接收使用的char数组 char[] buf=new char[1024]; //字符流、节点流打开文件类 FileReader fr = new FileReader(&quot;D:\\\\test.txt&quot;);//文件必须存在 //FileReader.read()：取出字符存到buf数组中,如果读取为-1代表为空即结束读取。 //FileReader.read()：读取的是一个字符，但是java虚拟机会自动将char类型数据转换为int数据， //如果你读取的是字符A，java虚拟机会自动将其转换成97，如果你想看到字符可以在返回的字符数前加（char）强制转换如 while((num=fr.read(buf))!=-1) &#123; &#125; //检测一下是否取到相应的数据 for(int i=0;i&lt;buf.length;i++) &#123; System.out.print(buf[i]); &#125; &#125;&#125;复制代码 运行结果： · 1.2 按字符流的·处理流方式读取 效果是一样，但是给了我们有不同的选择操作。进行了一个小封装，加缓冲功能，避免频繁读写硬盘。我这只是简单演示，处理流其实还有很多操作 BufferedReader 类： 字符输入流使用的类，加缓冲功能，避免频繁读写硬盘 1234567891011121314151617181920212223242526272829package com.test.io;import java.io.BufferedReader;import java.io.FileReader;import java.io.IOException;public class TestBufferedReader &#123; public static void main(String[] args) throws IOException &#123; int num=0; //字符流接收使用的String数组 String[] bufstring=new String[1024]; //字符流、节点流打开文件类 FileReader fr = new FileReader(&quot;D:\\\\test.txt&quot;);//文件必须存在 //字符流、处理流读取文件类 BufferedReader br = new BufferedReader(fr); //临时接收数据使用的变量 String line=null; //BufferedReader.readLine()：单行读取，读取为空返回null while((line=br.readLine())!=null) &#123; bufstring[num]=line; num++; &#125; br.close();//关闭文件 for(int i=0;i&lt;num;i++) &#123; System.out.println(bufstring[i]); &#125; &#125;&#125;复制代码 测试效果一样 2 按字符流写出文件2.1 按字符流的·节点流方式写出 写出字符，使用（字符流）这种方法写出文件比较适合。比如：输出内容添加到test.txt文件 FileWriter类：（字符输出流），如果写出文件不存在会自动创建一个相对应的文件。使用FileWriter写出文件默认是覆盖原文件，如果要想在源文件添加内容不覆盖的话，需要构造参数添加true参数：看示例了解 123456789101112131415161718192021package com.test.io;import java.io.File;import java.io.FileWriter;import java.io.IOException;public class TestFileWriter &#123; public static void main(String[] args) throws IOException &#123; //File是操作文件类 File file = new File(&quot;D:\\\\test.txt&quot;);//文件必须存在 //字符流、节点流写出文件类 //new FileWriter(file,true)，这个true代表追加，不写就代表覆盖文件 FileWriter out=new FileWriter(file,true); //写入的字节,\\n代表换行 String str=&quot;\\nholler&quot;; //写入 out.write(str); out.close(); &#125;&#125;复制代码 运行效果 ： 2.2 按字符流的·处理流方式写出 BufferedWriter ： 增加缓冲功能，避免频繁读写硬盘。 我这里： //new FileWriter(file)，这里我只给了他文件位置，我没加true代表覆盖源文件 12345678910111213141516171819package com.test.io;import java.io.*;public class TestBufferedWriter &#123; public static void main(String[] args) throws IOException &#123; //File是操作文件类 File file = new File(&quot;D:\\\\test.txt&quot;);//文件必须存在 //字符流、节点流写出文件类 //new FileWriter(file)，这个我没加true代表覆盖文件 Writer writer = new FileWriter(file); ////字符流、处理流写出文件类 BufferedWriter bw = new BufferedWriter(writer); bw.write(&quot;\\n小心&quot;); bw.close(); writer.close(); &#125;&#125;复制代码 运行效果 ： 3 按字节流写入写出文件3.1 按字节流的·节点流写入写出文件 如果我们要取的数据 图片、文件、音乐视频等类型，就必须使用字节流进行读取写出 注释： 字符流：以字符为单位，每次次读入或读出是16位数据。其只能读取字符类型数据。 (Java代码接收数据为一般为char数组，也可以是别的) 字节流：以字节为单位，每次次读入或读出是8位数据。可以读任何类型数据，图片、文件、音乐视频等。 (Java代码接收数据只能为byte数组) FileInputStream：（字节输入流） FileOutputStream：（字节输出流） 123456789101112131415161718192021222324package com.test.io;import java.io.FileInputStream;import java.io.FileOutputStream;import java.io.IOException;public class TestFileOutputStream &#123; public static void main(String[] args) throws IOException &#123; //创建字节输入流、节点流方式读取文件 FileInputStream fis = new FileInputStream(&quot;D:\\\\Akie秋绘 - Lemon（Cover：米津玄師）.mp3&quot;); //创建字节输入流、节点流方式输出文件 FileOutputStream fos = new FileOutputStream(&quot;D:\\\\copy.mp3&quot;); //根据文件大小做一个字节数组 byte[] arr = new byte[fis.available()]; //将文件上的所有字节读取到数组中 fis.read(arr); //将数组中的所有字节一次写到了文件上 fos.write(arr); fis.close(); fos.close(); &#125;&#125;复制代码 运行之前： 运行之后： 3.2 按字节流的·处理流写入写出文件 FileInputStream：（字节输入流） FileOutputStream：（字节输出流） BufferedInputStream：（带缓冲区字节输入流） BufferedOutputStream：（带缓冲区字节输入流） 带缓冲区的处理流，缓冲区的作用的主要目的是：避免每次和硬盘打交道，提高数据访问的效率。 123456789101112131415161718192021222324package com.test.io;import java.io.*;public class TestBufferedOutputStream &#123; //创建文件输入流对象,关联致青春.mp3 public static void main(String[] args) throws IOException &#123; FileInputStream fis = new FileInputStream(&quot;D:\\\\copy.mp3&quot;); //创建缓冲区对fis装饰 BufferedInputStream bis = new BufferedInputStream(fis); //创建输出流对象,关联copy.mp3 FileOutputStream fos = new FileOutputStream(&quot;D:\\\\copy2.mp3&quot;); //创建缓冲区对fos装饰 BufferedOutputStream bos = new BufferedOutputStream(fos); //循环直接输出 int i; while((i = bis.read()) != -1) &#123; bos.write(i); &#125; bis.close(); bos.close(); &#125;&#125;复制代码 运行之前： 运行之后： 网络操作IO讲解 我这使用Socket简单的来模拟网络编程IO会带来的问题 不懂Socket可以看我之前的文章，这个东西很容易懂的，就是基于TCP实现的网络通信，比http要快，很多实现网络通信的框架都是基于Socket来实现 网络操作IO编程演变历史1 BIO编程会出现什么问题？ BIO是阻塞的 例子： 阻塞IO（blocking I/O） A拿着一支鱼竿在河边钓鱼，并且一直在鱼竿前等，在等的时候不做其他的事情，十分专心。只有鱼上钩的时，才结束掉等的动作，把鱼钓上来。 看起来没问题，但是我很多请求一起发送请求资源怎么办： 那不是要等待第一个人资源完成后后面的人才可以继续？ 因为BIO是阻塞的所以读取写出操作都是非常浪费资源的 BIO代码示例：（后面有代码，往后移动一点点，认真看，代码学习量很足） 我这有三个类，我模拟启动服务端，然后启动客户端，模拟客户端操作未完成的时候启动第二个客户端 启动服务端（ 1后面有代码，我这是教运行顺序 ） 启动第一个客户端，发现服务器显示连接成功 1先不要在控制台 输入 ，模拟堵塞。（我的代码输入了就代表请求完成了） · 启动第二个客户端， 1发现服务端没效果 ，而客户端连接成功（在堵塞当中） 1我这启动了俩个Client，注意看，(这俩个代码是一样的) · 第一个客户控制台输入，输入完后就会关闭第一个客户端， 在看服务端发现第二个客户端连接上来了 · BIO通信代码： TCP协议Socket使用BIO进行通信：服务端（先执行） 1234567891011121314151617181920212223242526272829303132333435363738394041package com.test.io;import java.io.IOException;import java.io.InputStream;import java.io.OutputStream;import java.net.ServerSocket;import java.net.Socket;//TCP协议Socket使用BIO进行通信：服务端public class BIOServer &#123; // 在main线程中执行下面这些代码 public static void main(String[] args) &#123; //使用Socket进行网络通信 ServerSocket server = null; Socket socket = null; //基于字节流 InputStream in = null; OutputStream out = null; try &#123; server = new ServerSocket(8000); System.out.println(&quot;服务端启动成功，监听端口为8000，等待客户端连接...&quot;); while (true)&#123; socket = server.accept(); //等待客户端连接 System.out.println(&quot;客户连接成功，客户信息为：&quot; + socket.getRemoteSocketAddress()); in = socket.getInputStream(); byte[] buffer = new byte[1024]; int len = 0; //读取客户端的数据 while ((len = in.read(buffer)) &gt; 0) &#123; System.out.println(new String(buffer, 0, len)); &#125; //向客户端写数据 out = socket.getOutputStream(); out.write(&quot;hello!&quot;.getBytes()); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125;复制代码 TCP协议Socket使用BIO进行通信：客户端（第二执行） 12345678910111213141516171819202122232425262728package com.test.io;import java.io.IOException;import java.io.OutputStream;import java.net.Socket;import java.util.Scanner;//TCP协议Socket使用BIO进行通信：客户端public class Client01 &#123; public static void main(String[] args) throws IOException &#123; //创建套接字对象socket并封装ip与port Socket socket = new Socket(&quot;127.0.0.1&quot;, 8000); //根据创建的socket对象获得一个输出流 //基于字节流 OutputStream outputStream = socket.getOutputStream(); //控制台输入以IO的形式发送到服务器 System.out.println(&quot;TCP连接成功 \\n请输入：&quot;); String str = new Scanner(System.in).nextLine(); byte[] car = str.getBytes(); outputStream.write(car); System.out.println(&quot;TCP协议的Socket发送成功&quot;); //刷新缓冲区 outputStream.flush(); //关闭连接 socket.close(); &#125;&#125;复制代码 TCP协议Socket使用BIO进行通信：客户端（第三执行） 1234567891011121314151617181920212223242526272829package com.test.io;import java.io.IOException;import java.io.OutputStream;import java.net.Socket;import java.util.Scanner;//TCP协议Socket：客户端public class Client02 &#123; public static void main(String[] args) throws IOException &#123; //创建套接字对象socket并封装ip与port Socket socket = new Socket(&quot;127.0.0.1&quot;, 8000); //根据创建的socket对象获得一个输出流 //基于字节流 OutputStream outputStream = socket.getOutputStream(); //控制台输入以IO的形式发送到服务器 System.out.println(&quot;TCP连接成功 \\n请输入：&quot;); String str = new Scanner(System.in).nextLine(); byte[] car = str.getBytes(); outputStream.write(car); System.out.println(&quot;TCP协议的Socket发送成功&quot;); //刷新缓冲区 outputStream.flush(); //关闭连接 socket.close(); &#125;&#125;复制代码为了解决堵塞问题，可以使用多线程，请看下面 2 多线程解决BIO编程会出现的问题这时有人就会说，我多线程不就解决了吗? 使用多线程是可以解决堵塞等待时间很长的问题，因为他可以充分发挥CPU 然而系统资源是有限的，不能过多的新建线程，线程过多带来线程上下文的切换，从来带来更大的性能损耗 万一请求越来越多，线程越来越多那我CPU不就炸了？ 在这里插入图片描述 多线程BIO代码示例： 四个客户端，这次我多复制了俩个一样客户端类 1先启动服务端，在启动所有客户端，测试 ，发现连接成功（ 1后面有代码 ） 在所有客户端输入消息（ 1Client01、Client02这些是我在客户端输入的消息 ）：发现没有问题 多线程BIO通信代码： 服务端的代码，客户端的代码还是上面之前的代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package com.test.io;import java.io.IOException;import java.io.InputStream;import java.io.OutputStream;import java.net.ServerSocket;import java.net.Socket;//TCP协议Socket使用多线程BIO进行通行：服务端public class BIOThreadService &#123; public static void main(String[] args) &#123; try &#123; ServerSocket server = new ServerSocket(8000); System.out.println(&quot;服务端启动成功，监听端口为8000，等待客户端连接... &quot;); while (true) &#123; Socket socket = server.accept();//等待客户连接 System.out.println(&quot;客户连接成功，客户信息为：&quot; + socket.getRemoteSocketAddress()); //针对每个连接创建一个线程， 去处理I0操作 //创建多线程创建开始 Thread thread = new Thread(new Runnable() &#123; public void run() &#123; try &#123; InputStream in = socket.getInputStream(); byte[] buffer = new byte[1024]; int len = 0; //读取客户端的数据 while ((len = in.read(buffer)) &gt; 0) &#123; System.out.println(new String(buffer, 0, len)); &#125; //向客户端写数据 OutputStream out = socket.getOutputStream(); out.write(&quot;hello&quot;.getBytes()); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); thread.start(); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125;复制代码为了解决线程太多，这时又来了，线程池 3 线程池解决多线程BIO编程会出现的问题这时有人就会说，我TM用线程池? 在这里插入图片描述 线程池固然可以解决这个问题，万一需求量还不够还要扩大线程池。当是这是我们自己靠着自己的思想完成的IO操作，Socket 上来了就去创建线程去抢夺CPU资源，MD，线程都TM做IO去了，CPU也不舒服呀 这时呢：Jdk官方坐不住了，兄弟BIO的问题交给我，我来给你解决：NIO的诞生 线程池BIO代码示例： 四个客户端 1先启动服务端，在启动所有客户端，测试 ，（ 1后面有代码 ） 在所有客户端输入消息（ 1Client01、Client02这些是我在客户端输入的消息 ）：发现没有问题 线程池BIO通信代码： 服务端的代码，客户端的代码还是上面的代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package com.test.io;import java.io.IOException;import java.io.InputStream;import java.io.OutputStream;import java.net.ServerSocket;import java.net.Socket;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;//TCP协议Socket使用线程池BIO进行通行：服务端public class BIOThreadPoolService &#123; public static void main(String[] args) &#123; //创建线程池 ExecutorService executorService = Executors.newFixedThreadPool(30); try &#123; ServerSocket server = new ServerSocket(8000); System.out.println(&quot;服务端启动成功，监听端口为8000，等待客户端连接...&quot;); while (true) &#123; Socket socket = server.accept();//等待客户连接 System.out.println(&quot;客户连接成功，客户信息为：&quot; + socket.getRemoteSocketAddress()); //使用线程池中的线程去执行每个对应的任务 executorService.execute(new Thread(new Runnable() &#123; public void run() &#123; try &#123; InputStream in = socket.getInputStream(); byte[] buffer = new byte[1024]; int len = 0; //读取客户端的数据 while ((len = in.read(buffer)) &gt; 0) &#123; System.out.println(new String(buffer, 0, len)); &#125; //向客户端写数据 OutputStream out = socket.getOutputStream(); out.write(&quot;hello&quot;.getBytes()); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;) ); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125;复制代码 4 使用NIO实现网络通信 NIO是JDK1.4提供的操作，他的流还是流，没有改变，服务器实现的还是一个连接一个线程，当是：客户端发送的连接请求都会注册到多路复用器上，多路复用器轮询到连接有I/O请求时才启动一个线程进行处理。NIO方式适用于连接数目多且连接比较短（轻操作）的架构，比如聊天服务器，并发局限于应用中，编程比较复杂，JDK1.4之后开始支持。 1看不懂介绍可以认真看看代码实例，其实不难 什么是通道（Channel） Channel是一个对象，可以通过它读取和写入数据。 通常我们都是将数据写入包含一个或者多个字节的缓冲区，然后再将缓存区的数据写入到通道中，将数据从通道读入缓冲区，再从缓冲区获取数据。 Channel 类似于原I/O中的流（Stream），但有所区别： 流是单向的，通道是双向的，可读可写。 流读写是阻塞的，通道可以异步读写。 什么是选择器（Selector） Selector可以称他为通道的集合，每次客户端来了之后我们会把Channel注册到Selector中并且我们给他一个状态，在用死循环来环判断(判断是否做完某个操作，完成某个操作后改变不一样的状态)状态是否发生变化，知道IO操作完成后在退出死循环 什么是Buffer（缓冲区） Buffer 是一个缓冲数据的对象， 它包含一些要写入或者刚读出的数据。 在普通的面向流的 I/O 中，一般将数据直接写入或直接读到 Stream 对象中。当是有了Buffer（缓冲区）后，数据第一步到达的是Buffer（缓冲区）中 缓冲区实质上是一个数组(底层完全是数组实现的，感兴趣可以去看一下)。通常它是一个字节数组，内部维护几个状态变量，可以实现在同一块缓冲区上反复读写（不用清空数据再写）。 代码实例： 目录结构 运行示例，先运行服务端，在运行所有客户端控制台输入消息就好了。： 1我这客户端和服务端代码有些修该变，后面有代码 服务端示例，先运行，想要搞定NIO请认真看代码示例，真的很清楚 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687package com.test.io;import com.lijie.iob.RequestHandler;import java.io.IOException;import java.net.InetSocketAddress;import java.nio.ByteBuffer;import java.nio.channels.SelectionKey;import java.nio.channels.Selector;import java.nio.channels.ServerSocketChannel;import java.nio.channels.SocketChannel;import java.util.Iterator;import java.util.Set;public class NIOServer &#123; public static void main(String[] args) throws IOException &#123; //111111111 //Service端的Channel，监听端口的 ServerSocketChannel serverChannel = ServerSocketChannel.open(); //设置为非阻塞 serverChannel.configureBlocking(false); //nio的api规定这样赋值端口 serverChannel.bind(new InetSocketAddress(8000)); //显示Channel是否已经启动成功，包括绑定在哪个地址上 System.out.println(&quot;服务端启动成功，监听端口为8000，等待客户端连接...&quot;+ serverChannel.getLocalAddress()); //22222222 //声明selector选择器 Selector selector = Selector.open(); //这句话的含义，是把selector注册到Channel上面， //每个客户端来了之后，就把客户端注册到Selector选择器上,默认状态是Accepted serverChannel.register(selector, SelectionKey.OP_ACCEPT); //33333333 //创建buffer缓冲区，声明大小是1024，底层使用数组来实现的 ByteBuffer buffer = ByteBuffer.allocate(1024); RequestHandler requestHandler = new RequestHandler(); //444444444 //轮询，服务端不断轮询，等待客户端的连接 //如果有客户端轮询上来就取出对应的Channel，没有就一直轮询 while (true) &#123; int select = selector.select(); if (select == 0) &#123; continue; &#125; //有可能有很多，使用Set保存Channel Set&lt;SelectionKey&gt; selectionKeys = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; iterator = selectionKeys.iterator(); while (iterator.hasNext()) &#123; //使用SelectionKey来获取连接了客户端和服务端的Channel SelectionKey key = iterator.next(); //判断SelectionKey中的Channel状态如何，如果是OP_ACCEPT就进入 if (key.isAcceptable()) &#123; //从判断SelectionKey中取出Channel ServerSocketChannel channel = (ServerSocketChannel) key.channel(); //拿到对应客户端的Channel SocketChannel clientChannel = channel.accept(); //把客户端的Channel打印出来 System.out.println(&quot;客户端通道信息打印：&quot; + clientChannel.getRemoteAddress()); //设置客户端的Channel设置为非阻塞 clientChannel.configureBlocking(false); //操作完了改变SelectionKey中的Channel的状态OP_READ clientChannel.register(selector, SelectionKey.OP_READ); &#125; //到此轮训到的时候，发现状态是read，开始进行数据交互 if (key.isReadable()) &#123; //以buffer作为数据桥梁 SocketChannel channel = (SocketChannel) key.channel(); //数据要想读要先写，必须先读取到buffer里面进行操作 channel.read(buffer); //进行读取 String request = new String(buffer.array()).trim(); buffer.clear(); //进行打印buffer中的数据 System.out.println(String.format(&quot;客户端发来的消息： %s : %s&quot;, channel.getRemoteAddress(), request)); //要返回数据的话也要先返回buffer里面进行返回 String response = requestHandler.handle(request); //然后返回出去 channel.write(ByteBuffer.wrap(response.getBytes())); &#125; iterator.remove(); &#125; &#125; &#125;&#125;复制代码 客户端示例：（ 1我这用的不是之前的了，有修改 ）运行起来客户端控制台输入消息就好了。 1要模拟测试，请复制粘贴改一下，修改客户端的类名就行了，四个客户端代码一样的 , 1234567891011121314151617181920212223242526package com.test.io;import java.io.IOException;import java.io.OutputStream;import java.net.Socket;import java.util.Scanner;//TCP协议Socket：客户端public class Client01 &#123; public static void main(String[] args) throws IOException &#123; //创建套接字对象socket并封装ip与port Socket socket = new Socket(&quot;127.0.0.1&quot;, 8000); //根据创建的socket对象获得一个输出流 OutputStream outputStream = socket.getOutputStream(); //控制台输入以IO的形式发送到服务器 System.out.println(&quot;TCP连接成功 \\n请输入：&quot;); while(true)&#123; byte[] car = new Scanner(System.in).nextLine().getBytes(); outputStream.write(car); System.out.println(&quot;TCP协议的Socket发送成功&quot;); //刷新缓冲区 outputStream.flush(); &#125; &#125;&#125;复制代码 5 使用Netty实现网络通信 Netty是由JBOSS提供的一个Java开源框架。Netty提供异步的、事件驱动的网络应用程序框架和工具，用以快速开发高性能、高可靠性的网络服务器和客户端程序。 Netty 是一个基于NIO的客户、服务器端编程框架，使用Netty 可以确保你快速和简单的开发出一个网络应用，例如实现了某种协议的客户，服务端应用。Netty相当简化和流线化了网络应用的编程开发过程，例如，TCP和UDP的Socket服务开发。 Netty是由NIO演进而来，使用过NIO编程的用户就知道NIO编程非常繁重，Netty是能够能跟好的使用NIO Netty的原里就是NIO，他是基于NIO的一个完美的封装，并且优化了NIO，使用他非常方便，简单快捷 我直接上代码： 1、先添加依赖： 123456 &lt;dependency&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;artifactId&gt;netty-all&lt;/artifactId&gt; &lt;version&gt;4.1.16.Final&lt;/version&gt; &lt;/dependency&gt;复制代码 2、NettyServer 模板，看起来代码那么多，其实只需要添加一行消息就好了 请认真看中间的代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package com.lijie.iob;import io.netty.bootstrap.ServerBootstrap;import io.netty.channel.*;import io.netty.channel.nio.NioEventLoopGroup;import io.netty.channel.socket.SocketChannel;import io.netty.channel.socket.nio.NioServerSocketChannel;import io.netty.handler.codec.serialization.ClassResolvers;import io.netty.handler.codec.serialization.ObjectEncoder;import io.netty.handler.codec.string.StringDecoder;public class NettyServer &#123; public static void main(String[] args) throws InterruptedException &#123; EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); try &#123; ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel socketChannel) throws Exception &#123; ChannelPipeline pipeline = socketChannel.pipeline(); pipeline.addLast(new StringDecoder()); pipeline.addLast(&quot;encoder&quot;, new ObjectEncoder()); pipeline.addLast(&quot; decoder&quot;, new io.netty.handler.codec.serialization.ObjectDecoder(Integer.MAX_VALUE, ClassResolvers.cacheDisabled(null))); //重点，其他的都是复用的 //这是真正的I0的业务代码，把他封装成一个个的个Hand1e类就行了 //把他当成 SpringMVC的Controller pipeline.addLast(new NettyServerHandler()); &#125; &#125;) .option(ChannelOption.SO_BACKLOG, 128) .childOption(ChannelOption.SO_KEEPALIVE, true); ChannelFuture f = b.bind(8000).sync(); System.out.println(&quot;服务端启动成功，端口号为:&quot; + 8000); f.channel().closeFuture().sync(); &#125; finally &#123; workerGroup.shutdownGracefully(); bossGroup.shutdownGracefully(); &#125; &#125;&#125;复制代码 3、需要做的IO操作，重点是继承ChannelInboundHandlerAdapter类就好了 1234567891011121314151617181920212223242526package com.lijie.iob;import io.netty.channel.Channel;import io.netty.channel.ChannelHandlerContext;import io.netty.channel.ChannelInboundHandlerAdapter;public class NettyServerHandler extends ChannelInboundHandlerAdapter &#123; RequestHandler requestHandler = new RequestHandler(); @Override public void handlerAdded(ChannelHandlerContext ctx) throws Exception &#123; Channel channel = ctx.channel(); System.out.println(String.format(&quot;客户端信息： %s&quot;, channel.remoteAddress())); &#125; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; Channel channel = ctx.channel(); String request = (String) msg; System.out.println(String.format(&quot;客户端发送的消息 %s : %s&quot;, channel.remoteAddress(), request)); String response = requestHandler.handle(request); ctx.write(response); ctx.flush(); &#125;&#125;复制代码 4 客户的代码还是之前NIO的代码，我在复制下来一下吧 1234567891011121314151617181920212223242526package com.test.io;import java.io.IOException;import java.io.OutputStream;import java.net.Socket;import java.util.Scanner;//TCP协议Socket：客户端public class Client01 &#123; public static void main(String[] args) throws IOException &#123; //创建套接字对象socket并封装ip与port Socket socket = new Socket(&quot;127.0.0.1&quot;, 8000); //根据创建的socket对象获得一个输出流 OutputStream outputStream = socket.getOutputStream(); //控制台输入以IO的形式发送到服务器 System.out.println(&quot;TCP连接成功 \\n请输入：&quot;); while(true)&#123; byte[] car = new Scanner(System.in).nextLine().getBytes(); outputStream.write(car); System.out.println(&quot;TCP协议的Socket发送成功&quot;); //刷新缓冲区 outputStream.flush(); &#125; &#125;&#125;复制代码 运行测试，还是之前那样，启动服务端，在启动所有客户端控制台输入就好了： 作者：小杰要吃蛋链接：https://juejin.cn/post/6844904125700784136来源：掘金著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。","tags":[{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"},{"name":"基础","slug":"基础","permalink":"https://lywlefan.github.io/tags/基础/"}]},{"title":"Hive中导入csv数据","date":"2020-03-29T16:00:00.000Z","path":"2020/03/30/软件研发/后端/大数据/存储/hive/Hive中导入csv数据/","text":"Hive中导入csv数据常规表导入数据在hive中创建表通过查看csv的数据结构,在hive中创建一个对应的表,建表语句(以下创建的是内部表,也可以创建外部表)如下: 123456789101112create table if not exists wdc_user_01(id string,number string,type string,name String,archiveNumber string,vehicleType string,licenceOrgan string,status string,totalDockPoints string,licenseDate timestamp,row format delimited fields terminated by &apos;,&apos;; 导入数据1hive&gt; load data local inpath &apos;/tmp/certificate.csv&apos; overwrite into table open_user; 查看数据查看数据总条数 1select count(*) from open_user; 查看数据情况 1select * from open_user limit 100; 分区表数据导入按身份证最后一位进行分区前期准备工作先通过常规表数据的导入方式,把csv的数据导入到certificate表中。 分区方式动态分区 创建分区表12345678910111213hive&gt; create table if not exists wdc_user_03(id string,number string,type string,name String,archiveNumber string,vehicleType string,licenceOrgan string,status string,totalDockPoints string,licenseDate timestamp)PARTITIONED BY (code string)row format delimited fields terminated by &apos;,&apos;; 相关设置关闭严格分区模式1hive&gt; set hive.exec.dynamic.partition.mode=nonstrict 开启动态分区1hive&gt; set hive.exec.dynamic.partition=true 设置最大动态分区数1hive&gt; set hive.exec.max.dynamic.partitions=1000 //最大动态分区数,默认1000 导入数据12hive&gt; insert overwrite table wdc_user_03 partition (code) select id,number,type,name ,archiveNumber,vehicleType,licenceOrgan,status,totalDockPoints,licenseDate,SUBSTRING(number ,0,4) as code from default.certificate; certificate是数据的原始表,从原始表获取数据后,插入wdc_user_03分区表,在插入数据的时候会根据code进行动态的分区。 按年和月分区 参考文档 官方文档 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"大数据","slug":"大数据","permalink":"https://lywlefan.github.io/tags/大数据/"},{"name":"hive","slug":"hive","permalink":"https://lywlefan.github.io/tags/hive/"}]},{"title":"Hive的HQL语法详解","date":"2020-03-29T16:00:00.000Z","path":"2020/03/30/软件研发/后端/大数据/存储/hive/Hive的HQL语法详解/","text":"基础语法常用语法修改外部表为内部表1hive&gt; ALTER TABLE stg_mysql__winstar_business_open__open_account SET TBLPROPERTIES(&apos;EXTERNAL&apos;=&apos;False&apos;); 修改空为NULL1hive&gt; alter table stg_mysql__winstar_business_open__open_user_face SET SERDEPROPERTIES(&apos;serialization.null.format&apos; = &apos;&apos;); 建库建表内部表特点 未被external修饰的是内部表（managed table） 内部表数据由Hive自身管理，外部表数据由HDFS管理 内部表数据存储的位置是hive.metastore.warehouse.dir（默认：/user/hive/warehouse） 删除内部表会直接删除元数据（metadata）及存储数据 脚本1234567891011create table t1( id int ,name string ,hobby array&lt;string&gt; ,add map&lt;String,string&gt;)row format delimitedfields terminated by &apos;,&apos;collection items terminated by &apos;-&apos;map keys terminated by &apos;:&apos;; 查看表的描述: 1$ desc t1; 查看表的详细描述 1$ desc formatted table_name; 外部表特点 被external修饰的为外部表（external table） 外部表数据由HDFS管理 外部表数据的存储位置由自己制定（如果没有LOCATION，Hive将在HDFS上的/user/hive/warehouse文件夹下以外部表的表名创建一个文件夹，并将属于这个表的数据存放在这里）； 删除外部表仅仅会删除元数据，HDFS上的文件并不会被删除； 脚本123456789101112create external table t2( id int ,name string ,hobby array&lt;string&gt; ,add map&lt;String,string&gt;)row format delimitedfields terminated by &apos;,&apos;collection items terminated by &apos;-&apos;map keys terminated by &apos;:&apos;location &apos;/user/t2&apos;; 分区表特点脚本12345678CREATE TABLE par_table(viewTime INT, userid BIGINT, page_url STRING, referrer_url STRING, ip STRING COMMENT &apos;IP Address of the User&apos;)COMMENT &apos;This is the page view table&apos;PARTITIONED BY(date STRING, pos STRING)ROW FORMAT DELIMITED ‘\\t’ FIELDS TERMINATED BY &apos;\\n&apos;STORED AS SEQUENCEFILE; 常用脚本显示表分区1hive&gt; show partitions table_name; 根据分区查询数据1hive&gt; select * from table_name where partition_date=&apos;2018-04-10&apos; ; 添加分区1hive&gt; alter table employees add partition (country=&quot;china&quot;,state=&quot;Asia&quot;); 把一个分区打包成一个har包1hive&gt; alter table employees archive partition (country=&quot;china&quot;,state=&quot;Asia&quot;) 把一个分区har包还原成原来的分区1hive&gt; alter table employees unarchive partition (country=&quot;china&quot;,state=&quot;Asia&quot;) 保护分区防止被删除1hive&gt; alter table employees partition (country=&quot;china&quot;,state=&quot;Asia&quot;) enable no_drop 保护分区防止被查询1hive&gt; alter table employees partition (country=&quot;china&quot;,state=&quot;Asia&quot;) enable offline 允许分区删除和查询12hive&gt; alter table employees partition (country=&quot;china&quot;,state=&quot;Asia&quot;) disable no_drophive&gt; alter table employees partition (country=&quot;china&quot;,state=&quot;Asia&quot;) disable offline 插入数据12345格式:hive&gt; INSERT INTO TABLE tablename [PARTITION (partcol1[=val1], partcol2[=val2] ...)] hive&gt; VALUES values_row [, values_row …]; 格式2：（推荐使用）hive&gt; load data local inpath &apos;/home/had/data1.txt&apos; into table employees partition (country =china,state=Asia) case语句和like1234创建表，携带数据create table employees1 as select * from employees1创建表，携带表结构create table employees2 like employees Bucket表特点 bucket table(桶表)是对数据进行哈希取值，然后放到不同文件中存储 。 脚本123456789CREATE TABLE par_table(viewTime INT, userid BIGINT, page_url STRING, referrer_url STRING, ip STRING COMMENT &apos;IP Address of the User&apos;)COMMENT &apos;This is the page view table&apos;PARTITIONED BY(date STRING, pos STRING)CLUSTERED BY(userid) SORTED BY(viewTime) INTO 32 BUCKETSROW FORMAT DELIMITED ‘\\t’ FIELDS TERMINATED BY &apos;\\n&apos;STORED AS SEQUENCEFILE; 注: \\t 代表的是字段之间是通过tab进行分割的，\\n指的是行之间是断行。 装载数据insert into 一般很少用insert （不是insert overwrite）语句，因为就算就算插入一条数据，也会调用MapReduce，这里我们选择Load Data的方式。 load data 1hive&gt; load data local inpath &apos;/home/hadoop/Desktop/data&apos; overwrite into table t2; Bucket表注意事项①执行insert前不要忘记设置 1set hive.enforce.bucketing = true; 参考文档 官方文档 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"大数据","slug":"大数据","permalink":"https://lywlefan.github.io/tags/大数据/"},{"name":"hive","slug":"hive","permalink":"https://lywlefan.github.io/tags/hive/"}]},{"title":"Hive的配置文件学习","date":"2020-03-27T16:00:00.000Z","path":"2020/03/28/软件研发/后端/大数据/存储/hive/Hive的配置文件学习/","text":"hive-site.xml配置文件数据库配置配置数据库地址 参考文档 官方文档 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"大数据","slug":"大数据","permalink":"https://lywlefan.github.io/tags/大数据/"},{"name":"hive","slug":"hive","permalink":"https://lywlefan.github.io/tags/hive/"}]},{"title":"ES的Mapping学习总结","date":"2020-03-25T16:00:00.000Z","path":"2020/03/26/软件研发/后端/搜索引擎/es/ES的Mapping学习总结/","text":"参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 【3】elasticsearch官网 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"搜索引擎","slug":"搜索引擎","permalink":"https://lywlefan.github.io/tags/搜索引擎/"},{"name":"es","slug":"es","permalink":"https://lywlefan.github.io/tags/es/"}]},{"title":"Hive的安装","date":"2020-03-24T16:00:00.000Z","path":"2020/03/25/软件研发/后端/大数据/存储/hive/Hive的安装/","text":"Hive下载安装下载地址下载地址 安装步骤解压hive到指定文件夹1$ tar -xzvf apache-hive-3.1.2-bin.tar.gz 在/conf文件夹下配置hive-site.xml12345678910111213141516171819202122232425262728&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;no&quot;?&gt;&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;&lt;configuration&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt; &lt;value&gt;jdbc:mysql://192.168.118.8:23306/hive_test&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt; &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt; &lt;value&gt;root&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt; &lt;value&gt;123456&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hive.metastore.schema.verification&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 如果没有该文件,直接新建即可!该配置文件主要配置了mysql 的连接地址! 导入mysql驱动到lib文件夹导入mysql-connector-java-5.1.20.jar到hive的lib文件夹下。 初始化hive在mysql中的表1$ schematool -dbType mysql -initSchema 启动停止hive进入hive客户端1$ hive 启动hiveServer1$ hiveserver2 &amp; hiveServer是hive提供的jdbc连接hive的一种方式 测试在hive中创建一个库1231 hive&gt; create database hive_1;2 OK3 Time taken: 1.432 seconds 查看hive中的库1231 hive&gt; create database hive_1;2 OK3 Time taken: 1.432 seconds 切换到创建的库上1231 hive&gt; create database hive_1;2 OK3 Time taken: 1.432 seconds 在当前库创建一张表1231 hive&gt; create database hive_1;2 OK3 Time taken: 1.432 seconds 查看当前库里面所有的表1234hive&gt; show tables;OKhive_01Time taken: 0.107 seconds, Fetched: 1 row(s) 通过mysql查询创建的表1select * from TBLS; 通过hsfs的web界面查看我们创建的表 1585207863239 以上就是hive 的安装步骤!!! 遇到问题启动hive报错报错详情123456789101112131415161718192021SLF4J: Class path contains multiple SLF4J bindings.SLF4J: Found binding in [jar:file:/opt/software/hive/apache-hive-3.1.2-bin/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]SLF4J: Found binding in [jar:file:/opt/software/hadoop/hadoop-3.1.3/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]Exception in thread &quot;main&quot; java.lang.NoSuchMethodError: com.google.common.base.Preconditions.checkArgument(ZLjava/lang/String;Ljava/lang/Object;)V at org.apache.hadoop.conf.Configuration.set(Configuration.java:1357) at org.apache.hadoop.conf.Configuration.set(Configuration.java:1338) at org.apache.hadoop.mapred.JobConf.setJar(JobConf.java:518) at org.apache.hadoop.mapred.JobConf.setJarByClass(JobConf.java:536) at org.apache.hadoop.mapred.JobConf.&lt;init&gt;(JobConf.java:430) at org.apache.hadoop.hive.conf.HiveConf.initialize(HiveConf.java:5141) at org.apache.hadoop.hive.conf.HiveConf.&lt;init&gt;(HiveConf.java:5104) at org.apache.hive.beeline.HiveSchemaTool.&lt;init&gt;(HiveSchemaTool.java:96) at org.apache.hive.beeline.HiveSchemaTool.main(HiveSchemaTool.java:1473) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.hadoop.util.RunJar.run(RunJar.java:318) at org.apache.hadoop.util.RunJar.main(RunJar.java:232) 错误原因guava版本太低造成的。 错误解决提升版本，删除lib文件夹下的guava原jar包，然后去maven仓库下载最新jar包放入即可！ 创建库报错错误详情1FAILED: HiveException java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient 错误原因hive数据库格式化失败错误详情123456789101112SLF4J: Class path contains multiple SLF4J bindings.SLF4J: Found binding in [jar:file:/opt/software/hive/apache-hive-3.1.2-bin/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]SLF4J: Found binding in [jar:file:/opt/software/hadoop/hadoop-3.1.3/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]Metastore connection URL: jdbc:mysql://219.145.62.237:23306/hive_testMetastore Connection Driver : com.MySQL.jdbc.DriverMetastore connection User: rootorg.apache.hadoop.hive.metastore.HiveMetaException: Failed to load driverUnderlying cause: java.lang.ClassNotFoundException : com.MySQL.jdbc.DriverUse --verbose for detailed stacktrace.*** schemaTool failed *** 错误原因hive/lib文件夹下面没有导入mysql 的驱动。 还有可能是配置文件错误了。 错误解决导入mysql驱动，用官方的配置文件，不要在网上乱粘！！！ HiveServer2启动报错错误详情1234567891011121314151617181920212223java.lang.NoClassDefFoundError: org/apache/tez/dag/api/TezConfiguration at org.apache.hadoop.hive.ql.exec.tez.TezSessionPoolSession$AbstractTriggerValidator.startTriggerValidator(TezSessionPoolSession.java:74) ~[hive-exec-3.1.2.jar:3.1.2] at org.apache.hadoop.hive.ql.exec.tez.TezSessionPoolManager.initTriggers(TezSessionPoolManager.java:207) ~[hive-exec-3.1.2.jar:3.1.2] at org.apache.hadoop.hive.ql.exec.tez.TezSessionPoolManager.startPool(TezSessionPoolManager.java:114) ~[hive-exec-3.1.2.jar:3.1.2] at org.apache.hive.service.server.HiveServer2.initAndStartTezSessionPoolManager(HiveServer2.java:839) ~[hive-service-3.1.2.jar:3.1.2] at org.apache.hive.service.server.HiveServer2.startOrReconnectTezSessions(HiveServer2.java:822) ~[hive-service-3.1.2.jar:3.1.2] at org.apache.hive.service.server.HiveServer2.start(HiveServer2.java:745) ~[hive-service-3.1.2.jar:3.1.2] at org.apache.hive.service.server.HiveServer2.startHiveServer2(HiveServer2.java:1037) [hive-service-3.1.2.jar:3.1.2] at org.apache.hive.service.server.HiveServer2.access$1600(HiveServer2.java:140) [hive-service-3.1.2.jar:3.1.2] at org.apache.hive.service.server.HiveServer2$StartOptionExecutor.execute(HiveServer2.java:1305) [hive-service-3.1.2.jar:3.1.2] at org.apache.hive.service.server.HiveServer2.main(HiveServer2.java:1149) [hive-service-3.1.2.jar:3.1.2] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_212] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_212] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_212] at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_212] at org.apache.hadoop.util.RunJar.run(RunJar.java:318) [hadoop-common-3.1.3.jar:?] at org.apache.hadoop.util.RunJar.main(RunJar.java:232) [hadoop-common-3.1.3.jar:?]Caused by: java.lang.ClassNotFoundException: org.apache.tez.dag.api.TezConfiguration at java.net.URLClassLoader.findClass(URLClassLoader.java:382) ~[?:1.8.0_212] at java.lang.ClassLoader.loadClass(ClassLoader.java:424) ~[?:1.8.0_212] at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349) ~[?:1.8.0_212] at java.lang.ClassLoader.loadClass(ClassLoader.java:357) ~[?:1.8.0_212] ... 16 more 错误原因这种问题是从机上运行的Container试图使用过多的内存，而被NodeManager kill掉了。 错误解决关掉虚拟内存检查,修改yarn-site.xml文件（添加相关代码）！！ 12cd /opt/module/hadoop/etc/hadoopvim yarn-site.xml 关掉虚拟机内存检查！！ 1234&lt;property&gt; &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt; &lt;value&gt;false&lt;/value&gt;&lt;/property&gt; 参考文档 官方文档 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"大数据","slug":"大数据","permalink":"https://lywlefan.github.io/tags/大数据/"},{"name":"hive","slug":"hive","permalink":"https://lywlefan.github.io/tags/hive/"}]},{"title":"vue中是如何自定义组件的.","date":"2019-12-05T16:00:00.000Z","path":"2019/12/06/软件研发/前端/vue/vue中是如何自定义组件的/","text":"如何自定义组件??父子组件之间是如何交互的?? 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"vue","slug":"vue","permalink":"https://lywlefan.github.io/tags/vue/"}]},{"title":"初始Knative","date":"2019-11-26T16:00:00.000Z","path":"2019/11/27/软件研发/后端/容器管理/Knative/初始Knative/","text":"函数即服务（FaaS） 平台即服务（PaaS） 无服务器架构（serverless） 路由（routing） 事件（eventing） build（构建） 什么是Knative??Knative的目标 Knative 的目标是在基于 Kubernetes 之上为整个开发生命周期提供帮助 。 具体实现 作为开发人员能够以你想要的语言和以你想要的方式来编写代码 其次帮助你构建和打包应用程序 最后帮助你运行和伸缩应用程序 关键组件 build（构建）你的应用程序 1通过灵活的插件化的构建系统将用户源代码构建成容器。目前已经支持多个构建系统，比如 Google 的 Kaniko，它无需运行 Docker daemon 就可以在 Kubernetes 集群上构建容器镜像。 serving（服务）为其提供流量 1基于负载自动伸缩，包括在没有负载时缩减到零。允许你为多个修订版本（revision）应用创建流量策略，从而能够通过 URL 轻松路由到目标应用程序。 event（事件）确保应用程序能够轻松地生产和消费。 1使得生产和消费事件变得容易。抽象出事件源，并允许操作人员使用自己选择的消息传递层。 综上所述:Knative是一个可以让Kubernetes更好用,扩展性更好的轮子。 一些新的概念无服务器架构(serverless)划重点 以前需要编写大型/单一应用程序,现在只需要编写通过事件来调用小型/单一用途的函数即可。 对于托管服务来说,意味着只需要为活跃期间的计算付费,而不是一台7×24小时运行的虚拟机付费。 代码在需要时就运行,不需要时就停止。 Kubernetes遇到的问题 如何保证一致性 谁负责给所有东西打补丁 如何根据需求伸缩 如何实现零停机部署 如何管理多个事件类型一致性 如何定义事件源和目标 Knative 构建在 Kubernetes 的基础上，并为构建和部署无服务器架构（serverless）和基于事件驱动的应用程序提供了一致的标准模式。Knative 减少了这种新的软件开发方法所产生的开销，同时还把路由（routing）和事件（eventing）的复杂性抽象出来。 Knative组件学习Serving（服务） 【1】简书主页·share猿 【2】掘金主页·share猿 【3】Knative入门——构建基于 Kubernetes 的现代化Serverless应用 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"容器管理","slug":"容器管理","permalink":"https://lywlefan.github.io/tags/容器管理/"},{"name":"Knative","slug":"Knative","permalink":"https://lywlefan.github.io/tags/Knative/"}]},{"title":"jpa参数为空查询报错问题","date":"2019-11-24T16:00:00.000Z","path":"2019/11/25/软件研发/后端/框架/java/hibernate/jpa参数为空查询报错问题/","text":"遇到问题在使用jpa的时候发现,通过@Query自定义的sql,参数不能传空,传空就报错: 在使用jpa的时候发现,通过@Query自定义的 12345678910111213@Query(value = \"select new com.winstar.vo.OilCouponVo(t.oilId,s.phone,s.certNo,t.couponCode,t.orderNumber,t.couponAmt,t.couponName,t.useState,t.gasStationId,t.gasStationName,t.useDate,t.createdAt,t.updatedAt,t.status) from OilCoupon t left join Account s on t.userId = s.id \" + \"where (t.createdAt between ?1 and ?2) and t.useDate = ?3 and t.couponCode like ?4 and t.orderNumber like ?5 and t.appId = ?6 and s.phone = ?7 and s.certNo = ?8\", countQuery = \"select count(t.id) from OilCoupon t left join Account s on t.userId = s.id \" + \"where (t.createdAt between ?1 and ?2) and t.useDate = ?3 and t.couponCode like ?4 and t.orderNumber like ?5 and t.appId = ?6 and s.phone = ?7 and s.certNo = ?8\") Page&lt;OilCouponVo&gt; getOilPage(Date startTime, Date endTime, String useState, String couponCode, String orderNumber, String appId, String phone, String certNo, Pageable pageable); 解决办法原生sql解决办法如下:123@Query(value = \"select * from xxx where if(?1 !='',x1=?1,1=1) and if(?2 !='',x2=?2,1=1)\" + \"and if(?3 !='',x3=?3,1=1) \",nativeQuery = true) List&lt;XXX&gt; find(String X1,String X2,String X3); 非原生sql解决办法如下12345678@Query(value = \"select new com.winstar.vo.OilCouponVo(t.oilId,s.phone,s.certNo,t.couponCode,t.orderNumber,t.couponAmt,t.couponName,t.useState,t.gasStationId,t.gasStationName,t.useDate,t.createdAt,t.updatedAt,t.status) from OilCoupon t left join Account s on t.userId = s.id \" + \"where (t.createdAt between ?1 and ?2) and (?3 is null or ?3 = '' or t.useState = ?3) and (?4 is null or ?4 = '' or t.couponCode like ?4)\" + \" and (?5 is null or ?5 = '' or t.orderNumber = ?5) and (?6 is null or ?6 = '' or t.appId = ?6)\" + \" and (?7 is null or ?7 = '' or s.phone = ?7) and (?8 is null or ?8 = '' or s.certNo like ?8)\", countQuery = \"select count(t.id) from OilCoupon t left join Account s on t.userId = s.id \" + \"where (t.createdAt between ?1 and ?2) and (?3 is null or ?3 = '' or t.useState = ?3) and (?4 is null or ?4 = '' or t.couponCode like ?4)\" + \" and (?5 is null or ?5 = '' or t.orderNumber = ?5) and (?6 is null or ?6 = '' or t.appId = ?6)\" + \" and (?7 is null or ?7 = '' or s.phone = ?7) and (?8 is null or ?8 = '' or s.certNo like ?8)\") 【1】简书主页·share猿【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"},{"name":"框架","slug":"框架","permalink":"https://lywlefan.github.io/tags/框架/"},{"name":"hibernate","slug":"hibernate","permalink":"https://lywlefan.github.io/tags/hibernate/"}]},{"title":"自定义枚举类型校验","date":"2019-11-17T16:00:00.000Z","path":"2019/11/18/软件研发/后端/框架/java/hibernate/自定义枚举类型校验/","text":"需求自定义了如下枚举类型,需要对其vo进行校验: 123456789101112131415161718192021222324252627public interface ValidateEnum &#123; /** * 证件类型 */ @Getter @AllArgsConstructor enum CertTypeEnum implements ValidateEnum &#123; CERT_TYPE(\"身份证\",\"0\"), PROTECTION_TYPE(\"护照\",\"1\"), OFFICER_TYPE(\"军官证\",\"2\"), SOLDIERS_TYPE(\"士兵证\",\"3\"), REENTRY_PERMIT_TYPE(\"回乡证\",\"4\"), INTERIM_IDENTITY_CARD_TYPE(\"临时身份证\",\"5\"), RESIDENCE_BOOKLET_TYPE(\"户口簿\",\"6\"), POLICE_OFFICER_TYPE(\"警官证\",\"7\"), TAIWAN_COMPATRIOTS_TYPE(\"台胞证\",\"8\"), BUSINESS_LICENSE_TYPE(\"营业执照\",\"9\"), OTHERS_TYPE(\"其他证件\",\"10\"), HONG_KONG_TYPE(\"港澳台居民来往内地通行证\",\"11\"), TAIWAN_TYPE(\"台湾居民来往大陆通行证\",\"12\"); private String name; private String value; &#125;&#125; 实现自定义枚举校验注解12345678910111213@Documented@Retention(RetentionPolicy.RUNTIME)@Target(&#123;ElementType.FIELD, ElementType.METHOD&#125;)@Constraint(validatedBy = EnumValidatorClass.class)public @interface EnumValidator &#123; Class&lt;?&gt; value(); String message() default \"入参值不在正确枚举中\"; Class&lt;?&gt;[] groups() default &#123;&#125;; Class&lt;? extends Payload&gt;[] payload() default &#123;&#125;;&#125; 枚举注解处理类1234567891011121314151617181920212223242526272829303132333435public class EnumValidatorClass implements ConstraintValidator&lt;EnumValidator, Object&gt;, Annotation &#123; private Logger log = LoggerFactory.getLogger(this.getClass()); private List&lt;Object&gt; values = new ArrayList&lt;&gt;(); @Override public void initialize(EnumValidator enumValidator) &#123; Class&lt;?&gt; clz = enumValidator.value(); Object[] ojects = clz.getEnumConstants(); try &#123; Method method = clz.getMethod(\"getValue\"); if (Objects.isNull(method)) &#123; throw new Exception(String.format(\"枚举对象&#123;&#125;缺少字段名为value的字段\", clz.getName())); &#125; Object value = null; for (Object obj : ojects) &#123; value = method.invoke(obj); values.add(value); &#125; &#125; catch (Exception e) &#123; log.error(\"[处理枚举校验异常]\", e); &#125; &#125; @Override public Class&lt;? extends Annotation&gt; annotationType() &#123; return null; &#125; @Override public boolean isValid(Object value, ConstraintValidatorContext constraintValidatorContext) &#123; return Objects.isNull(value) || values.contains(value) ? true : false; &#125;&#125; 定义枚举类型接口123456789101112131415161718192021222324252627public interface ValidateEnum &#123; /** * 证件类型 */ @Getter @AllArgsConstructor enum CertTypeEnum implements ValidateEnum &#123; CERT_TYPE(&quot;身份证&quot;,&quot;0&quot;), PROTECTION_TYPE(&quot;护照&quot;,&quot;1&quot;), OFFICER_TYPE(&quot;军官证&quot;,&quot;2&quot;), SOLDIERS_TYPE(&quot;士兵证&quot;,&quot;3&quot;), REENTRY_PERMIT_TYPE(&quot;回乡证&quot;,&quot;4&quot;), INTERIM_IDENTITY_CARD_TYPE(&quot;临时身份证&quot;,&quot;5&quot;), RESIDENCE_BOOKLET_TYPE(&quot;户口簿&quot;,&quot;6&quot;), POLICE_OFFICER_TYPE(&quot;警官证&quot;,&quot;7&quot;), TAIWAN_COMPATRIOTS_TYPE(&quot;台胞证&quot;,&quot;8&quot;), BUSINESS_LICENSE_TYPE(&quot;营业执照&quot;,&quot;9&quot;), OTHERS_TYPE(&quot;其他证件&quot;,&quot;10&quot;), HONG_KONG_TYPE(&quot;港澳台居民来往内地通行证&quot;,&quot;11&quot;), TAIWAN_TYPE(&quot;台湾居民来往大陆通行证&quot;,&quot;12&quot;); private String name; private String value; &#125;&#125; 使用枚举校验注解12345/** * 证件类型(0:身份证, 1:护照, 2:军官证, 3:士兵证, 4:回乡证, 5:临时身份证, 6:户口簿, 7:警官证, 8:台胞证, 9:营业执照, 10:其他证件, 11:港澳台居民来往内地通行证, 12:台湾居民来往大陆通行证) */@EnumValidator(message = &quot;证件类型不在指定类型中&quot;, value = ValidateEnum.CertTypeEnum.class)private String certType; 【1】简书主页·share猿【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"},{"name":"框架","slug":"框架","permalink":"https://lywlefan.github.io/tags/框架/"},{"name":"hibernate","slug":"hibernate","permalink":"https://lywlefan.github.io/tags/hibernate/"}]},{"title":"去中心化应用","date":"2019-11-04T16:00:00.000Z","path":"2019/11/05/软件研发/前沿技术/区块链/应用/去中心化应用/","text":"去中心化应用 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"区块链","slug":"区块链","permalink":"https://lywlefan.github.io/tags/区块链/"},{"name":"应用","slug":"应用","permalink":"https://lywlefan.github.io/tags/应用/"}]},{"title":"如何和别人进行合作协调","date":"2019-11-04T16:00:00.000Z","path":"2019/11/05/软件研发/管理/读书笔记/横向领导力/如何和别人进行合作协调/","text":"合作中常见的问题合作不佳找不到一个人解决问题改善团队表现需要解决的三个问题个人技能有限的问题打铁还得自身硬，要想领导团队自身能力要硬，要有好的德行。要有解决解决复杂问题的能力和思维，要有带领团队克服困难的勇气，要积极向上，做好团队的能量石，也做好团队的敲打棒。 对一个好的合作缺乏清晰的认识要对好的团队有清晰的认识，团队要有清晰的目标，领导人要划分清晰的职责，及时处理团队的矛盾，团队成员共同成长，相互提升，把相互teview当做团队的一种文化，团队协作形成一些标准的规范。领导人要为团队争取更多的福利。 大多数人都不知道怎么影响别人 自我成长 德行 清晰目标 职责分配清晰 及时沟通，当面表扬，私下批评 积极争取福利 团队协作的方法培养、锻炼自己独立工作的自己独立工作的能力，有计划，有目标，有方向，有解决问题思维方式，有处理问题的策略。 对共同工作的战略目标有清晰的认识深刻理解目标，对目标有清晰的认识。 学习一些领导方法参与式领导方法 提问 说出自己的想法邀请别人接受、运用或者修改想法 想法付诸实践，然后改进 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://lywlefan.github.io/tags/读书笔记/"},{"name":"横向领导力","slug":"横向领导力","permalink":"https://lywlefan.github.io/tags/横向领导力/"}]},{"title":"corda基础架构","date":"2019-10-29T16:00:00.000Z","path":"2019/10/30/软件研发/前沿技术/区块链/corda/corda基础架构/","text":"扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"区块链","slug":"区块链","permalink":"https://lywlefan.github.io/tags/区块链/"},{"name":"corda","slug":"corda","permalink":"https://lywlefan.github.io/tags/corda/"}]},{"title":"初始corda","date":"2019-10-29T16:00:00.000Z","path":"2019/10/30/软件研发/前沿技术/区块链/corda/cord中的基本概念总结/","text":"什么是corda??是什么?corda是一个分布式账本平台。 基本概念corda网络账本每个节点验证过交易的集合,账本是各个节点自有的。 每个节点维护一个已知事实的分离数据库。 没有一个节点知道整个账本。 身份身份有两种:组织的法律身份、网络服务身份。 法律身份用于交易的当事人,如:现金拥有者。 网络服务身份用于提供与交易相关的服务,如公证服务或oracle服务。服务身份基于混合KEY。 身份证明的X.509证书由看门人或其他众所周知的身份签发。身份是众所周知的还是机密的,取决于X.509证书是否公开。 应用节点看门人看门人服务可以理解为一个身份准入管理服务加上一个业务许可管理服务,它要求节点提供必要的信息,以及在接受进入网络前必须进行的了解客户的过程。 要想加入corda网络,节点必须联系看门人并提供必要的信息。看门人许可通过,会颁发TLS许可证书。 cordaDappsAMPQ/1.0协议公证节点公证节点保证账本更新的唯一性、可行性、正确性。 每个公证服务可以运行在一个节点或一组节点上。 状态状态是表示账本上的事实,是一个不可变的对象,表示在特定时刻由一个或多个Corda节点所知的事实。 状态序列状态的生命周期 合约每个状态指向一个合约。 合约以交易作为输入,并根据合约的规则说明交易是否被认为有效。 交易只有在合约的每个输入和输出状态被确认为有效的情况下才有效。 合约代码可以用任意的JVM语言进行编写。 一个不被合约认可的交易不会作为更新账本的有效提案。 合约沙箱预言机女巫攻击 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"区块链","slug":"区块链","permalink":"https://lywlefan.github.io/tags/区块链/"},{"name":"corda","slug":"corda","permalink":"https://lywlefan.github.io/tags/corda/"}]},{"title":"初始corda","date":"2019-10-29T16:00:00.000Z","path":"2019/10/30/软件研发/前沿技术/区块链/corda/初始corda/","text":"什么是corda??是什么?corda是一个分布式账本平台。 基本概念corda网络账本每个节点验证过交易的集合,账本是各个节点自有的。 每个节点维护一个已知事实的分离数据库。 没有一个节点知道整个账本。 身份身份有两种:组织的法律身份、网络服务身份。 法律身份用于交易的当事人,如:现金拥有者。 网络服务身份用于提供与交易相关的服务,如公证服务或oracle服务。服务身份基于混合KEY。 身份证明的X.509证书由看门人或其他众所周知的身份签发。身份是众所周知的还是机密的,取决于X.509证书是否公开。 应用节点看门人看门人服务可以理解为一个身份准入管理服务加上一个业务许可管理服务,它要求节点提供必要的信息,以及在接受进入网络前必须进行的了解客户的过程。 要想加入corda网络,节点必须联系看门人并提供必要的信息。看门人许可通过,会颁发TLS许可证书。 cordaDappsAMPQ/1.0协议公证节点公证节点保证账本更新的唯一性、可行性、正确性。 每个公证服务可以运行在一个节点或一组节点上。 状态状态是表示账本上的事实,是一个不可变的对象,表示在特定时刻由一个或多个Corda节点所知的事实。 状态序列状态的生命周期 合约每个状态指向一个合约。 合约以交易作为输入,并根据合约的规则说明交易是否被认为有效。 交易只有在合约的每个输入和输出状态被确认为有效的情况下才有效。 合约代码可以用任意的JVM语言进行编写。 一个不被合约认可的交易不会作为更新账本的有效提案。 合约沙箱预言机女巫攻击 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"区块链","slug":"区块链","permalink":"https://lywlefan.github.io/tags/区块链/"},{"name":"corda","slug":"corda","permalink":"https://lywlefan.github.io/tags/corda/"}]},{"title":"企业在落地区块链时要考虑的点","date":"2019-10-29T16:00:00.000Z","path":"2019/10/30/软件研发/前沿技术/区块链/fabric/Hyperledger Composer学习总结/","text":"扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"区块链","slug":"区块链","permalink":"https://lywlefan.github.io/tags/区块链/"},{"name":"fabric","slug":"fabric","permalink":"https://lywlefan.github.io/tags/fabric/"}]},{"title":"fabric架构","date":"2019-10-29T16:00:00.000Z","path":"2019/10/30/软件研发/前沿技术/区块链/fabric/fabric架构/","text":"扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"区块链","slug":"区块链","permalink":"https://lywlefan.github.io/tags/区块链/"},{"name":"fabric","slug":"fabric","permalink":"https://lywlefan.github.io/tags/fabric/"}]},{"title":"企业在落地区块链时要考虑的点","date":"2019-10-29T16:00:00.000Z","path":"2019/10/30/软件研发/前沿技术/区块链/应用/企业在落地区块链时要考虑的点/","text":"业务人才团队建设业务场景选择业务流程化应用开发模式可视化与分析数据模块管理技术技术方案选型平台设计实施高可用与灾备安全合规治理平台应用运维运营市场营销宣传生态系统参与 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"区块链","slug":"区块链","permalink":"https://lywlefan.github.io/tags/区块链/"},{"name":"应用","slug":"应用","permalink":"https://lywlefan.github.io/tags/应用/"}]},{"title":"redis基础总结","date":"2019-10-29T16:00:00.000Z","path":"2019/10/30/软件研发/后端/缓存/redis/redis基础总结/","text":"redis附加功能 “附加功能”部分介绍了Redis在数据结构的基础上为用户提供的额外功能，包括管理数据结构的数据库管理功能和自动过期功能，将数据结构持久化至硬盘从而避免数据丢失的持久化功能，提高多条命令执行效率的流水线功能，保证命令安全性的事务和Lua脚本功能，以及扩展服务器特性的模块功能等。 Redis的PING命令接受一条可选的消息作为参数，这个命令通常用于测试客户端和服务器之间的连接是否正常: 连接正常的情况下，将向客户端返回PONG 如果服务器与客户端的连接不正常，那么客户端将返回一个错误 123-- 客户端未能连接服务器，返回一个连接错误 127.0.0.1:6379&gt; PING Could not connect to Redis at 127.0.0.1:6379: Connection refused 更换端口号: Redis服务器默认使用6379作为端口号，但如果你想使用10086而不是6379作为端口号，那么可以在启动Redis服务器时通过设定port可选项来指定想要的端口号： 1$ redis-server --port 10086 第二种方法是在启动Redis服务器的时候为其提供配置文件，并将想要修改的配置选项写在配置文件中 1$ redis-server /path/to/your/file 例如，为了将Redis服务器的端口号改为12345，我们可以在当前文件夹中创建配置文件myredis.conf，并在文件中包含以下内容： 1port 12345 然后在启动Redis服务器时向其提供该配置文件： 1$ redis-server myredis.conf 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"redis","slug":"redis","permalink":"https://lywlefan.github.io/tags/redis/"},{"name":"缓存","slug":"缓存","permalink":"https://lywlefan.github.io/tags/缓存/"}]},{"title":"Vue基础","date":"2019-10-23T16:00:00.000Z","path":"2019/10/24/软件研发/前端/vue/vue基础/","text":"基础简介什么是Vue？？开发web界面的前端库 vue特性 具有响应式编程（保持状态和视图同步） 组件化 轻量级 易上手 MVC：MVC 模式代表 Model-View-Controller（模型-视图-控制器） 模式。 MVP：MVP是Model-View-Presenter的简称，即模型-视图-表现层的缩写。MVP是由MVC模式进化而来的，MVP改进了MVC中的控制器过于臃肿的问题。 MVC MVP Model 业务逻辑和实体模型 Model 业务逻辑和实体模型 View 对应布局文件 View 对应Activity，负责view的绘制与用户交互 Controller 对应Activity等 Presenter 负责完成view与model的交互，处理程序逻辑 MVVM： MVM： 理念一切都是组件！ 为什么用vue 轻量，易上手 阿里支持，开源weex 抛弃IE8支持 Android支持到4.2+ ios支持到7+ 适用前后端分离项目 压缩后仅有18KB，不依赖其他 前端框架基本逻辑 模板渲染 事件绑定 用户交互处理 实例及选项一个Vue实例相当于一个MVVM模式中的ViewModel，实例化的时候传入一个选项对象（包括数据、模板、挂载元素、方法、生命周期钩子等） 模板el为实例提供挂载元素，类型为字符串。在初始化指定el，实例将立即进入编译过程。 template配置挂载 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"vue","slug":"vue","permalink":"https://lywlefan.github.io/tags/vue/"}]},{"title":"抓包工具学习","date":"2019-10-23T16:00:00.000Z","path":"2019/10/24/软件研发/前端/idea/fiddler/抓包工具学习/","text":"扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"idea","slug":"idea","permalink":"https://lywlefan.github.io/tags/idea/"},{"name":"fiddler","slug":"fiddler","permalink":"https://lywlefan.github.io/tags/fiddler/"}]},{"title":"在Ubuntu下安装webstorm","date":"2019-10-23T16:00:00.000Z","path":"2019/10/24/软件研发/前端/idea/webstorm/在Ubuntu下安装webstorm/","text":"扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"idea","slug":"idea","permalink":"https://lywlefan.github.io/tags/idea/"},{"name":"webstorm","slug":"webstorm","permalink":"https://lywlefan.github.io/tags/webstorm/"}]},{"title":"jpa原生sql分页","date":"2019-10-17T16:00:00.000Z","path":"2019/10/18/软件研发/后端/框架/java/hibernate/jpa原生sql分页/","text":"需求其实需求很简单,就是通过查询一个表得到数据列表,然后再对这个数据列表进行分页,自定义sql如下: 1234567891011121314151617181920212223SELECT t.order_number AS orderNumber, sum(t.coupon_amt) AS sum, sum( CASE WHEN t.use_state = 'NOT_USE' THEN t.coupon_amt ELSE 0 END ) AS balanceFROM open_oil_coupon tWHERE t.user_id = ? 1AND t.app_id = ? 2GROUP BY t.order_idHAVING balance = 0ORDER BY t.created_at DESC, balance DESC 解决办法方法一:通过jpa的原生sql分页查询Repository1234567public interface OilCouponRepository extends JpaRepository&lt;OilCoupon,Long&gt;,JpaSpecificationExecutor&lt;OilCoupon&gt; &#123; @Query(value = \"SELECT t.order_number AS orderNumber, sum(t.coupon_amt) AS sum, sum(CASE WHEN t.use_state = 'NOT_USE' THEN t.coupon_amt ELSE 0 END ) AS balance FROM open_oil_coupon t WHERE t.user_id = ?1 AND t.app_id = ?2 GROUP BY t.order_number HAVING balance &gt; 0\",nativeQuery = true, countQuery = \"SELECT count(*) FROM (SELECT t.order_number AS orderNumber, sum(t.coupon_amt) AS sum, sum(CASE WHEN t.use_state = 'NOT_USE' THEN t.coupon_amt ELSE 0 END ) AS balance FROM open_oil_coupon t WHERE t.user_id = ?1 AND t.app_id = ?2 GROUP BY t.order_number HAVING balance = 0) T\")Page&lt;Map&gt; getAllCouponsUsed(Long userId, String appId, Pageable pageable);&#125; 注意:countQuery如果带有having等语句最好的办法是把@Query的sql复制一份把他查出来的结果当成表,然后对其进行count(*)查询。 Service123456789101112public OpenPage&lt;CouponsVo&gt; getCouponsByOrderId(String appId, Long userId, CouponPageVo couponPageVo)&#123; Pageable pageable = new PageRequest(couponPageVo.getPageNum(), couponPageVo.getPageSize(), Sort.Direction.DESC, \"order_number\"); OpenPage&lt;CouponsVo&gt; pages = new OpenPage(); Page page2 = oilCouponRepository.getAllCouponsUsed(userId,appId,pageable); List&lt;CouponsVo&gt; couponsVos = JSON.parseArray(JSON.toJSONString(page2.getContent()),CouponsVo.class); pages.setContent(couponsVos); pages.setPageNum(page2.getNumber()); pages.setPageSize(page2.getSize()); pages.setTotalElements(page2.getTotalElements()); pages.setTotalPages(page2.getTotalPages()); return pages; &#125; 注意:排序的字段要用跟数据库里面一样的字段名称 方法二:通过jdbc原生sql拼接的方法进行分页抽象的jdbc分页类型123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153package com.winstar.config;import com.winstar.util.OpenPage;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.jdbc.core.JdbcTemplate;import org.springframework.util.Assert;import javax.persistence.EntityManager;import java.io.Serializable;import java.lang.reflect.Field;import java.lang.reflect.ParameterizedType;import java.util.HashMap;import java.util.List;import java.util.Map;import java.util.regex.Matcher;import java.util.regex.Pattern;/** * 包:com.winstar.manager.repository * 类描述: jdbc父Dao封装 * 创建人:shareyuan * 创建时间:2018/12/26 11:52 * 版本:v1.0 */@SuppressWarnings(\"unchecked\")public class AbstractServerRepository&lt;T, PK extends Serializable&gt;&#123; @Autowired protected JdbcTemplate jdbcTemplate; @Autowired EntityManager entityManager; protected Class&lt;T&gt; entityClass; private static final String EMPYT_STR = \"\"; private Map&lt;String, String&gt; fieldClassNames = null; public AbstractServerRepository() &#123; this.entityClass = (Class&lt;T&gt;) ((ParameterizedType) getClass() .getGenericSuperclass()).getActualTypeArguments()[0]; this.initEntityFieldsClassNames(); &#125; private void initEntityFieldsClassNames() &#123; Field[] fields = this.entityClass.getDeclaredFields(); this.fieldClassNames = new HashMap&lt;&gt;(); for (Field field : fields) &#123; fieldClassNames.put(field.getName(), field.getType().getName()); &#125; &#125; /** * Description: 根据SQL查询数据并返回一个List&lt;Map&lt;String,Object&gt;&gt;,将其封装为 Page * Param: sql,pageNo,pageSize,values * return: Page * Author: shareyuan * Date: 2018/12/27 */ public OpenPage findPageBySqlForListMap(final String sql, final int pageNo, final int pageSize, final Object... values) &#123; final String countSql = \"SELECT count(1) FROM (\"+ removeOrders(sql) + \") T\"; final long totalCount = this.getCountBySql(countSql, values); if (totalCount &lt; 1) &#123; return new OpenPage(); &#125; else &#123; final int startIndex = OpenPage.getStartOfPage(pageNo, pageSize); final String querySql =getString( sql,\" limit \", startIndex,\",\", pageSize); List&lt;Map&lt;String,Object&gt;&gt; list = this.jdbcTemplate.queryForList(querySql,values); return new OpenPage(pageNo,pageSize, list,Integer.parseInt(String.valueOf(totalCount))); &#125; &#125; /** * Description: 根据id获取唯一对象 * Param: id * return: T * Author: shareyuan * Date: 2018/12/27 */ public T findOne(final PK id)&#123; return entityManager.find(entityClass,id); &#125; /** * Description: 根据sql查询数据总数 * Param: sql,values * return: Long * Author: shareyuan * Date: 2018/12/26 */ private Long getCountBySql(final String sql, final Object... values) &#123; return jdbcTemplate.queryForObject(sql, Long.class, values); &#125; /** * Description: 组合传入字符串数组 * Param: objs * return: String * Author: shareyuan * Date: 2018/12/26 */ private String getString(Object... objs) &#123; if(objs != null &amp;&amp; objs.length &gt; 0) &#123; StringBuilder sb = new StringBuilder(); for (int i = 0; i &lt; objs.length; i++) &#123; sb.append(objs[i] == null ? EMPYT_STR : objs[i].toString()); &#125; return sb.toString(); &#125; return EMPYT_STR; &#125; /** * Description: 去除sql的orderby 子句，用于分页查询 * Param: sql * return: String * Author: shareyuan * Date: 2018/12/27 */ private String removeOrders(String sql) &#123; Pattern p = Pattern.compile(\"order\\\\s*by[\\\\w|\\\\W|\\\\s|\\\\S]*\", Pattern.CASE_INSENSITIVE); Matcher m = p.matcher(sql); StringBuffer sb = new StringBuffer(); while (m.find()) &#123; m.appendReplacement(sb, \"\"); &#125; m.appendTail(sb); return sb.toString(); &#125; /** * Description: 去除sql的select 子句，未考虑union的情况 * Param: sql * return: String * Author: shareyuan * Date: 2018/12/27 */ private String removeSelect(String sql) &#123; int beginPos = sql.toLowerCase().indexOf(\"from \"); Assert.isTrue(beginPos != -1, \" hql : \" + sql + \" must has a keyword 'from'\"); return sql.substring(beginPos); &#125;&#125; Repository1234@Repository(\"oilCouponJdbcRepository\")public class OilCouponJdbcRepository extends AbstractServerRepository&lt;OilCoupon,Long&gt; &#123;&#125; Service123456789101112131415161718192021 public OpenPage&lt;Map&gt; getPage(String appId, Long userId, CouponPageVo couponPageVo) &#123; StringBuffer sql = new StringBuffer(\"SELECT t.order_number AS orderNumber, sum(t.coupon_amt) AS sum, sum(CASE WHEN t.use_state = 'NOT_USE' THEN t.coupon_amt ELSE 0 END ) AS balance FROM open_oil_coupon t\"); List params = new ArrayList&lt;&gt;(); if (StringUtils.isNotEmpty(appId))&#123; sql.append(\" WHERE t.user_id = ? \"); params.add(userId); &#125; if (StringUtils.isNotEmpty(appId))&#123; sql.append(\" AND t.app_id = ? \"); params.add(appId); &#125; sql.append(\" GROUP BY t.order_number\"); if (StringUtils.equals(couponPageVo.getUseState(),CommonEnum.USED.getValue()))&#123; sql.append(\" HAVING balance = 0\"); &#125;else if (StringUtils.equals(couponPageVo.getUseState(),CommonEnum.NOT_USE.getValue()))&#123; sql.append(\" HAVING balance &gt; 0\"); &#125; sql.append(\" ORDER BY t.created_at DESC,balance \"); log.info(\"分页sql为:&#123;&#125;,分页请求参数为:&#123;&#125;\",sql,params.toArray()); return oilCouponJdbcRepository.findPageBySqlForListMap(sql.toString(),couponPageVo.getPageNum(),couponPageVo.getPageSize(),params.toArray());&#125; 说明:jdbc分页的好处就是可以多表进行联查自定义sql,相对来说比较灵活,对于复杂sql,我个人感觉可读性要比jpa的自定义sql要好一些。 【1】简书主页·share猿【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"},{"name":"框架","slug":"框架","permalink":"https://lywlefan.github.io/tags/框架/"},{"name":"hibernate","slug":"hibernate","permalink":"https://lywlefan.github.io/tags/hibernate/"}]},{"title":"如何设计一个秒杀系统读书笔记","date":"2019-10-16T16:00:00.000Z","path":"2019/10/17/软件研发/后端/高并发/java/书籍/如何设计一个秒杀系统-许令波/如何设计一个秒杀系统读书笔记/","text":"阅读笔记秒杀系统关键点①我觉得作为一个程序员,你首先需要从高维度出发,从整体上思考问题。 1G:对整体要有高屋建瓴，要站在最高处俯瞰，在落实的时候要把握好细节，下绣花针功夫。 ②秒杀其实主要解决两个问题,一个是并发读,一个是并发写。并发读的核心优化理念是尽量减少用户到服务来“读”数据,或者让他们读更少的数据;并发写的处理原则也一样,它要求我们在数据库层面独立出来一个库,做特殊的处理。另外,我们还要针对秒杀系统做一些保护,针对意料之外的情况设计兜底方案,以防止最坏的情况发生。 1G：两个疑问，见疑问区域 ③从浏览器到服务端我们要遵循几个原则： 请求数据尽量少 请求数尽量少 路径尽量短 依赖尽量少 不要有单点 ④整体架构概括为几个字：稳、准、快 稳（高性能）：流量超出预期要保证稳定 准（一致性）：秒杀多少个商品就是多少个，一台也不能多，一台也不能少 快（高可用）：支撑大的流量，性能要好 设计秒杀系统注意的5个架构原则①“4要1不要” 数据尽量少：上传的数据和返回的数据 请求尽量少： 合并CSS和JavaScript文件，多个合成一个 在 URL 中用逗号隔开 (https://g.xxx.com/tm/xx-b/4.0.94/mods/??module-preview/index.xtpl.js,module-jhs/index.xtpl.js,module-focus/index.xtpl.js)。 这种方式在服务端仍然是单个文件各自存放,只是服务端会有一个组件解析这个 URL,然后动态把这些文件合并起来一起返回。 路径尽量短 缩短请求不仅可以增加可用性而且可以有效提升性能 要缩短访问路径有一种办法,就是多个相互强依赖的应用合并部署在一起,把远程过程调用(RPC)变成JVM内部之间的调用。 依赖尽量少 系统分级（0级、1级、2级等等） 不要单点 应用无状态化 服务无状态化 架构是一种平衡的艺术,而最好的架构一旦脱离了它所适应的场景,一切都将是空谈。 二八原则:有正对性的处理好系统的热点数据把少部分访问速度高的数据隔离拆分出来做单独的处理,让大多数的请求正常运行。 流量削峰削峰的存在，一是可以让服务端处理变得更加平稳，二是可以节省服务器的资源成本。 它遵从“请求数要尽量少”的原则。 影响性能的因素有哪些？又该如何提高系统的性能？疑问如何减少用户来服务端读数据？？什么是兜底方案？？如何设计兜底？？什么是无状态化？？？什么是”热点数据”???热点数据就是一个系统中,用户访问量最大的数据,比如:热点商品。热点数据又分为:静态热点数据和动态热点数据。 如何分析发现热点数据??静态热点数据的发现 提前通过统计这些数据,比如:热卖商品,我们可以通过TOP排行榜进行统计,秒杀商品可以让商家进行报名,提前对这些数据做好缓存和预处理。 动态数据的发现 构建热点发现系统,用于在短时间内发现热点商品,从而做出相应的处理策略。 构建一个异步的系统，它可以收集交易链路上各个环节中的中间件产品的热点 Key，如 Nginx、缓存、RPC 服务框架等这些中间件（一些中间件产品本身已经有热点统计模块）。 建立一个热点上报和可以按照需求订阅的热点服务的下发规范，主要目的是通过交易链路上各个系统（包括详情、购物车、交易、优惠、库存、物流等）访问的时间差，把上游已经发现的热点透传给下游系统，提前做好保护。比如，对于大促高峰期，详情系统是最早知道的，在统一接入层上 Nginx 模块统计的热点 URL。 将上游系统收集的热点数据发送到热点服务台，然后下游系统（如交易系统）就会知道哪些商品会被频繁调用，然后做热点保护。 1G:热点分析平台:它存在的主要作用就是从各个可能收集热点数据的地方(每台机器上的Agen把日志汇总)收集到热点数据,然后对这些数据进行分析(分析集群),把分析到的热点数据进行发布,相关服务订阅到热点数据后,提前对这些热点数据做好处理(填充到 Cache等手段)。 热点分析系统构建注意事项: 这个热点服务后台抓取热点数据日志最好采用异步方式，因为“异步”一方面便于保证通用性，另一方面又不影响业务系统和中间件产品的主流程。 热点服务发现和中间件自身的热点保护模块并存，每个中间件和应用还需要保护自己。热点服务台提供热点数据的收集和订阅服务，便于把各个系统的热点数据透明出来。 热点发现要做到接近实时（3s 内完成热点数据的发现），因为只有做到接近实时，动态发现才有意义，才能实时地对下游系统提供保护。 总结热点数据发现的方法: 人工标识 大数据统计计算 以及实时热点发现方案 发现热点数据后如何处理热点数据?优化 LRU淘汰算法实时缓存热点数据 1LRU（Least recently used，最近最少使用）算法根据数据的历史访问记录来进行淘汰数据，其核心思想是“如果数据最近被访问过，那么将来被访问的几率也更高”。 限制 限制更多的是一种保护机制，限制的办法也有很多，例如对被访问商品的 ID 做一致性 Hash，然后根据 Hash 做分桶，每个分桶设置一个处理队列，这样可以把热点商品限制在一个请求队列里，防止因某些热点商品占用太多的服务器资源，而使其他请求始终得不到服务器的处理资源。 隔离 不要让 1% 的请求影响到另外的 99%，隔离出来后也更方便对这 1% 的请求做针对性的优化。 具体到“秒杀”业务，我们可以在以下几个层次实现隔离: 业务隔离。把秒杀做成一种营销活动，卖家要参加秒杀这种营销活动需要单独报名，从技术上来说，卖家报名后对我们来说就有了已知热点，因此可以提前做好预热。 系统隔离。系统隔离更多的是运行时的隔离，可以通过分组部署的方式和另外 99% 分开。秒杀可以申请单独的域名，目的也是让请求落到不同的集群中。 数据隔离。秒杀所调用的数据大部分都是热点数据，比如会启用单独的 Cache 集群或者 MySQL 数据库来放热点数据，目的也是不想 0.01% 的数据有机会影响 99.99% 数据。 你可以按照用户来区分，给不同的用户分配不同的 Cookie，在接入层，路由到不同的服务接口中； 你还可以在接入层针对 URL 中的不同 Path 来设置限流策略。 服务层调用不同的服务接口，以及数据层通过给数据打标来区分等等这些措施，其目的都是把已经识别出来的热点请求和普通的请求区分开。 流量削峰什么是流量削峰???在秒杀的过程中,就某一个时间来说请求实非常大的,我们的服务监控会看到一根非常直的线,因为所有请求都汇聚在这个时间点,对流量产生瞬时的消耗。 而流量削峰就是避免这种情况的发生,让并发请延缓,过滤掉无效的请求,让秒杀请求不在瞬时爆发,避免压垮服务器情况的发生。 为什么要削峰???秒杀就像大家去买早餐,早餐是有限的,买早餐的人可能非常多,大家为了买到早餐都往早餐店冲,这样的结果就是挤爆早餐店,大家谁也买不到早餐。 把请求当做买早餐的人,把早餐当成秒杀的商品是一样的道理.所以,削峰的意义就在于让服务器正常处理请求,避免服务器资源的浪费,保质保量完成请求任务。 如何进行流量削峰???无损的解决方案 答题 排队 分层过滤 有损的解决方案 限流 负载保护 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"},{"name":"读书笔记","slug":"读书笔记","permalink":"https://lywlefan.github.io/tags/读书笔记/"},{"name":"高并发","slug":"高并发","permalink":"https://lywlefan.github.io/tags/高并发/"},{"name":"java并发编程实战-王宝令","slug":"java并发编程实战-王宝令","permalink":"https://lywlefan.github.io/tags/java并发编程实战-王宝令/"}]},{"title":"后端导航","date":"2019-10-14T16:00:00.000Z","path":"2019/10/15/软件研发/后端/后端导航/","text":"官网导航java前沿技术人工智能技术人工智能图片补全 博客汇总团队博客美团技术团队&emsp;滴滴技术团队&emsp;阿里中间件团队博客 &emsp;阿里云系统组技术博客&emsp; 腾讯云+社区 Qcon 极客邦&emsp; 个人博客必看博主酷壳 阮一峰的网络日志 敖小剑的博客 领域博主区块链领域万维链博客 其他领域 技匠社 &emsp;少数派&emsp;李学凯&emsp;程序员DD &emsp;周立|Spring Cloud &emsp;泥瓦匠BYSocket的博客 &emsp;KL博客 Edison Xu’s Blog &emsp;梁桂钊的博客 &emsp;城南往事 &emsp;Any-Video 钿畑的博客&emsp; chenssy &emsp;徐靖峰|个人博客 &emsp;猿天地 crossoverjie&emsp; 芋道源码 &emsp;Pure White &emsp;小柒&emsp; 汤雪华的博客&emsp; kafka核心技术讲解作者·huxihx &emsp;黄小斜 黄小斜github&emsp;张逸的博客(ThoughtWorks架构师)&emsp;神经网络与深度学习·邱锡鹏&emsp; 【1】简书主页·share猿【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"导航","slug":"导航","permalink":"https://lywlefan.github.io/tags/导航/"}]},{"title":"后端导航","date":"2019-10-14T16:00:00.000Z","path":"2019/10/15/软件研发/前沿技术/区块链/区块链导航/","text":"企业区块链官方大企业导航壹账链·平安 ) 趣链科技 学习资料收集CONTENTS INTRO 介绍 TUTORIAL 教程 PROJECT 项目 DOCUMENT 资料 APPLICATION 应用 INTRO 介绍Started 入门 （一）简单易懂地介绍什么是区块链 比特币区块链关键词讲解 （二）简单易懂地介绍什么是区块链（技术篇） 比特币区块链技术图解 一文看懂区块链：一步一步发明比特币 一步一步学区块链 按步骤的实际操作入门指南 区块链技术指南 区块链领域比较系统的入门资料 理解区块链 区块链关键技术要点讲解 一文看懂区块链架构设计 从技术分层解构架构 共识算法与如何解决拜占庭将军问题 Ethereum 以太坊进阶 区块链技术-智能合约-以太坊 以太坊智能合约入门概念 以太坊白皮书 The Ethereum Wiki (English) 以太坊设计原理 以太坊Dapp开发入门 以太坊Gas使用 Calculating Costs in Ethereum Contracts (English) 以太坊代码剖析 以太坊源码阅读 Merkle Tree学习 以太坊的指南针 Fabric 联盟链进阶 Blockchain区块链架构设计之一：成员管理 Blockchain区块链架构设计之二：分布式账本技术对比 Blockchain区块链架构设计之三：Hyperledger Fabric介绍 Blockchain区块链架构设计之四：Fabric多通道和下一代账本设计 Blockchain区块链架构设计之五：让DLT产生协作，对Corda和GSL的思考 Blockchain区块链架构设计之六：Fabric 1.0账本设计（1） Blockchain区块链架构设计之七：Fabric 1.0 Endorse背书策略 Hyperledger架构解读：Hyperledger Fabric1.0架构概览 TUTORIAL 教程BitCoin 比特币 Bitcoin and Cryptocurrency Technologies Cousera上的比特币教程 (English) Ethereum 以太坊 以太坊从零开始入门 以太坊开发入门经验 mac配置以太坊本地开发环境 以太坊智能合约编程之菜鸟教程 以太坊常见问题FAQ 区块链语言Solidity校验椭圆曲线加密数字签名（附实例） Create your own crypto-currency 来自以太坊官方的代币创建教程 (English) ETHEREUM PET SHOP Truffle框架逐步案例教程 (English) ROBUST SMART CONTRACTS WITH OPENZEPPELIN OpenZeppelin集成Truffle编写健壮安全的合约 (English) Truffle3.0案例教程 集成NodeJS并完全跑通，附详细实例和可能的错误 (English) 以太坊开发入门教程 Fabric 联盟链 Fabric Basics 使用Docker Toolbox来搭建Fabric的开发环境 (English) Learn Chaincode Fabric Chaincode入门 (English) Marbles Project Tutorial: Part One 官方Chaincode案例教程第一部分 (English) Marbles Project Tutorial: Part Two 官方Chaincode案例教程第二部分 (English) Hyperledger Fabric V1.0– 开发者快速入门 这个是基于baseos 0.2.2 的 搭建运行Fabric V1.0-alpha版本 针对Fabric1.0版本的开发环境搭建指引 Fabric v1.0-alpha 开发镜像编译 使用Fabric源码编译v1.0-alpha版本的Docker镜像指引 Hyperledger Composer使用入门 官方Fabric应用开发工具Hyperledger Composer入门 Fabric-CA-1.0-Alpha小结 Videos 视频 Building Ethereum DApps using Solidity 视频教程 (English) Devcon 0 (Berlin, 2014) talks and videos (English) Devcon 1 (London, 2015) talks and videos (English) Devcon 2 (Shanghai, 2016) talks and videos (English) Devcon 3 (Cancún, 2017) website and registration (English) PROJECT 项目Chain 区块链底层 Metaverse 原界链源码 EOS EOS链源码 BYTOM 比原链源码 NEO NEO链源码 CITA cita联盟链的底层源码 Nervos 公链 Nervos CKB 的底层源码 比特币0.1 最原始的比特币代码 Quorum 来自JP Morgan基于Go-Ethereum数据隐私加强的以太坊实现 FISCO-BCOS 来自金链盟的聚焦金融行业的区块链底层平台 Presto-Ethereum 以太坊增加Presto的SQL访问能力 IPFS IPFS的GO语言实现 原理 SDK 工具包 Remix 在线以太坊编译器 Truffle 以太坊Dapp开发脚手架 Zeppelin 用于编写安全的以太坊合约框架 Web3j 以太坊官方Web3轻量级java SDK Embark 以太坊Dapp开发框架，支持IPFS、Whisper及Orbit调用 Web3Swift 一个Web3的swift SDK Porosity 反编译以太坊智能合约工具 Solidity-Coverage 检测Solidity代码覆盖 Caliper hyperledger区块链性能测试工具 Composer 官方可视化Fabric应用开发框架 Cakeshop 来自JP Morgan的以太坊可视化管理工具 Research 最新研究 eWASM 让以太坊支持WebAssembly FSolidM 可视化智能合约生成工具 源码 Maian 以太坊智能合约漏洞查找工具 Oyente 以太坊智能合约分析工具 Blockbench 区块链性能测试工具 Zokrates 以太坊使用zkSNARKS工具包(实验用) libsnark zkSNARKS C++库 DOCUMENT 资料BitCoin 比特币 精通比特币 精通比特币开发Oreilly开源书 中文翻译版 blockchaindev.org 区块链创业公司维优CTO的专栏 区块链研习社 比特币源码解读 Ethereum 以太坊 Mastering Ethereum 精通以太坊开发Oreilly开源书 区块链技术博客 关注以太坊 以太坊系列教程 solidity语言学习 Solidity语言文档 语言中文手册 Web3.JS接口文档 接口中文手册 Truffle框架文档 框架中文手册 Open Zeppelin框架文档 框架中文手册 Ethplorer接口 Ethplorer接口文档 Ethereum Smart Contract Security Best Practices (english) 以太坊常见问题FAQ EthList 以太坊开发相关学习资料收集 Fabric 联盟链 Fabric Official Docs Fabric官方最新文档 浮白 Fabric开发环境搭建与codechain入门 yeasy的专栏 IBM fabric核心开发者yeasy的专栏 菜鸟的博客 fabric0.6及1.0源码分析 jiang_xinxing的博客 fabric0.6源码分析 APPLICATION 应用Explorer 链浏览 Blockchain 比特币区块链浏览器 Etherscan 以太坊区块链浏览器 Ethplorer 以太坊区块链浏览器，提供API调用 Eth Gas Station 以太坊Gas目前定价 Etherscope 以太坊区块链浏览器 Wallet 钱包 My Ether Wallet 网页版以太坊钱包 源码 MetaMask Chrome Extension浏览器插件版 Multi-platform Jaxx Wallet 同时兼容以太坊和比特币钱包 Mist Wallet 官方版轻量级钱包 Parity Wallet Harmony Wallet imToken 移动App版钱包 Trust iOS / Android 原生钱包 + DApp 浏览器 Cipher iOS / Android 钱包 + DApp 浏览器 Ledger Nano S 硬件钱包 Trezor 硬件钱包 Exchange 交易所 0x 0x交易所平台 源码 IDEX IDEX交易所，目前最活跃 源码 ethdelf etherdelta交易所 源码 forkdelta forkdelta交易所,较活跃 源码 kyber kyber交易所 源码 Dmarket dmarket交易所 源码 augur 对赌交易所 源码 melonport 数字资产交易所 源码 Game 游戏 CryptoKitties 以太猫 Etheremon 以太神奇宝贝 Edgeless 虚拟币在线赌场 源码 IM 通信 status-im status.im项目开源代码 Social 社会 Oraclize 第三方信息提供 Aragon 公司业务 源码 dharma 第三方增信 源码 Chronobank 共享机制 slockit 租借智能设备 源码 DAO DAO提案 Cross Chain 跨链 Cosmos cosmos跨链交易，包括BTC到ETH 源码 polkadot polkadot跨链，实现了一个轻量级以太坊客户端 源码 Token 代币 ERC20 以太坊的ICO代币标准 Token Sale 代币销售模型 maker Dai代币 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"导航","slug":"导航","permalink":"https://lywlefan.github.io/tags/导航/"}]},{"title":"如何把订单均匀分布到分片表里面","date":"2019-09-28T16:00:00.000Z","path":"2019/09/29/软件研发/后端/中间件/分库分表/sharding-jdbc/如何把订单均匀分布到分片表里面/","text":"这几天学习了数据库的中间件—-sharding-jdbc, 参考文档 官方文档 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"分库分表","slug":"分库分表","permalink":"https://lywlefan.github.io/tags/分库分表/"},{"name":"sharding-jdbc","slug":"sharding-jdbc","permalink":"https://lywlefan.github.io/tags/sharding-jdbc/"}]},{"title":"初始Sharding-jdbc.md","date":"2019-09-26T16:00:00.000Z","path":"2019/09/27/软件研发/后端/中间件/分库分表/sharding-jdbc/初始Sharding-jdbc/","text":"让我们一起来学习数据库中间件shardingsphere,shareding-jdbc是他其中的一个产品. what什么是shardingsphere?shardingsphere是一个数据库中间件, 参考文档 官方文档 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"分库分表","slug":"分库分表","permalink":"https://lywlefan.github.io/tags/分库分表/"},{"name":"sharding-jdbc","slug":"sharding-jdbc","permalink":"https://lywlefan.github.io/tags/sharding-jdbc/"}]},{"title":"AOT,JIT学习总结","date":"2019-09-02T16:00:00.000Z","path":"2019/09/03/软件研发/后端/基础巩固/java/jvm/AOT,JIT学习/","text":"万丈高楼平地起的前提是地基好. 是什么?JIT，即Just-in-time,动态(即时)编译，边运行边编译；AOT，Ahead Of Time，指运行前编译，是两种程序的编译方式 区别这两种编译方式的主要区别在于是否在“运行时”进行编译 JIT优点 可以根据当前硬件情况实时编译生成最优机器指令（ps. AOT也可以做到，在用户使用是使用字节码根据机器情况在做一次编译） 可以根据当前程序的运行情况生成最优的机器指令序列 当程序需要支持动态链接时，只能使用JIT 可以根据进程中内存的实际情况调整代码，使内存能够更充分的利用 缺点 编译需要占用运行时资源，会导致进程卡顿 由于编译时间需要占用运行时间，对于某些代码的编译优化不能完全支持，需要在程序流畅和编译时间之间做权衡 在编译准备和识别频繁使用的方法需要占用时间，使得初始编译不能达到最高性能 AOT优点 在程序运行前编译，可以避免在运行时的编译性能消耗和内存消耗 可以在程序运行初期就达到最高性能 可以显著的加快程序的启动 缺点 在程序运行前编译会使程序安装的时间增加 牺牲Java的一致性 将提前编译的内容保存会占用更多的外 【1】简书主页·share猿【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"},{"name":"基础","slug":"基础","permalink":"https://lywlefan.github.io/tags/基础/"}]},{"title":"try-with-resources和multiple catch的学习","date":"2019-09-02T16:00:00.000Z","path":"2019/09/03/软件研发/后端/基础巩固/java/异常/try-with-resources和multiple catch的学习/","text":"万丈高楼平地起的前提是地基好. try-with-resources是什么?在Java编程过程中，如果打开了外部资源（文件、数据库连接、网络连接等），我们必须在这些外部资源使用完毕后，手动关闭它们。因为外部资源不由JVM管理，无法享用JVM的垃圾回收机制，如果我们不在编程时确保在正确的时机关闭外部资源，就会导致外部资源泄露，紧接着就会出现文件被异常占用，数据库连接过多导致连接池溢出等诸多很严重的问题。 为了确保外部资源一定要被关闭，通常关闭代码被写入finally代码块中，当然我们还必须注意到关闭资源时可能抛出的异常，于是变有了下面的经典代码： 1234567891011121314151617public static void main(String[] args) &#123; FileInputStream inputStream = null; try &#123; inputStream = new FileInputStream(new File(\"test\")); System.out.println(inputStream.read()); &#125; catch (IOException e) &#123; throw new RuntimeException(e.getMessage(), e); &#125; finally &#123; if (inputStream != null) &#123; try &#123; inputStream.close(); &#125; catch (IOException e) &#123; throw new RuntimeException(e.getMessage(), e); &#125; &#125; &#125;&#125; multiple catch是什么? 【1】简书主页·share猿【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"},{"name":"基础","slug":"基础","permalink":"https://lywlefan.github.io/tags/基础/"}]},{"title":"内功修炼-算法02","date":"2019-08-12T16:00:00.000Z","path":"2019/08/13/软件研发/算法/算法基础/力扣/内功修炼-算法02/","text":"万丈高楼平地起的前提是地基好. 题目:无重复字符的最长子串题目描述给定一个字符串，请你找出其中不含有重复字符的 最长子串 的长度。 示例 1: 123456789101112131415输入: &quot;abcabcbb&quot;输出: 3 解释: 因为无重复字符的最长子串是 &quot;abc&quot;，所以其长度为 3。示例 2:输入: &quot;bbbbb&quot;输出: 1解释: 因为无重复字符的最长子串是 &quot;b&quot;，所以其长度为 1。示例 3:输入: &quot;pwwkew&quot;输出: 3解释: 因为无重复字符的最长子串是 &quot;wke&quot;，所以其长度为 3。 请注意，你的答案必须是 子串 的长度，&quot;pwke&quot; 是一个子序列，不是子串。 题目分析关键点 不含有重复字符的最大字符串长度 思路梳理我的解题思路 1.把字符串转换为字符数组 2.把字符串逐个放入set集合(set),同时记录放入集合的数量(j) 2.如果set集合长度和放入数量不符,记录该长度(l),清空set集合,把j设置为0,放入刚才放入的值,继续循环 3.如果继续出现上述清空,和上面记录的长度进行对比,小于清空继续,大于更新记录长度 总结:上述解题思路忽略了空格字符串的情况,存在问题. 正确的解题思路:滑动窗口 时间窗移动原理 1.定义一个map集合(map)，用于存储字符值和位置，key为字符，value为字符位置加1 2.定义一个变量ans,用于记录时间窗最大长度 3.定义时间窗起点start和时间窗结束点end 4.然后把end向右滑动,最大长度为（end-start+1），如果map集合中存在该元素,说明遇到了重复的元素 4.1.记录时间窗最大值ans 4.2.移动时间窗start到重复元素第一个之后的位置 5.继续滑动,直到j=字符串长度 题目解答我的解答123456789101112131415161718192021222324252627282930313233/** * 思路一: * * 1.把字符串转换为字符数组 * 2.把字符串逐个放入set集合(set),同时记录放入集合的数量(j) * 2.如果set集合长度和放入数量不符,记录该长度(l),清空set集合,把j设置为0,放入刚才放入的值,继续循环 * 3.如果继续出现上述清空,和上面记录的长度进行对比,小于清空继续,大于更新记录长度 * * 时间复杂度:T(N) 空间复杂度:O(1) * * 测试情况:不通过 * * 总结分析: * * 1.没有考虑到空格字符串的情况 */public int lengthOfLongestSubstring1(String s) &#123; char [] chars = s.toCharArray(); Set set = new HashSet(); int l=0; for (int i=0,j=0;i&lt;chars.length;i++)&#123; set.add(chars[i]); j++; if (set.size()&lt;j)&#123; l = Math.max(set.size(),l); set.clear(); j = 1; set.add(chars[i]); &#125; &#125; return l;&#125; 正确的解答1234567891011121314151617181920212223242526/** * 思路二: 滑动窗口 * * 1.定义一个map集合(map)，用于存储字符值和位置，key为字符，value为字符位置加1 * 2.定义一个变量ans,用于记录时间窗最大长度 * 3.定义时间窗起点start和时间窗结束点end * 4.然后把end向右滑动,最大长度为（end-start+1），如果map集合中存在该元素,说明遇到了重复的元素 * 4.1.记录时间窗最大值ans * 4.2.移动时间窗start到重复元素第一个之后的位置 * 5.继续滑动,直到j=字符串长度 * */public int lengthOfLongestSubstring2(String s) &#123; int n = s.length(), ans = 0; Map&lt;Character, Integer&gt; map = new HashMap&lt;&gt;(); for (int end = 0, start = 0; end &lt; n; end++) &#123; char alpha = s.charAt(end); if (map.containsKey(alpha)) &#123; start = Math.max(map.get(alpha), start); &#125; ans = Math.max(ans, end - start + 1); map.put(s.charAt(end), end + 1); &#125; return ans;&#125; 题目总结在做这道题目的过程中,没有考虑到空格字符串的情况,这是基础不扎实导致的,null/“”/“ “,这三个还是有很大的区别的,如果大家也遇到和我一样的问题,可以当做是一个教训。 还有就是滑动窗口,这个理解比较麻烦,最好可以看我上面画的那种图,或者你可以自己画一个出来,滑动窗口是一个常用的办法,我们要深入理解。记得在有一次做限流的时候也用到了滑动窗口的概念。 问题讨论 假如让你用滑动窗口实现一个简单的限流,如何实现?(加入星球看答案哦!里面有更多精彩内容!) 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 【3】leetcode算法指南 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"力扣","slug":"力扣","permalink":"https://lywlefan.github.io/tags/力扣/"},{"name":"基础","slug":"基础","permalink":"https://lywlefan.github.io/tags/基础/"}]},{"title":"02.redis的线程IO和通讯协议","date":"2019-08-12T16:00:00.000Z","path":"2019/08/13/软件研发/后端/数据存储/NOSQL/redis/03.redis的线程IO和通讯协议/","text":"redis的线程IO 线程IO Redis是个单线程程序!但是他有高并发特性,单个节点可以支持10w的QPS。除了redis是单线程,Nginx也是单线程的。单线程为什么如此之快?单线程有如何处理多并发的客户端连接?下面让我们带着这些问题一起深究redis的线程IO。 5种IO模型学习 阻塞IO模型 非阻塞IO模型 IO复用模型 信号驱动的IO模型 异步IO模型 阻塞IO模型进程发起IO系统调用后，进程被阻塞，转到内核空间处理，整个IO处理完毕后返回进程。操作成功则进程获取到数据。 类比老李去火车站买票，排队三天买到一张退票。 耗费：在车站吃喝拉撒睡 3天，其他事一件没干。 典型应用 阻塞socket java BIO 特点 进程阻塞挂起不消耗CPU资源，及时响应每个操作； 实现难度低、开发应用较容易； 适用并发量小的网络应用开发； 不适用并发量大的应用：因为一个请求IO会阻塞进程，所以，得为每请求分配一个处理进程（线程）以及时响应，系统开销大。 非阻塞IO模型进程发起IO系统调用后，如果内核缓冲区没有数据，需要到IO设备中读取，进程返回一个错误而不会被阻塞；进程发起IO系统调用后，如果内核缓冲区有数据，内核就会把数据返回进程。 类比 老李去火车站买票，隔12小时去火车站问有没有退票，三天后买到一张票。 耗费：往返车站6次，路上6小时，其他时间做了好多事。 典型应用 socket是非阻塞的方式（设置为NONBLOCK） 特点 进程轮询（重复）调用，消耗CPU的资源； 实现难度低、开发应用相对阻塞IO模式较难； 适用并发量较小、且不需要及时响应的网络应用开发； IO复用模型多个的进程的IO可以注册到一个复用器（select）上，然后用一个进程调用该select， select会监听所有注册进来的IO； 如果select没有监听的IO在内核缓冲区都没有可读数据，select调用进程会被阻塞；而当任一IO在内核缓冲区中有可数据时，select调用就会返回； 而后select调用进程可以自己或通知另外的进程（注册进程）来再次发起读取IO，读取内核中准备好的数据。 可以看到，多个进程注册IO后，只有另一个select调用进程被阻塞。 类比是找一个宿管大妈来帮你监视下楼的女生, 这个期间你可以些其他的事情. 例如可以顺便看看其他妹子,玩玩王者荣耀, 上个厕所等等. IO复用又包括 select, poll, epoll 模式. 那么它们的区别是什么? select 每一个女生下楼, select大妈都不知道这个是不是你的女神, 她需要一个一个询问, 并且select大妈能力还有限, 最多一次帮你监视1024个妹子 poll 不限制盯着女生的数量, 只要是经过宿舍楼门口的女生, 都会帮你去问是不是你女神 epoll 不限制盯着女生的数量, 并且也不需要一个一个去问. 那么如何做呢? epoll大妈会为每个进宿舍楼的女生脸上贴上一个大字条,上面写上女生自己的名字, 只要女生下楼了, epoll大妈就知道这个是不是你女神了, 然后大妈再通知你. 典型应用 select poll epoll三种方案 nginx都可以选择使用这三个方案 Java NIO; 特点 专一进程解决多个进程IO的阻塞问题，性能好；Reactor模式; 实现、开发应用难度较大； 适用高并发服务应用开发：一个进程（线程）响应多个请求 形成原因如果一个I/O流进来，我们就开启一个进程处理这个I/O流。那么假设现在有一百万个I/O流进来，那我们就需要开启一百万个进程一一对应处理这些I/O流（——这就是传统意义下的多进程并发处理）。思考一下，一百万个进程，你的CPU占有率会多高，这个实现方式及其的不合理。所以人们提出了I/O多路复用这个模型，一个线程，通过记录I/O流的状态来同时管理多个I/O，可以提高服务器的吞吐能力。 信号驱动的IO模型当进程发起一个IO操作，会向内核注册一个信号处理函数，然后进程返回不阻塞；当内核数据就绪时会发送一个信号给进程，进程便在信号处理函数中调用IO读取数据。 特点 回调机制，实现、开发应用难度大； 异步IO模型当进程发起一个IO操作，进程返回（不阻塞），但也不能返回果结；内核把整个IO处理完后，会通知进程结果。如果IO操作成功则进程直接获取到数据。 特点 不阻塞，数据一步到位；Proactor模式； 需要操作系统的底层支持，LINUX 2.5 版本内核首现，2.6 版本产品的内核标准特性； 实现、开发应用难度大； 非常适合高性能高并发应用 典型 JAVA7 AIO 高性能服务器应用 通过学习5种IO模型,我们知道了Redis就是使用的IO复用模型里面的select。 指令队列Redis 会将每个客户端套接字都关联一个指令队列。客户端的指令通过队列来排队进行顺序处理，先到先服务。 也就是说指令的请求顺序是通过队列来进行约束的。 响应队列每个客户端关联一个响应队列。然后服务端通过响应队列将数据返回给客户端。 定时任务服务器处理要响应 IO 事件外，还要处理其它事情。比如定时任务就是非常重要的一件事。如果线程阻塞在 select 系统调用上，定时任务将无法得到准时调度。那 Redis 是如何解决这个问题的呢？ 如果面试官问到这个问题我肯定是处于懵逼状态。老钱书中写到,redis会把定时任务记录到一个叫最小堆的数据结构中,每个周期循环redis会立即处理堆最上面的数据。 redis的通讯协议 通讯协议 RESP协议简介Redis 的客户端和服务端之间采取了一种独立名为 RESP(REdis Serialization Protocol) 的协议，作者主要考虑了以下几个点： 容易实现 解析快 人类可读 注意：RESP 虽然是为 Redis 设计的，但是同样也可以用于其他 C/S 的软件。 数据类型及示例RESP 主要可以序列化以下几种类型：整数，单行回复(简单字符串)，数组，错误信息，多行字符串。Redis 客户端向服务端发送的是一组由执行的命令组成的字符串数组，服务端根据不同的命令回复不同类型的数据，但协议的每部分都是以 “\\r\\n” (CRLF) 结尾的。另外 RESP 是二进制安全的，不需要处理从一个进程到另一个进程的传输，因为它使用了前缀长度进行传输。 在 RESP 中, 一些数据的类型通过它的第一个字节进行判断： 单行回复：回复的第一个字节是 “+” 错误信息：回复的第一个字节是 “-” 整形数字：回复的第一个字节是 “:” 多行字符串：回复的第一个字节是 “\\$” 数组：回复的第一个字节是 “*” RESP 协议还是相对易于理解的，另外理解了协议也方便对 Redis 一些问题的定位及客户端的实现。 Redis 协议里有大量冗余的回车换行符，但是这不影响它成为互联网技术领域非常受欢迎的一个文本协议。有很多开源项目使用 RESP 作为它的通讯协议。在技术领域性能并不总是一切，还有简单性、易理解性和易实现性，这些都需要进行适当权衡。 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 【3】redis官网 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"redis","slug":"redis","permalink":"https://lywlefan.github.io/tags/redis/"},{"name":"数据存储","slug":"数据存储","permalink":"https://lywlefan.github.io/tags/数据存储/"},{"name":"NOSQL","slug":"NOSQL","permalink":"https://lywlefan.github.io/tags/NOSQL/"}]},{"title":"21.合并两个有序的链表","date":"2019-08-05T16:00:00.000Z","path":"2019/08/06/软件研发/算法/算法基础/力扣/21.合并两个有序的链表/","text":"万丈高楼平地起的前提是地基好. 题目介绍将两个有序链表合并为一个新的有序链表并返回。新链表是通过拼接给定的两个链表的所有节点组成的。 示例 1: 12输入：1-&gt;2-&gt;4, 1-&gt;3-&gt;4输出：1-&gt;1-&gt;2-&gt;3-&gt;4-&gt;4 题目解答思路梳理题目实现java12 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 【3】leetcode算法指南 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"力扣","slug":"力扣","permalink":"https://lywlefan.github.io/tags/力扣/"},{"name":"基础","slug":"基础","permalink":"https://lywlefan.github.io/tags/基础/"}]},{"title":"22.括号的生成","date":"2019-08-04T16:00:00.000Z","path":"2019/08/05/软件研发/算法/算法基础/力扣/22.括号的生成/","text":"万丈高楼平地起的前提是地基好. 题目介绍给出 n 代表生成括号的对数，请你写出一个函数，使其能够生成所有可能的并且有效的括号组合。 例如，给出 n = 3，生成结果为： 12345678[ &quot;((()))&quot;, &quot;(()())&quot;, &quot;(())()&quot;, &quot;()(())&quot;, &quot;()()()&quot;] 思路梳理关键点 生成括号对数 生成括号不同对数 生成的括号必须要闭合 生成括号的类型要用大括号包住 如何实现哪??我的思路:分类法 (X) 第一种情况:括号中括号 第二种情况:括号中多个括号 第三种情况:分割括号,然后括号中括号(左右) 第四种情况:括号独立类型 官方思路:题目实现我的实现分析代码最优解实现分析代码 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 【3】leetcode算法指南 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"力扣","slug":"力扣","permalink":"https://lywlefan.github.io/tags/力扣/"},{"name":"基础","slug":"基础","permalink":"https://lywlefan.github.io/tags/基础/"}]},{"title":"20.有效的括号","date":"2019-08-01T16:00:00.000Z","path":"2019/08/02/软件研发/算法/算法基础/力扣/20.有效的括号/","text":"万丈高楼平地起的前提是地基好. 题目介绍给定一个只包括 ‘(‘，’)’，’{‘，’}’，’[‘，’]’ 的字符串，判断字符串是否有效。 有效字符串需满足： 左括号必须用相同类型的右括号闭合。左括号必须以正确的顺序闭合。注意空字符串可被认为是有效字符串。 示例 1: 1234567891011输入: &quot;()&quot;输出: true示例 2:输入: &quot;()[]&#123;&#125;&quot;输出: true示例 3:输入: &quot;(]&quot;输出: false 题目解答思路梳理哪些情况括号不闭合 第一种:[(]) 第二种:[) 第三种:[]( 如何判断括号没有闭合 注意：只包括括号，这是条件要注意！ 1.获取每种类型左括号的第一次出现的位置 2.然后再找到每种类型右括号第一次出现的位置 3.如果存在以下情况则括号没有闭合 a.类型左括号位置小于另一种类型括号右括号的位置,则括号没有闭合 b.任意类型括号不存在左括号或者右括号,则括号没有闭合 最优解 1.把左括号压入栈中 2.如果遇到右括号,取出栈最上面的元素去对应的值,判断和循环的元素是否相等,相等继续循环,否则返回false 3.循环结束,栈里面的元素依次被取出,说明括号串没啥问题,是闭合的. 题目实现java123456789101112131415161718192021222324static Map&lt;Character, Character&gt; map = new HashMap();static &#123; map.put('(', ')'); map.put('&#123;', '&#125;'); map.put('[', ']');&#125;/** * 方法一 */public boolean isValid(String s) &#123; Stack&lt;Character&gt; stack = new Stack(); for (char in : s.toCharArray()) &#123; //左括号直接入栈 if (map.keySet().contains(in)) &#123; stack.push(in); continue; &#125; if (!stack.isEmpty() &amp;&amp; in == map.get(stack.pop())) continue; return false; &#125; return stack.isEmpty();&#125; 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 【3】leetcode算法指南 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"力扣","slug":"力扣","permalink":"https://lywlefan.github.io/tags/力扣/"},{"name":"基础","slug":"基础","permalink":"https://lywlefan.github.io/tags/基础/"}]},{"title":"算法导航","date":"2019-07-31T16:00:00.000Z","path":"2019/08/01/软件研发/算法/算法导航/","text":"万丈高楼平地起的前提是地基好. 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 【3】leetcode算法指南 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"导航","slug":"导航","permalink":"https://lywlefan.github.io/tags/导航/"}]},{"title":"ab.exe压测工具的使用","date":"2019-07-30T16:00:00.000Z","path":"2019/07/31/软件研发/测试/压力测试/ab.exe压测工具的使用/","text":"工欲善其事，必先利器！ ad.exe介绍ab.exe是一个性能检测工具，是apache server中的一个小组件，使用简单，方便 ad.exe下载下载地址 ad.exe使用步骤打开cmd进入ab.exe所在的路径（默认放在d盘根目录下）命令示例 1234567 #介绍ab的命令ab help#ab命令请求（一共请求10次,10个并发同时请求）ab -n 10 -c 10 http://www.cnblogs.com/#ab命令超时请求（一共请求50次,50个并发同时请求，超时时间设为100秒， 当出现timeout时，可以设置超时时间）ab -n 50 -c 50 -t 100 http://www.cnblogs.com/ ab命令使用场景 可以测试网关的限流 【1】简书主页·share猿【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"压力测试","slug":"压力测试","permalink":"https://lywlefan.github.io/tags/压力测试/"}]},{"title":"01.初始redis","date":"2019-07-29T16:00:00.000Z","path":"2019/07/30/软件研发/后端/数据存储/NOSQL/redis/01.初始redis/","text":"redis是什么?redis是一个内存型数据(in-memory data structure store)。Redis是用ANSI C编写的。 官网对redis关键词描述 开源内存数据库 可以进行缓存和消息代理 支持的数据类型有：字符串/hash/list/set/bitmaps/hyperloglogs 可以对集合进行排序 地理位置范围半径查询 支持流 内置复制功能 支持lua脚本 LRU缓存淘汰算法 磁盘级的持久化 redis集群 redis支持什么数据类型字符类型(strings)哈希类型(hashes)list集合类型(lists)set集合类型(sets) 不允许重复 无序 sorted set集合类型(sorted sets) 不允许重复 有序(通过设置分数进行排序) 位图(bitmaps) 按位进行标识 适合某个时间段状态只有两种的场景 比如:签到,每天签到,状态就是签了或者没签 占用内存小 hyperloglogs Redis 在 2.8.9 版本添加了 HyperLogLog 结构 Redis HyperLogLog 是用来做基数统计的算法，HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定 的、并且是很小的。 在 Redis 里面，每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基数。这和计算基数时，元素越多耗费内存就越多的集合形成鲜明对比。 因为 HyperLogLog 只会根据输入元素来计算基数，而不会储存输入元素本身，所以 HyperLogLog 不能像集合那样，返回输入的各个元素。 HyperLogLog是一种算法，并非redis独有 目的是做基数统计，故不是集合，不会保存元数据，只记录数量而不是数值。 耗空间极小，支持输入非常体积的数据量 核心是基数估算算法，主要表现为计算时内存的使用和数据合并的处理。最终数值存在一定误差 redis中每个hyperloglog key占用了12K的内存用于标记基数（官方文档） pfadd命令并不会一次性分配12k内存，而是随着基数的增加而逐渐增加内存分配；而pfmerge操作则会将sourcekey合并后存储在12k大小的key中，这由hyperloglog合并操作的原理（两个hyperloglog合并时需要单独比较每个桶的值）可以很容易理解。 误差说明：基数估计的结果是一个带有 0.81% 标准错误（standard error）的近似值。是可接受的范围 Redis 对 HyperLogLog 的存储进行了优化，在计数比较小时，它的存储空间采用稀疏矩阵存储，空间占用很小，仅仅在计数慢慢变大，稀疏矩阵占用空间渐渐超过了阈值时才会一次性转变成稠密矩阵，才会占用 12k 的空间 数据结构描述特征 基数统计(不允许重复的数据) 占用12k空间 适用场景 统计注册 IP 数 统计每日访问 IP 数 统计页面实时 UV 数 统计在线用户数 统计用户每天搜索不同词条的个数 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 【3】redis官网 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"redis","slug":"redis","permalink":"https://lywlefan.github.io/tags/redis/"},{"name":"数据存储","slug":"数据存储","permalink":"https://lywlefan.github.io/tags/数据存储/"},{"name":"NOSQL","slug":"NOSQL","permalink":"https://lywlefan.github.io/tags/NOSQL/"}]},{"title":"02.redis的应用--布隆过滤器","date":"2019-07-29T16:00:00.000Z","path":"2019/07/30/软件研发/后端/数据存储/NOSQL/redis/02.redis的应用--布隆过滤器/","text":"布隆过滤器思维导图 布隆过滤器 布隆过滤器应用新闻推送去重垃圾邮件去重插件安装下载插件点击该地址选择合适的版本 1234567#下载wget https://github.com/RedisLabsModules/rebloom/archive/v1.1.1.tar.gz#解压tar zxvf v1.1.1.tar.gzcd rebloom-1.1.1# 编译make 配置插件在redis配置文件(redis.conf)中加入该模块即可 1loadmodule /usr/local/web/redis/RedisBloom-1.1.1/rebloom.so 或者启动的时候加载进去： 1redis-server /etc/redis/redis.conf --loadmodule /opt/redis/RedisBloom-2.0.1/src/rebloom.so INITIAL_SIZE 10000000 ERROR_RATE 0.0001 执行相关命令测试 以上就是我安装的步骤，但是安装完成后还是出现了问题，记录下来，后续慢慢解决。 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 【3】redis官网 【4】布隆过滤器插件下载地址 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"redis","slug":"redis","permalink":"https://lywlefan.github.io/tags/redis/"},{"name":"数据存储","slug":"数据存储","permalink":"https://lywlefan.github.io/tags/数据存储/"},{"name":"NOSQL","slug":"NOSQL","permalink":"https://lywlefan.github.io/tags/NOSQL/"}]},{"title":"MPP(大规模并行处理)简介","date":"2019-07-18T16:00:00.000Z","path":"2019/07/19/软件研发/后端/数据存储/MBPP数据库/MPP(大规模并行处理)简介/","text":"&emsp;&emsp;实践一门技术的最好方式就是深入理解它的思想，然后造一个出来！ 1、 什么是MPP？MPP (Massively Parallel Processing)，即大规模并行处理，在数据库非共享集群中，每个节点都有独立的磁盘存储系统和内存系统，业务数据根据数据库模型和应用特点划分到各个节点上，每台数据节点通过专用网络或者商业通用网络互相连接，彼此协同计算，作为整体提供数据库服务。非共享数据库集群有完全的可伸缩性、高可用、高性能、优秀的性价比、资源共享等优势。 简单来说，MPP是将任务并行的分散到多个服务器和节点上，在每个节点上计算完成后，将各自部分的结果汇总在一起得到最终的结果(与Hadoop相似)。 2、MPP(大规模并行处理)架构 (MPP架构) 3、 MPP架构特征● 任务并行执行; ● 数据分布式存储(本地化); ● 分布式计算; ● 私有资源; ● 横向扩展; ● Shared Nothing架构。 4、 MPP服务器架构它由多个SMP服务器通过一定的节点互联网络进行连接，协同工作，完成相同的任务，从用户的角度来看是一个服务器系统。其基本特征是由多个SMP服务器(每个SMP服务器称节点)通过节点互联网络连接而成，每个节点只访问自己的本地资源(内存、存储等)，是一种完全无共享(Share Nothing)结构，因而扩展能力最好，理论上其扩展无限制。 5、MPPDBMPPDB是一款 Shared Nothing 架构的分布式并行结构化数据库集群，具备高性能、高可用、高扩展特性，可以为超大规模数据管理提供高性价比的通用计算平台，并广泛地用于支撑各类数据仓库系统、BI 系统和决策支持系统 6、MPPDB架构MPP 采用完全并行的MPP + Shared Nothing 的分布式扁平架构，这种架构中的每一个节点（node）都是独立的、自给的、节点之间对等，而且整个系统中不存在单点瓶颈，具有非常强的扩展性。 7、 MPPDB特征MPP 具备以下技术特征： 1) 低硬件成本：完全使用 x86 架构的 PC Server，不需要昂贵的 Unix 服务器和磁盘阵列； 2) 集群架构与部署：完全并行的 MPP + Shared Nothing 的分布式架构，采用 Non-Master 部署，节点对等的扁平结构； 3) 海量数据分布压缩存储：可处理 PB 级别以上的结构化数据，采用 hash分布、random 存储策略进行数据存储；同时采用先进的压缩算法，减少存储数据所需的空间，可以将所用空间减少 1~20 倍，并相应地提高 I/O 性能； 4) 数据加载高效性：基于策略的数据加载模式，集群整体加载速度可达2TB/h； 5) 高扩展、高可靠：支持集群节点的扩容和缩容，支持全量、增量的备份/恢复; 6) 高可用、易维护：数据通过副本提供冗余保护，自动故障探测和管理，自动同步元数据和业务数据。提供图形化工具，以简化管理员对数据库的管理工作； 7) 高并发：读写不互斥，支持数据的边加载边查询，单个节点并发能力大于 300 用户； 8) 行列混合存储：提供行列混合存储方案，从而提高了列存数据库特殊查询场景的查询响应耗时； 9) 标准化：支持SQL92 标准，支持 C API、ODBC、JDBC、ADO.NET 等接口规范。 8、 常见MPPDB● GREENPLUM(EMC) ● Asterdata(Teradata) ● Nettezza(IBM) ● Vertica(HP) ● GBase 8a MPP cluster(南大通用) 9、 MPPDB、Hadoop与传统数据库技术对比与适用场景MPPDB与Hadoop都是将运算分布到节点中独立运算后进行结果合并(分布式计算)，但由于依据的理论和采用的技术路线不同而有各自的优缺点和适用范围。两种技术以及传统数据库技术的对比如下： 综合而言，Hadoop和MPP两种技术的特定和适用场景为： ● Hadoop在处理非结构化和半结构化数据上具备优势，尤其适合海量数据批处理等应用要求。 ● MPP适合替代现有关系数据机构下的大数据处理，具有较高的效率。 MPP适合多维度数据自助分析、数据集市等；Hadoop适合海量数据存储查询、批量数据ETL、非机构化数据分析(日志分析、文本分析)等。 由上述对比可预见未来大数据存储与处理趋势：MPPDB+Hadoop混搭使用，用MPP处理PB级别的、高质量的结构化数据，同时为应用提供丰富的SQL和事物支持能力；用Hadoop实现半结构化、非结构化数据处理。这样可以同时满足结构化、半结构化和非结构化数据的高效处理需求。 【1】简书主页·share猿 【2】掘金主页·share猿 — 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"数据存储","slug":"数据存储","permalink":"https://lywlefan.github.io/tags/数据存储/"},{"name":"MBPP数据库","slug":"MBPP数据库","permalink":"https://lywlefan.github.io/tags/MBPP数据库/"}]},{"title":"理财书籍收集","date":"2019-07-17T16:00:00.000Z","path":"2019/07/18/读书看报/书单/理财书籍收集/理财书籍收集/","text":"多读书，多看报，少吃零食，少睡觉！ 理财书籍汇集未读 《谁动了我的奶酪》 《小狗钱钱》 《富爸爸，穷爸爸》，《财务自由之路》和《投资指南》 《一分钟百万富翁》 《怎样启迪你头脑中的金融意识》 《财源滚滚》 《钻石就在你家后院》 《我的百万富翁兄弟》 已读 【1】简书主页·share猿【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"书单","slug":"书单","permalink":"https://lywlefan.github.io/tags/书单/"},{"name":"理财","slug":"理财","permalink":"https://lywlefan.github.io/tags/理财/"}]},{"title":"财务词汇","date":"2019-07-10T16:00:00.000Z","path":"2019/07/11/读书看报/词汇/财务/财务词汇/","text":"先有词汇量,然后再能好好说话,好好做事。 重要 不重要 理解 未理解 2019年7月份词汇重要理解词汇 资产 G:如何获得资产？a.加杠杆购买资产，产生源源不断的现金流b.花时间创造资产 负债 现值 是在给定的利率水平下，未来的资金折现到现在时刻的价值。 现金流 经营性现金流 投资性现金流 融资性现金流 资产负债表 损益表 所有者权益变动表 财务报表附注 审查报表 预算盈余 净现值法（NPV） 净现值 未来资金流现值与未来资金流出现值差额。 折现率 折现率是指将未来有限期预期收益折算成现值的比率。 内部收益率（IRR） 不重要理解词汇 直线法折旧 双倍余额递减法折旧（年折旧率=2÷预计的折旧年限×100％） 重要不理解词汇不重要不理解词汇 借款人 信贷人员 银行流水 【1】简书主页·share猿【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"词汇","slug":"词汇","permalink":"https://lywlefan.github.io/tags/词汇/"},{"name":"财务","slug":"财务","permalink":"https://lywlefan.github.io/tags/财务/"}]},{"title":"研发英文词汇收集","date":"2019-07-10T16:00:00.000Z","path":"2019/07/11/读书看报/词汇/软件/研发英文词汇收集/","text":"先有词汇量,然后再能好好说话,好好做事。 java相关词汇框架存储关系型非关系型newSqlredis相关词汇 内存数据库:in-memory data structure store 消息代理:message broker 【1】简书主页·share猿【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"软件","slug":"软件","permalink":"https://lywlefan.github.io/tags/软件/"},{"name":"英文","slug":"英文","permalink":"https://lywlefan.github.io/tags/英文/"}]},{"title":"软件中未知词汇收集","date":"2019-07-10T16:00:00.000Z","path":"2019/07/11/读书看报/词汇/软件/软件中未知词汇收集/","text":"先有词汇量,然后再能好好说话,好好做事。 2019年词汇7月词汇二方库 一方库：本工程中的各模块的相互依赖 二方库：公司内部的依赖库，一般指公司内部的其他项目发布的jar包 三方库：公司之外的开源库， 比如apache、ibm、google等发布的依赖 mock数据在前后端分离开发过程中，后端为前端请求制造的模拟数据。常见制造模拟数据的方法有如下几种： easymock Mock.js server-mock SOA面向服务架构（Service-Oriented Architecture，SOA）又称“面向服务的体系结构”，是Gartner于2O世纪9O年代中期提出的面向服务架构的概念。 打tag说白了就是给你的项目打个标签，立个里程碑，这样就可以去方便的回溯每个版本的代码了。如何打tag，命令如下： 123456# 打tag -a 后面是tag名称 -m 后面是注释（这里我们可以写我们这个版本做了什么？）git tag -a v3.2.1 -m &apos;线上版本&apos;# 将标签提交到远程仓库git push origin v3.2.1 qps每秒查询率QPS是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准，在因特网上，作为域名系统服务器的机器的性能经常用每秒查询率来衡量。 吞吐量 吞吐量是指系统在单位时间内处理请求的数量。 并发用户数 并发用户数是指系统可以同时承载的正常使用系统功能的用户的数量。 IO线程VisualVMVisualVM是JDK自带的一款全能型性能监控和故障分析工具,包括对CPU使用、JVM堆内存消耗、线程、类加载的实时监控,内存dump文件分析,垃圾回收运行情况的可视化分析等,对故障排查和性能调优很有帮助。 包装类包装类（Wrapper Class）： Java是一个面向对象的编程语言，但是Java中的八种基本数据类型却是不面向对象的，为了使用方便和解决这个不足，在设计类时为每个基本数据类型设计了一个对应的类进行代表，这样八种基本数据类型对应的类统称为包装类(Wrapper Class)，包装类均位于java.lang包。 栈栈就像枪的梭子一样,先进后出. 8月词汇TDDTDD是测试驱动开发（Test-Driven Development）的英文简称，是敏捷开发中的一项核心实践和技术，也是一种设计方法论。 时间复杂度一个算法中的所有语句执行次数之和称为语句频度或时间频度,记为T(n)。 空间复杂度如果算法执行所需要的临时空间不随着某个变量n的大小而变化，即此算法空间复杂度为一个常量，可表示为 O(1) 哑结点说白了就是无用的节点,一般处在链表的头部.是一个被人为创建的节点，虽然其内容为NULL，但是它在堆中有占有一定的空间。哑节点的使用可以避免边界问题的处理，达到简化代码与减少代码出错可能性的目的。 10月词汇QPSQuery Per Second，每秒请求数 IOPSInput/Output Operations Per Second，即每秒进行读写操作的次数 RT响应时间 【1】简书主页·share猿【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"软件","slug":"软件","permalink":"https://lywlefan.github.io/tags/软件/"},{"name":"新词","slug":"新词","permalink":"https://lywlefan.github.io/tags/新词/"}]},{"title":"02.Java内存模型：看Java如何解决可见性和有序性问题","date":"2019-07-02T16:00:00.000Z","path":"2019/07/03/软件研发/后端/高并发/java/书籍/java并发编程实战-王宝令/02.Java内存模型：看Java如何解决可见性和有序性问题 /","text":"阅读笔记 java内存模型 volatile Happens-Before规则 什么是java内存模型？java内存模型说的直白一点就是java程序使用内存的规范，让java语言在各种系统和平台中能保持数据的一致性。 Happens-Before规则（6项规则）前一个操作对后一个操作是可见的。假如有一个公有变量，a方法先引用然后b方法再引用，那么我们称a方法的操作对b方法可见。 程序顺序性规则假如有一个公有变量，a方法先引用然后b方法再引用，那么我们称a方法的操作对b方法可见。 volatile变量规则volatile变量的写操作对volatile变量读操作可见。说白了读之前，我要知道是谁写的，不然我不读。 传递性如果A对B可见，B对C可见，那么A对C可见。 管程中锁的规则管程是一种通用的同步原语，在java中指的是synchronized,synchronized是java里对管程的实现。 对变量进行加锁，执行完再继续。 线程smart()规则它是指主线程 A 启动子线程 B 后，子线程 B 能够看到主线程在启动子线程 B 前的操作。 G:说白了就是主线程要优于子线程。 线程join()规则关键词解析volatile这个关键词可以禁用cpu缓存。禁用了cpu缓存，那么我们的变量只能从内存中进行读写。 Happens-Before规则Happens-Before规则说白了就是定义java内存模型的一种约束或者规则。 推荐书单 -《Java并发编程实战》作者阵容可谓大师云集，也包括Doug Lea -《Java并发编程的艺术》讲解并发包内部实现原理，能读明白，内功大增 -《图解Java多线程设计模式》并发编程设计模式方面的经典书籍 -《操作系统：精髓与设计原理》经典操作系统教材 http://ifeve.com 国内专业并发编程网站 http://www.cs.umd.edu/~pugh/java/memoryModel/ 很多并发编程的早期资料都在这里 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"},{"name":"读书笔记","slug":"读书笔记","permalink":"https://lywlefan.github.io/tags/读书笔记/"},{"name":"高并发","slug":"高并发","permalink":"https://lywlefan.github.io/tags/高并发/"},{"name":"java并发编程实战-王宝令","slug":"java并发编程实战-王宝令","permalink":"https://lywlefan.github.io/tags/java并发编程实战-王宝令/"}]},{"title":"01.可见性、原子性和有序性问题：并发编程Bug的源头","date":"2019-07-01T16:00:00.000Z","path":"2019/07/02/软件研发/后端/高并发/java/书籍/java并发编程实战-王宝令/01.可见性、原子性和有序性问题：并发编程Bug的源头 /","text":"阅读笔记 可见性 原子性 有序性 并发幕后的故事这些年，我们的 CPU、内存、I/O 设备都在不断迭代，不断朝着更快的方向努力。但是，在这个快速发展的过程中，有一个核心矛盾一直存在，就是这三者的速度差异。 CPU和内存速度差异可以形象描述:CPU是天上一天，内存是地上一年。内存和I/O设备速度差异就更大了，内存是天山一天，I/O设备是地上十年。 大部分程序是需要访问内存，有些还要访问I/O,所以单方面提高CPU性能是无效的。 为了合理利用CPU高性能，平衡三者的速度差异，计算机体系/操作系统/编译程序都做了很大的贡献，主要体现在以下几点： CPU增加了缓存，以均衡速度差异 操作系统增加了进程/线程，以分时复用CPU，进而均衡CPU与I/O设备的速度差异； 编译程序优化指令执行次序，使得缓存能够更加合理的利用。 源头之一：缓存导致的可见性问题单核时代单核时代，所有线程在一颗CPU上执行，CPU缓存与内存的数据一致性容易解决。 一个线程对CPU的操作，其他线程都是可见的。 如下图所示，线程A和线程B都是操作同一个CPU里面的缓存，线程A操作CPU变量V之后，线程B再访问就一定可以得到最新值： 一个线程对共享变量的修改，另外一个线程立刻看到，我们称为可见性。 多核时代多核时代，每颗 CPU 都有自己的缓存，这时 CPU 缓存与内存的数据一致性就没那么容易解决了。 当多个线程在不同的 CPU 上执行时，这些线程操作的是不同的CPU。 线程 A 操作的是 CPU-1 上的缓存，而线程B操作的是 CPU-2 上的缓存，很明显，这个时候线程 A 对变量 V 的操作对于线程B 而言就不具备可见性了。这个就属于硬件程序员给软件程序员挖的“坑”。 多核 CPU 的缓存与内存关系图 下面我们再用一段代码来验证一下多核场景下的可见性问题。下面的代码，每执行一次 add10K() 方法，都会循环 10000 次 count+=1 操作。在 calc() 方法中我们创建了两个线程，每个线程调用一次 add10K() 方法，我们来想一想执行 calc() 方法得到的结果应该是多少呢？ 1234567891011121314151617181920212223242526public class Test &#123; private long count = 0; private void add10K() &#123; int idx = 0; while(idx++ &lt; 10000) &#123; count += 1; &#125; &#125; public static long calc() &#123; final Test test = new Test(); // 创建两个线程，执行 add() 操作 Thread th1 = new Thread(()-&gt;&#123; test.add10K(); &#125;); Thread th2 = new Thread(()-&gt;&#123; test.add10K(); &#125;); // 启动两个线程 th1.start(); th2.start(); // 等待两个线程执行结束 th1.join(); th2.join(); return count; &#125;&#125; 直觉可能告诉你应该是20000，但实际结果确实10000到20000之间的随机数。为什么那？因为两个线程在两cpu的核之间不断切换才导致的。 G:所谓可见性问题，说白了可见性是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值同时可以操作这个值。 源头之二：线程切换带来的原子性问题 关键词： 线程切换 时间片 多进程 unix操作系统支持多进程分时复用而名噪天下 内存映射 一个进程创建的所有线程共享同一个内存空间 提到的“任务切换”都是指“线程切换” 高级语句里一条语句需要多条CPU指令来完成 比如：count + =1，需要以下几个指令来完成 指令一：把count从内存加载到cpu寄存器中 指令二：在寄存器执行+1操作 指令三：最后，将结果写入内存（缓存机制导致可能写入的是CPU缓存而不是内存） 重点语句 我们把一个或多个操作在CPU执行的过程中不被中断的特性称为原子性。 源头之三：编译优化带来的有序性问题 关键词 - 关键语句 有序性：代码按先后顺序执行 案例分析 利用双重检查创建单例对象 123456789101112public class Singleton &#123; static Singleton instance; static Singleton getInstance()&#123; if (instance == null) &#123; synchronized(Singleton.class) &#123; if (instance == null) instance = new Singleton(); &#125; &#125; return instance; &#125;&#125; 上面的代码，假设有两个线程同时判断instance为null—&gt;此时A和B任意一个线程加锁成功（假设是A）,另外一个线程处于等待状态（假设是B）—&gt;线程A创建实例释放锁，然后唤醒B —&gt; B继续加锁，结果实力不为空，B不创建实例 以上逻辑看似无懈可击，但实际并不完美，问题出在哪里？？ 出在new操作上 我们以为的new操作： 1.分配一块内存M 2.在内存M上初始化Singleton对象 3.然后M的地址赋值给instance对象 实际优化后如下： 1.分配一块内存M 2.将M的地址赋值给instanc变量 3.最后在M上初始化Singleton对象 优化后会导致什么问题那？假设A先执行getInstance()方法，当执行完指令2后恰好发生了线程切换，切换到线程B上；如果此时线程B也执行getInstance方法，那么线程B在执行第一个判断时会发现instance！=null，所以直接返回instance，而此时的instance是没有初始化过的，如果这个时候访问instance的成员变量就可能触发空指针异常。 总结 要想写好并发，就要知道并发问题出在哪里 只要我们能够深刻理解可见性/原子性/有序性在并发场景下的原理，很多并发bug都可以理解，可以诊断。 缓存导致可见性问题 线程切换带来的原子性问题 编译优化带来的有序性问题 在采用一项技术的时候一定要清楚它带来的问题是啥，以及如何规避 思考 1.常听人说，在 32 位的机器上对 long 型变量进行加减操操作存在并发隐患，到底是不是这样呢？ long类型64位，所以在32位的机器上，对long类型的数据操作通常需要多条指令组合出来，无法保证原子性，所以并发的时候会出问题 疑问：什么是32位机器？指的是啥？ cpu运算的数据都是由内存提供的，内存与cpu的通信速度靠的是外部频率（所谓外频指的是cpu与外部组件进行数据传输/运算是的速度，倍频则是cpu内部用来加速工作性能的一个倍数，两者相乘才是cpu的频率），每次工作可以传输的数据量大小是由总线决定的。一般主板芯片组分为北桥与南桥，北桥的总线称为系统总线，因为是内存传输的主要信道，所以速度较快；南桥就是所谓的输入输出（I/O）总线，主要用于联系硬盘、usb、网卡等接口设备。 北桥所支持的频率我们称之为前端总线速度（Front Side Bus,FSB），而每次传输的位数则是总线宽度。所以总线频宽 = FSB x 总线宽度，也就是每秒钟可传送的最大数据量，目前常见的总线宽度有32为和64位。 例如前端总线的最高速度可达1600MHZ。我们看到内存和北桥的频宽为12.8GB/S，也就是1600MHZ x 64Bit =1600MHZ x 8Bytes = 12800MHZ = 12.8GB/S。 与总线宽度相似，cpu每次能处理的数据量称为字组大小，字组大小依据cpu的设计而有32位与64位。我们现在所称的计算机是32位或64位主要依据cpu解析的字组大小而来的！早期的32位cpu中，因为cpu每次能够解析的数据量有限，因此由内存传来的数据量就有所限制了。这也导致32位的cpu最多只能支持最大到4GB的内存。 ​ 推荐书单 -《Java并发编程实战》作者阵容可谓大师云集，也包括Doug Lea -《Java并发编程的艺术》讲解并发包内部实现原理，能读明白，内功大增 -《图解Java多线程设计模式》并发编程设计模式方面的经典书籍 -《操作系统：精髓与设计原理》经典操作系统教材 http://ifeve.com 国内专业并发编程网站 http://www.cs.umd.edu/~pugh/java/memoryModel/ 很多并发编程的早期资料都在这里 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"},{"name":"读书笔记","slug":"读书笔记","permalink":"https://lywlefan.github.io/tags/读书笔记/"},{"name":"高并发","slug":"高并发","permalink":"https://lywlefan.github.io/tags/高并发/"},{"name":"java并发编程实战-王宝令","slug":"java并发编程实战-王宝令","permalink":"https://lywlefan.github.io/tags/java并发编程实战-王宝令/"}]},{"title":"学习攻略.如何才能学好并发编程？","date":"2019-07-01T16:00:00.000Z","path":"2019/07/02/软件研发/后端/高并发/java/书籍/java并发编程实战-王宝令/学习攻略.如何才能学好并发编程？/","text":"阅读笔记并发是一门独立学科也是一门综合科学，从两个方面突破并发编程： 跳出来，看全景 钻进去，看本质 跳出来，看全景学习最忌讳的就是“盲人摸象”，只看到局部，没有全局。从单一知识点跳出来，高屋建瓴看并发编程，首要之事就是建立一张全景图。 并发核心问题分工像做项目的分工一样，不同的工作分给不同的人，实现工作效率最大化。 在学习抽象的东西的时候要多与现实生活中的场景进行类比。 Java SDK 并发包里的 Executor、Fork/Join、Future本质上都是一种分工的方式。 并发编程领域还总结了一些设计模式，基本上都是和分工方法相关的，例如生产者 - 消费者、Message、Worker Thread 模式等。 同步同步就相当于项目中的沟通协调，什么时间干什么工作。 放到软件程序中就是一个线程执行完，通知下一个线程执行而已。例如，用 Future 可以发起一个异步调用，当主线程通过 get() 方法取结果时，主线程就会等待，当异步执行的结果返回时，get() 方法就自动返回了，这就解决了我们主从线程的协作。 Java SDK 里提供的 CountDownLatch、CyclicBarrierr、Phaser、Exchanger 也都是用来解决线程协作问题的。 还有很多场景，是需要你自己来处理线程之间的协作。 在java并发编程领域，解决协作问题的核心就是管程，上面提到的所有线程协作技术底层都是利用管程解决的。管程是一种解决并发问题的通用模型，除了能解决线程协助问题，还能解决下面我们将要介绍的互斥问题。可以这么说，管程是解决并发问题的万能钥匙。 关键是理解管程模型，学好它就可以解决所有问题。 其次是了解java JDK并发包提供的几个线程协作的工具类场景，用好它们可以妥妥地提高你的工作效率。 互斥分工/同步主要强调性能，但是并发程序里还有一部分是关于正确性，用专业术语叫“线程安全”。 可见性问题 有序性问题 原子性问题 为了解决以上三个问题，java语言引入了内存模型，内存模型提供了一系列的规则，利用这些规则，我们可以避免以上问题。 所谓互斥，指的是同一时刻，只允许一个线程访问共享变量。 实现互斥的核心技术是锁，java语言里synchronized、SDK里各种Lock都能解决互斥问题。 虽说锁解决了安全性问题，但同时也带来了性能问题，那如何保证安全性的同时又尽量提高性能那？分场景优化： Java SDK 里提供的 ReadWriteLock、StampedLock 就可以优化读多写少场景下锁的性能。 还可以使用无锁的数据结构，例如 Java SDK 里提供的原子类都是基于无锁技术实现的。 除此之外，还有一些其他的方案，原理是不共享变量或者变量只允许许读。这方面，Java 提供了Thread Local 和 final 关键字，还有一种 Copy-on-write 的模式。 使用锁除了要注意性能问题外，还需要注意死锁问题。 这部分内容比较复杂，往往还是跨领域的，例如要理解可见性，就需要了解一些 CPU 和缓存的知识； 很多无锁算法的实现往往也需要理解 CPU 缓存。 这部分内容的学习，需要博览群书，在大脑里建立起 CPU、内存、I/O 执行的模拟器。 全景图 钻进去，看本质深入理解，找到本质。 多分析这些概念和结论是怎么来的？？ 它们是用来解决什么问题的？ 知其然知其所以然。 工程上解决问题，一定要有理论做基础。 总结 推荐书单 -《Java并发编程实战》作者阵容可谓大师云集，也包括Doug Lea -《Java并发编程的艺术》讲解并发包内部实现原理，能读明白，内功大增 -《图解Java多线程设计模式》并发编程设计模式方面的经典书籍 -《操作系统：精髓与设计原理》经典操作系统教材 http://ifeve.com 国内专业并发编程网站 http://www.cs.umd.edu/~pugh/java/memoryModel/ 很多并发编程的早期资料都在这里 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"},{"name":"读书笔记","slug":"读书笔记","permalink":"https://lywlefan.github.io/tags/读书笔记/"},{"name":"高并发","slug":"高并发","permalink":"https://lywlefan.github.io/tags/高并发/"},{"name":"java并发编程实战-王宝令","slug":"java并发编程实战-王宝令","permalink":"https://lywlefan.github.io/tags/java并发编程实战-王宝令/"}]},{"title":"12.客户端都有哪些不常见但是很高级的功能？","date":"2019-07-01T16:00:00.000Z","path":"2019/07/02/软件研发/后端/中间件/消息中间件/kafka/读书笔记/kafka核心技术与实战-胡夕/12.客户端都有哪些不常见但是很高级的功能？/","text":"阅读笔记kafka 拦截器拦截器的原理和spring的拦截器的原理类似，可以做消息处理前后多个点的动态植入不同的处理逻辑。比如消息发送前或者在消息消费后。 kafka拦截器分为生产者拦截器和消费者拦截器。 生产拦截器允许你在发送消息前以及消息提交后植入你的拦截器逻辑； 消费拦截器支持在消费消息前以及提交位移后编写特定逻辑。 两种拦截器都支持链的方式，kafka会按序执行拦截器逻辑。 ###如何编写拦截器？ 生产者拦截器继承接口ProducerInterceptor onSend：消息调用前被调用 onAcknowledgement：消息提交成功或发送失败后被调用。这个方法要早于callback。这个方法和onSend不是在同一个线程里面调用，因此在两个方法调用过程中调用了某个共享变量，一定要保证线程安全。这个方法处在Producer发送的主路径中，所以我们不要放一些太重逻辑进去，负责你会发现Producer的TPS直线下降。 消费者拦截器实现ConsumerInterceptor接口 onConsume：在消息返回给Consumer 程序之前调用。也就是在消息开始处理前拦截一道。 onCommit：Consumer 在提交位移之后调用该方法。通常你可以在该方法做一些记账类的动作，比如：日志打印。 注意的问题 指定拦截器要指定它们全限定名，说的直白一点就是要把包名加上 典型使用场景 客户端监控 kafka默认提供的监控指标都是针对单个客户端或Broker的，你很难从具体消息维度去追踪群间消息的流转路径。同时如何监控一条消息从生产到最后消费的端到端延时也是很多kafka用户需要解决的问题。 从技术上讲，我们可以在客户端增加这样的逻辑，但是监控一般是不跟业务代码耦合的，因为耦合会影响业务代码性能。 基于以上的考虑，我们可以把监控的逻辑加到拦截器里面，这样做的好处可以实现可插拔，不耦合。 端到端性能检测 同上。 消息审计 所谓消息审计就是可以随时查看消息的去向，什么时间发布的？被什么业务消费了？我们就可以借用kafka的拦截器实现这个场景。 案例分享 处理端到端的延时 统计Producer到Consumer消费时间总时长，我们消费拦截器就可以按如下来写 1234567891011121314151617181920212223242526public class AvgLatencyProducerInterceptor implements ProducerInterceptor&lt;String, String&gt; &#123; private Jedis jedis; // 省略 Jedis 初始化 @Override public ProducerRecord&lt;String, String&gt; onSend(ProducerRecord&lt;String, String&gt; record) &#123; jedis.incr(\"totalSentMessage\"); return record; &#125; @Override public void onAcknowledgement(RecordMetadata metadata, Exception exception) &#123; &#125; @Override public void close() &#123; &#125; @Override public void configure(Map&lt;java.lang.String, ?&gt; configs) &#123; &#125; 下面是消费端代码：123456789101112131415161718192021222324252627282930313233public class AvgLatencyConsumerInterceptor implements ConsumerInterceptor&lt;String, String&gt; &#123; private Jedis jedis; // 省略 Jedis 初始化 @Override public ConsumerRecords&lt;String, String&gt; onConsume(ConsumerRecords&lt;String, String&gt; records) &#123; long lantency = 0L; for (ConsumerRecord&lt;String, String&gt; record : records) &#123; lantency += (System.currentTimeMillis() - record.timestamp()); &#125; jedis.incrBy(\"totalLatency\", lantency); long totalLatency = Long.parseLong(jedis.get(\"totalLatency\")); long totalSentMsgs = Long.parseLong(jedis.get(\"totalSentMessage\")); jedis.set(\"avgLatency\", String.valueOf(totalLatency / totalSentMsgs)); return records; &#125; @Override public void onCommit(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets) &#123; &#125; @Override public void close() &#123; &#125; @Override public void configure(Map&lt;String, ?&gt; configs) &#123;&#125; 这里我们可以用redis记录消息消费的时间,到redis中我们就可以很好的进行统计了,可以很好的统计到从producer到consumer的时间了。 小结 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://lywlefan.github.io/tags/读书笔记/"},{"name":"kafka","slug":"kafka","permalink":"https://lywlefan.github.io/tags/kafka/"},{"name":"kafka核心技术与实战-胡夕","slug":"kafka核心技术与实战-胡夕","permalink":"https://lywlefan.github.io/tags/kafka核心技术与实战-胡夕/"}]},{"title":"11.无消息丢失配置怎么实现？","date":"2019-06-30T16:00:00.000Z","path":"2019/07/01/软件研发/后端/中间件/消息中间件/kafka/读书笔记/kafka核心技术与实战-胡夕/11.无消息丢失配置怎么实现？/","text":"阅读笔记 kafka中什么算消息丢失 什么情况下能保证kafka消息不丢失 一句话概括,Kafka只对”已提交”的消息做有限度的持久化保证。 什么是已提交的消息?当kafka的若干个Broker成功的接收到一条消息并写入到日志文件之后,它们就会告诉生产者程序这条消息已成功提交。此时,这条消息在kafka看来就正式变为”已提交”消息了。 为什么是若干个Broker?这取决于”已提交”的定义,你可以选择只有一个broker成功保存该消息就算已提交,也可以令所有broker都保存才算已提交. 有限度的持久化保证至少有一个Broker存活,只要这个条件成立,kafka就不会丢消息,但是一个都不会存活的情况是有可能出现的. 消息丢失的案例复盘”kafka消息丢失”案例。 生产者程序丢失数据kafka producer是异步发送消息的,所以说当我们调用完producer.send(msg)这个api后,他通过会立即返回,但是并不代表我们消息发送成功. 以上发送消息的方式是不靠谱的,建议不要这样去搞,因为这种方式以下原因可能造成消息发送失败: 网络抖动 消息本身不合格,Broker不接受 解决以上问题其实有比较好的办法,就是我们Producer永远使用带有回调通知的发送API,也就是说不要使用producer.send(msg),而要使用producer.send(msg,callback),callback会告诉你消息是否处理成功,然后你再根据具体情况进行相应的处理。 如果因为某些瞬间错误,可以让producer继续重试,总之发送消息失败的责任是producer而不是在broker,当然broker宕机断网除外。 消费者程序丢失数据在kafka消费消息的时候有个”位移”的概念,我们可以把消费消息当做我们读书,而”位移”就相当于”书签”。 什么情况下消费者程序会存在丢数据的情况哪??? 我们把上面的类比分成两个部分:1.读书 2.移动书签位置 加入我们先移动书签,再读书就有可能造成消费者丢数据的情况,比如:我们计划读书到100页,然后我们把书签放到100页,当我们读到96页的时候突然有急事出去了,下次继续读的时候就从100页开始了,中间的页我们就没读到。 针对以上情况,我们应该是先读书然后移动书签的位置。 但是先读书再移动书签会不会造成消息重复消费的情况。 还一种多线程消费的情况,以前我们是一个人读书,现在把一本书10章分给10个人一起读,然后大家读完宣布这本书读完。 以上这种情况有可能这种异常情况,有部分线程没有读完就更新了位移,这就导致部分消息没有消费,但是响应的确实已经消费了的情况。 解决以上问题的办法就是:多线程处理消费消息,Consumer程序不要开启自动提交位移,而是要应用程序手动提交位移。 最佳实践 使用掉回调的生产消息的方法 设置 acks = all。acks 是 Producer的一个参数，代表了你对“已提交”消息的定义。如果设置成 all，则表明所有副本 Broker都要接收到消息，该消息才算是“已提交”。这是最高等级的“已提交”定义。 设置 retries 为一个较大的值。这里的 retries 同样是 Producer 的参数，对应前面提到的 Producer 自动重试。当出现网络的瞬时抖动时，消息发送可能会失败，此时配置了 retries &gt; 0 的 Producer 能够自动重试消息发送，避免消息丢失。 设置 unclean.leader.election.enable = false。这是 Broker 端的参数，它控制的是哪些 Broker有资格竞选分区的 Leader。如果一个 Broker 落后原先的 Leader 太多，那么它一旦成为新的 Leader，必然会造成消息的丢失。故一般都要将该参数设置成 false，即不允许这种情况的发生。 设置 replication.factor &gt;= 3。这也是 Broker 端的参数。其实这里想表述的是，最好将消息多保存几份，毕竟目前防止消息丢失的主要机制就是冗余。 设置 min.insync.replicas &gt; 1。这依然是 Broker 端参数，控制的是消息至少要被写入到多少个副本才算是“已提交”。设置成大于 1 可以提升消息持久性。在实际环境中千万不要使用默认值 1。 确保 replication.factor&gt; min.insync.replicas。如果两者相等，那么只要有一个副本挂机，整个分区就无法正常工作了。我们不仅要改善消息的持久性，防止数据丢失，还要在不降低可用性的基础上完成。推荐设置成 replication.factor = min.insync.replicas + 1。 确保消息消费完成再提交。Consumer 端有个参数 enable.auto.commit，最好把它设置成 false ，并采用手动提交位移的方式。 就像前面说的，这对于单 Consumer 多线程处理的场景而言是至关重要的。 开发讨论特别隐秘丢消息的场景: 当增加主题分区后，在某段“不凑巧”的时间间隔后，Producer 先于 Consumer 感知到新增加的分区，而 Consumer 设置的是“从最新位移处”开始读取消息，因此在 Consumer 感知到新分区前，Producer 发送的这些消息就全部“丢失”了，或者说 Consumer 无法读取到这些消息。Kafka 设计上的一个小缺陷，你有什么解决的办法吗？ cricket1981：consumer改用”从最早位置”读解决新加分区造成的问题 明翼：这个问题我想个办法就是程序停止再增加分区，如果不能停止那就找个通知机制了。请教一个问题min.insync.replicas这个参数如果设置成3，假设副本数设置为4，那岂不是只支持一台broker坏掉的情况？ 作者：能想到的一个简单方法是让consumer端缓存订阅信息，如果发现新的订阅分区出现，手动调整位移到最开始处执行（比如consumer.seekToBeginning） 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://lywlefan.github.io/tags/读书笔记/"},{"name":"kafka","slug":"kafka","permalink":"https://lywlefan.github.io/tags/kafka/"},{"name":"kafka核心技术与实战-胡夕","slug":"kafka核心技术与实战-胡夕","permalink":"https://lywlefan.github.io/tags/kafka核心技术与实战-胡夕/"}]},{"title":"es的VERSION","date":"2019-06-27T16:00:00.000Z","path":"2019/06/28/软件研发/后端/搜索引擎/es/VERSION(ES)/","text":"问题整理 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 【3】redis官网 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"redis","slug":"redis","permalink":"https://lywlefan.github.io/tags/redis/"},{"name":"学习笔记","slug":"学习笔记","permalink":"https://lywlefan.github.io/tags/学习笔记/"}]},{"title":"redis的FAQ","date":"2019-06-27T16:00:00.000Z","path":"2019/06/28/软件研发/后端/数据存储/NOSQL/redis/FAQ/","text":"问题整理 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 【3】redis官网 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"redis","slug":"redis","permalink":"https://lywlefan.github.io/tags/redis/"},{"name":"数据存储","slug":"数据存储","permalink":"https://lywlefan.github.io/tags/数据存储/"},{"name":"NOSQL","slug":"NOSQL","permalink":"https://lywlefan.github.io/tags/NOSQL/"}]},{"title":"redis的VERSION","date":"2019-06-27T16:00:00.000Z","path":"2019/06/28/软件研发/后端/数据存储/NOSQL/redis/VERSION/","text":"问题整理 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 【3】redis官网 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"redis","slug":"redis","permalink":"https://lywlefan.github.io/tags/redis/"},{"name":"数据存储","slug":"数据存储","permalink":"https://lywlefan.github.io/tags/数据存储/"},{"name":"NOSQL","slug":"NOSQL","permalink":"https://lywlefan.github.io/tags/NOSQL/"}]},{"title":"09.生产者消息分区机制原理剖析","date":"2019-06-27T16:00:00.000Z","path":"2019/06/28/软件研发/后端/中间件/消息中间件/kafka/实践问题/kafka如何处理消息重复的问题/","text":"背景kafka没有重试机制不支持消息重试，也没有死信队列，因此使用kafka做消息队列时，如果遇到了消息在业务处理时出现异常，就会很难进行下一步处理。应对这种场景，需要自己实现消息重试的功能。 如果不想自己实现消息重试机制，建议使用RocketMQ作为消息队列，RocketMQ的消息重试机制相当完善，对于开发者使用也非常友好，详见https://help.aliyun.com/document_detail/43490.html。 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"kafka","slug":"kafka","permalink":"https://lywlefan.github.io/tags/kafka/"},{"name":"实践问题","slug":"实践问题","permalink":"https://lywlefan.github.io/tags/实践问题/"}]},{"title":"","date":"2019-06-27T16:00:00.000Z","path":"2019/06/28/软件研发/后端/中间件/消息中间件/kafka/读书笔记/kafka核心技术与实战-胡夕/09.生产者消息分区机制原理剖析/","text":"阅读笔记生产者消息分区机制原理剖析 如何将大的数据均匀的分配到Kafka的各个Broker上？ 为什么分区？ 为什么分区？ 三级结构：主题-分区-消息 主题下的每条消息只会保存在某一个分区中，而不会在多个分区中被保存多份 疑问:为什么kafka要这样设计？有什么好处？ 回答:我们设想一个问题，我们在学校找一个学生，如果我们直接把学生集中在一起去找是不是很麻烦，很低效。换种方式，每50个学生一组，配置一个负责人，然后通知这些负责人去找某个同学，是不是很快就可以找到了，这也就是分区的意义所在。如果，我们把这种思想放到我们的系统中，就可以提高我们系统的负载均衡能力，实现了系统的高伸缩性(Scalability) 不同的分区能够被放置到不同节点的机器上 疑问：同一个topic下不同的分区是保存到相同机器的不同磁盘上的吗？ 回答: 在 MongoDB 和 Elasticsearch 中就叫分Shard，而在HBase中则叫Region,在Cassandra中又被称作vnode。 实现业务级别的消息顺序的问题 都有哪些分区策略？所谓分区策略是决定生产者将消息发送到那个分区的算法。提供了默认的分区策略，同时支持自定义分区策略。 自定义分区 配置partitioner.class参数 实现Partitioner接口 1int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster); 这里的topic、key、keyBytes、value和valueBytes都属于消息数据，cluster则是集群信息(比如当前Kafka集群有多少主题，多少Broker等)。 策略 轮询策略(Round-robin) 轮询是kafka默认的消息存储策略，新增的消息会依次进入1/2/3/4/….对应的分区。轮询策略有非常优秀的负载均衡表现，它总能保证消息最大限度地平均分配到所有分区上，故默认情况下它是最合理的分区策略，也是我们常用的分区策略之一。 随机策略(Randomness) 12List&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(topic);return ThreadLocalRandom.current().nextInt(partitions.size()); 实现比较简单，先计算出该主题总的分区数，然后随机地返回一个小于它的正整数。 该策略是kafka老版本的策略，追求数据均匀分布还是轮询策略比较好。 按消息键保序策略 同一个消息key的消息进入同一个分区 一个分区只能被同一个消费组（ConsumerGroup）内的一个消费者消费 这里我们可以给我们的消息以时间的维度定义key，如此同一时间的消息就进入了同一个分区，同一个分区下的消息也有了顺序性。 每个分区消息都是有顺序的 代码实现 12List&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(topic);return Math.abs(key.hashCode()) % partitions.size(); 其他分区策略(比如：基于地理位置的分区策略) 场景 公司有两个机房，一个在广州，一个在北京，在每个机房里面抽取部分机器组成kafka集群。现在公司app搞活动，北京新注册的用户送北京烤鸭一只，广州注册的用户送一次大保健，我们如何用kafka实现这一需求？ 解决方案一 解决方案二 提出问题自己提问问题1 通过kafka创建一个topic，默认分几个区？ 回答：创建topic的时候就需要指定需要创建的分区个数. 问题2 基于地理位置的分区策略可以通过按消息键保序策略实现，这样做有什么意义？ 其他人的问题问题1 老师能不能有空能不能讲讲kafka和rocketMQ的对比, 我用下来感觉整体挺像的但是具体使用场景和性能优劣方面还是有点不知道该使用选择, 谢谢. 回答：在我看来RocketMQ与Kafka的主要区别 ：1. Kafka吞吐量大，多是面向大数据场景。RocketMQ吞吐量也很强， 不过它号称是金融业务级的消息中间件，也就是说可以用于实际的业务系统；2. RocketMQ毕竟是阿里出品，在国内技术支持力度要比Kafka强；3. Kafka现在主要发力Streaming，RocketMQ在流处理这块表现如何我不太清楚，至少streaming不是它现阶段的主要卖点。 问题2 kafka的主题只有一级、像mq可以进行主题分层：一级主题、二级主题。kafka为何这样设计？ 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://lywlefan.github.io/tags/读书笔记/"},{"name":"kafka","slug":"kafka","permalink":"https://lywlefan.github.io/tags/kafka/"},{"name":"kafka核心技术与实战-胡夕","slug":"kafka核心技术与实战-胡夕","permalink":"https://lywlefan.github.io/tags/kafka核心技术与实战-胡夕/"}]},{"title":"10.生产者压缩算法面面观","date":"2019-06-27T16:00:00.000Z","path":"2019/06/28/软件研发/后端/中间件/消息中间件/kafka/读书笔记/kafka核心技术与实战-胡夕/10.生产者压缩算法面面观/","text":"阅读笔记 消息压缩 GZIP Snappy Zero Copy(零拷贝技术) 何时压缩 笔记压缩算法笔记 GZIP Snappy LZ4 Zstandard(zstd):2.1.0开始，facebook开源的压缩算法，能够提高超高性能压缩比。 如何压缩 v1（kafka 0.11.0之前）:message set, message ,v2（kafka 0.11.0以后）:record batch,record 我看了三遍老师的课，得到了我要的答案：1.如果生产者使用了压缩，broker为了crc校验，会启动解压，这个解压过程不可避免；2.v2的broker为了低版本的消费者，会把消息再次解压并进行协议转换。 CRC校验（每条消息执行CRC校验） 消息集合 消息 日志项 看一个压缩算法的指标 压缩比 原来占100份空间的东西压缩成20，那么压缩比就是5，显然压缩比越高越好。 吞吐量(压缩/解压缩) 每秒能压缩或者解压多少MB数据,同样吞吐量也是越高越好。 facebook各个压缩算法性能测试 1.png 如何选择压缩算法 启用压缩的一个条件就是Producer程序运行机器上的CPU要充足。 带宽资源有限建议开启压缩(带宽比cpu和内存还要珍贵) cpu资源富于，建议开启zstd压缩，这样能极大节省网络资源消耗。 规避意料之外的解压缩，比如：兼容老版本而引入解压缩 有条件尽量保证不要出现消息格式转换的情况 浓缩精华 Producer端压缩/Broker端保持/Consumer端解压 注意问题producer和broker端的压缩算法尽量保持一致建议京东小哥建议 去掉因为做消息校验而引入解压缩,据他们称，去掉解压缩后，Broker端CPU使用率至少降低了50%。 社区未采纳建议，原因是消息校验特别重要，不能盲目去掉。 应用实践实时日志收集系统 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://lywlefan.github.io/tags/读书笔记/"},{"name":"kafka","slug":"kafka","permalink":"https://lywlefan.github.io/tags/kafka/"},{"name":"kafka核心技术与实战-胡夕","slug":"kafka核心技术与实战-胡夕","permalink":"https://lywlefan.github.io/tags/kafka核心技术与实战-胡夕/"}]},{"title":"关于支付宝用户信息获取的总结","date":"2019-06-26T16:00:00.000Z","path":"2019/06/27/软件研发/后端/第三方对接/支付宝/关于支付宝用户信息获取的总结/","text":"需求需求分析随着互联网的快速发展,巨头互联网公司占据了互联网的半壁江山,几乎大一点的互联网巨头公司都要搞个小程序或者生活号,方便其他公司的接入自己的生态。 随着互联网的快速发展,巨头互联网公司占据了互联网的半壁江山,几乎大一点的互联网巨头公司都要搞个小程序或者生活号,方便其他公司的接入自己的生态。 我最近这段时间就在对接支付宝的相关生态,给我最大的感触就是支付宝的对接确实要比微信麻烦,文档太难找了,一会跳着,一会跳哪,搞的我是好不难受。 接下来我会接受如何对接支付宝的生活号获取用户的信息。 后端存储支付宝用户信息(用户授权后在回调的时候存储) 前端在本地存储一个用户唯一标识,通过唯一标识进行后续业务 流程梳理获取用户信息后端交互 image 在生活号菜单上配置跳转地址为:https://openauth.alipay.com/oauth2/publicAppAuthorize.htm?app_id=APPID&amp;scope=SCOPE&amp;redirect_uri=ENCODED_URL ,其中redirect_uri为后台的回调地址,我们可以在该回调地址上传自定义的参数,要注意的是需要对redirect_url进行转码,转码后进行拼接。 当用户点击后,会去请求支付宝的认证服务,支付宝返回一个授权页面,用户确认后,该页面带着auth_code去回调后台地址。 后台接受到请求后,通过auth_code调用支付宝相关API获取token,然后再通过token获取用户信息。代码如下: controller123456789101112131415161718@RequestMapping(value = \"aliAuth\", method = RequestMethod.GET)@ResponseBodypublic void aliAuth( @RequestParam(value = \"auth_code\",required = false) String authCode, @RequestParam(value =\"app_id\",required = false) String appId, @RequestParam(value =\"scope\",required = false) String scope, @RequestParam(value =\"authUrl\",required = false) String authUrl, HttpServletResponse response) throws AlipayApiException, IOException &#123; //1.通过auth_code换token String accessToken = authLifeService.getToken(authCode); //2.获取用户基本信息 AlipayUserInfoShareResponse userInfo = authLifeService.getUserInfo(accessToken); //3.获取用户信息成功,跳转到第三方首页 log.info(JSON.toJSONString(userInfo)); //TODO:这里可以保存用户信息,生成自己平台的用户唯一标识,可以把参数拼接到页面跳转到指定的页面 response.sendRedirect(\"http://www.baidu.com\");&#125; service123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class AuthLifeService &#123; AlipayClient alipayClient; /** * 获取token * @param authCode code * @return 返回token */ public String getToken(String authCode) throws AlipayApiException &#123; String accessToken = null; try &#123; AlipaySystemOauthTokenRequest request = new AlipaySystemOauthTokenRequest(); request.setGrantType(\"authorization_code\"); request.setCode(authCode); request.setRefreshToken(\"201208134b203fe6c11548bcabd8da5bb087a83b\"); AlipaySystemOauthTokenResponse response = alipayClient.execute(request); accessToken = response.getAccessToken(); String userId = response.getUserId(); &#125; catch (AlipayApiException e) &#123; e.printStackTrace(); &#125; return accessToken; &#125; /** * 获取用户信息 * @param accessToken 用户token * @return 用户信息 */ public AlipayUserInfoShareResponse getUserInfo(String accessToken)&#123; UserInfo userInfo = null; AlipayUserInfoShareResponse userInfoShareResponse = null; try &#123; AlipayUserInfoShareRequest requestUser = new AlipayUserInfoShareRequest(); userInfoShareResponse = alipayClient.execute(requestUser, accessToken); if(userInfoShareResponse.isSuccess())&#123; userInfo = JSON.parseObject(JSON.toJSONString(userInfoShareResponse), UserInfo.class); &#125; else &#123; System.out.println(\"调用失败\"); &#125; &#125; catch (AlipayApiException e) &#123; e.printStackTrace(); &#125; return userInfoShareResponse; &#125; 配置文件12345678910111213141516171819202122@Configuration@ConfigurationProperties(prefix = \"ali\")@PropertySource(\"classpath:config/ali.properties\")@Data@Componentpublic class AliProperties &#123; private String publicKey; //支付宝公钥 private String appId; //appId private String format; //数据格式 private String charset; //字符编码 private String signType; //签名方式 private String privateKey; //商户私钥 private String url; //url&#125; 经过如上操作,我们顺利的获取到了用户的基本信息,但是这样每次都的依赖支付宝,每次都得回调。 如何让获取用户信息不依赖支付宝?如何让下面的业务根据后台的用户标识走? 前后端交互(缓存用户唯一标识到本地) 这个验证页面其实相当于一个路由页面,作用如下: 缓存用户唯一标识:openCode 路由转发,可以配置多个不同菜单 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"第三方对接","slug":"第三方对接","permalink":"https://lywlefan.github.io/tags/第三方对接/"},{"name":"支付宝","slug":"支付宝","permalink":"https://lywlefan.github.io/tags/支付宝/"}]},{"title":"Java并发编程：CountDownLatch、CyclicBarrier和Semaphore","date":"2019-06-26T16:00:00.000Z","path":"2019/06/27/软件研发/后端/高并发/java/并发基础/Java并发编程：CountDownLatch、CyclicBarrier和Semaphore/","text":"面向对象的语言最好的学习方法就是在实际生活中找一个列子类比。 CountDownLatch(计数器) CyclicBarrier(回环栅栏) Semaphore(信号量) CountDownLatchCountDownLatch类位于java.util.concurrent包下，利用它可以实现类似计数器的功能。比如有一个任务A，它要等待其他4个任务执行完毕之后才能执行，此时就可以利用CountDownLatch来实现这种功能了。 基础构造方法123456//count代表计数的个数public CountDownLatch(int count) &#123; if (count &lt; 0) throw new IllegalArgumentException(\"count &lt; 0\"); this.sync = new Sync(count);&#125; 方法123456//调用await()方法的线程会被挂起，它会等待直到count值为0才继续执行public void await() throws InterruptedException &#123; &#125;; //和await()类似，只不过等待一定的时间后count值还没变为0的话就会继续执行public boolean await(long timeout, TimeUnit unit) throws InterruptedException &#123; &#125;; //将count值减1public void countDown() &#123; &#125;; 类比理解大家在考科目一的时候是如何考的？我们知道车管所的考试机器比考试人数要少很多，假如机器有50个，每次考官让50个人进去，然后再宣布考试开始，其他人继续等待。 CountDownLatch就可以实现这个效果，我们可以这样做： CountDownLatch latch=new CountDownLatch(50) 进入考场一个学员，我们就latch.countDown()减一 到latch为0的时候，考官宣布考试开始，如此而已 12345678910111213141516171819202122232425262728293031323334353637383940public class Test &#123; public static void main(String[] args) &#123; final CountDownLatch latch = new CountDownLatch(2); new Thread()&#123; public void run() &#123; try &#123; System.out.println(\"子线程\"+Thread.currentThread().getName()+\"正在执行\"); Thread.sleep(3000); System.out.println(\"子线程\"+Thread.currentThread().getName()+\"执行完毕\"); latch.countDown(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;; &#125;.start(); new Thread()&#123; public void run() &#123; try &#123; System.out.println(\"子线程\"+Thread.currentThread().getName()+\"正在执行\"); Thread.sleep(3000); System.out.println(\"子线程\"+Thread.currentThread().getName()+\"执行完毕\"); latch.countDown(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;; &#125;.start(); try &#123; System.out.println(\"等待2个子线程执行完毕...\"); latch.await(); System.out.println(\"2个子线程已经执行完毕\"); System.out.println(\"继续执行主线程\"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 执行结果： 1234567线程Thread-0正在执行线程Thread-1正在执行等待2个子线程执行完毕...线程Thread-0执行完毕线程Thread-1执行完毕2个子线程已经执行完毕继续执行主线程 CyclicBarrier基础字面意思回环栅栏，通过它可以实现让一组线程等待至某个状态之后再全部同时执行。叫做回环是因为当所有等待线程都被释放以后，CyclicBarrier可以被重用。我们暂且把这个状态就叫做barrier，当调用await()方法之后，线程就处于barrier了。 CyclicBarrier类位于java.util.concurrent包下，CyclicBarrier提供2个构造器： 构造方法12345public CyclicBarrier(int parties, Runnable barrierAction) &#123;&#125; public CyclicBarrier(int parties) &#123;&#125; 参数parties指让多少个线程或者任务等待至barrier状态；参数barrierAction为当这些线程都达到barrier状态时会执行的内容。 方法然后CyclicBarrier中最重要的方法就是await方法，它有2个重载版本： 12public int await() throws InterruptedException, BrokenBarrierException &#123; &#125;;public int await(long timeout, TimeUnit unit)throws InterruptedException,BrokenBarrierException,TimeoutException &#123; &#125;; 第一个版本比较常用，用来挂起当前线程，直至所有线程都到达barrier状态再同时执行后续任务； 第二个版本是让这些线程等待至一定的时间，如果还有线程没有到达barrier状态就直接让到达barrier的线程执行后续任务。 类比理解例1假若有若干个线程都要进行写数据操作，并且只有所有线程都完成写数据操作之后，这些线程才能继续做后面的事情，此时就可以利用CyclicBarrier了： 1234567891011121314151617181920212223242526272829public class Test &#123; public static void main(String[] args) &#123; int N = 4; CyclicBarrier barrier = new CyclicBarrier(N); for(int i=0;i&lt;N;i++) new Writer(barrier).start(); &#125; static class Writer extends Thread&#123; private CyclicBarrier cyclicBarrier; public Writer(CyclicBarrier cyclicBarrier) &#123; this.cyclicBarrier = cyclicBarrier; &#125; @Override public void run() &#123; System.out.println(\"线程\"+Thread.currentThread().getName()+\"正在写入数据...\"); try &#123; Thread.sleep(5000); //以睡眠来模拟写入数据操作 System.out.println(\"线程\"+Thread.currentThread().getName()+\"写入数据完毕，等待其他线程写入完毕\"); cyclicBarrier.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;catch(BrokenBarrierException e)&#123; e.printStackTrace(); &#125; System.out.println(\"所有线程写入完毕，继续处理其他任务...\"); &#125; &#125;&#125; 执行结果： 123456789101112线程Thread-0正在写入数据...线程Thread-3正在写入数据...线程Thread-2正在写入数据...线程Thread-1正在写入数据...线程Thread-2写入数据完毕，等待其他线程写入完毕线程Thread-0写入数据完毕，等待其他线程写入完毕线程Thread-3写入数据完毕，等待其他线程写入完毕线程Thread-1写入数据完毕，等待其他线程写入完毕所有线程写入完毕，继续处理其他任务...所有线程写入完毕，继续处理其他任务...所有线程写入完毕，继续处理其他任务...所有线程写入完毕，继续处理其他任务... 从上面输出结果可以看出，每个写入线程执行完写数据操作之后，就在等待其他线程写入操作完毕。 当所有线程线程写入操作完毕之后，所有线程就继续进行后续的操作了。 例2如果说想在所有线程写入操作完之后，进行额外的其他操作可以为CyclicBarrier提供Runnable参数： 1234567891011121314151617181920212223242526272829303132333435public class Test &#123; public static void main(String[] args) &#123; int N = 4; CyclicBarrier barrier = new CyclicBarrier(N,new Runnable() &#123; @Override public void run() &#123; System.out.println(\"当前线程\"+Thread.currentThread().getName()); &#125; &#125;); for(int i=0;i&lt;N;i++) new Writer(barrier).start(); &#125; static class Writer extends Thread&#123; private CyclicBarrier cyclicBarrier; public Writer(CyclicBarrier cyclicBarrier) &#123; this.cyclicBarrier = cyclicBarrier; &#125; @Override public void run() &#123; System.out.println(\"线程\"+Thread.currentThread().getName()+\"正在写入数据...\"); try &#123; Thread.sleep(5000); //以睡眠来模拟写入数据操作 System.out.println(\"线程\"+Thread.currentThread().getName()+\"写入数据完毕，等待其他线程写入完毕\"); cyclicBarrier.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;catch(BrokenBarrierException e)&#123; e.printStackTrace(); &#125; System.out.println(\"所有线程写入完毕，继续处理其他任务...\"); &#125; &#125;&#125; 运行结果: 1234567891011121314线程Thread-0正在写入数据...线程Thread-1正在写入数据...线程Thread-2正在写入数据...线程Thread-3正在写入数据...线程Thread-0写入数据完毕，等待其他线程写入完毕线程Thread-1写入数据完毕，等待其他线程写入完毕线程Thread-2写入数据完毕，等待其他线程写入完毕线程Thread-3写入数据完毕，等待其他线程写入完毕当前线程Thread-3所有线程写入完毕，继续处理其他任务...所有线程写入完毕，继续处理其他任务...所有线程写入完毕，继续处理其他任务...所有线程写入完毕，继续处理其他任务... 从结果可以看出，当四个线程都到达barrier状态后，会从四个线程中选择一个线程去执行Runnable。 例3下面看一下为await指定时间的效果： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class Test &#123; public static void main(String[] args) &#123; int N = 4; CyclicBarrier barrier = new CyclicBarrier(N); for(int i=0;i&lt;N;i++) &#123; if(i&lt;N-1) new Writer(barrier).start(); else &#123; try &#123; Thread.sleep(5000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; new Writer(barrier).start(); &#125; &#125; &#125; static class Writer extends Thread&#123; private CyclicBarrier cyclicBarrier; public Writer(CyclicBarrier cyclicBarrier) &#123; this.cyclicBarrier = cyclicBarrier; &#125; @Override public void run() &#123; System.out.println(\"线程\"+Thread.currentThread().getName()+\"正在写入数据...\"); try &#123; Thread.sleep(5000); //以睡眠来模拟写入数据操作 System.out.println(\"线程\"+Thread.currentThread().getName()+\"写入数据完毕，等待其他线程写入完毕\"); try &#123; cyclicBarrier.await(2000, TimeUnit.MILLISECONDS); &#125; catch (TimeoutException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;catch(BrokenBarrierException e)&#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName()+\"所有线程写入完毕，继续处理其他任务...\"); &#125; &#125;&#125; 执行结果： 12345678910111213141516171819202122232425262728线程Thread-0正在写入数据...线程Thread-2正在写入数据...线程Thread-1正在写入数据...线程Thread-2写入数据完毕，等待其他线程写入完毕线程Thread-0写入数据完毕，等待其他线程写入完毕线程Thread-1写入数据完毕，等待其他线程写入完毕线程Thread-3正在写入数据...java.util.concurrent.TimeoutExceptionThread-1所有线程写入完毕，继续处理其他任务...Thread-0所有线程写入完毕，继续处理其他任务... at java.util.concurrent.CyclicBarrier.dowait(Unknown Source) at java.util.concurrent.CyclicBarrier.await(Unknown Source) at com.cxh.test1.Test$Writer.run(Test.java:58)java.util.concurrent.BrokenBarrierException at java.util.concurrent.CyclicBarrier.dowait(Unknown Source) at java.util.concurrent.CyclicBarrier.await(Unknown Source) at com.cxh.test1.Test$Writer.run(Test.java:58)java.util.concurrent.BrokenBarrierException at java.util.concurrent.CyclicBarrier.dowait(Unknown Source) at java.util.concurrent.CyclicBarrier.await(Unknown Source) at com.cxh.test1.Test$Writer.run(Test.java:58)Thread-2所有线程写入完毕，继续处理其他任务...java.util.concurrent.BrokenBarrierException线程Thread-3写入数据完毕，等待其他线程写入完毕 at java.util.concurrent.CyclicBarrier.dowait(Unknown Source) at java.util.concurrent.CyclicBarrier.await(Unknown Source) at com.cxh.test1.Test$Writer.run(Test.java:58)Thread-3所有线程写入完毕，继续处理其他任务... 上面的代码在main方法的for循环中，故意让最后一个线程启动延迟，因为在前面三个线程都达到barrier之后，等待了指定的时间发现第四个线程还没有达到barrier，就抛出异常并继续执行后面的任务。 例5另外CyclicBarrier是可以重用的，看下面这个例子： 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class Test &#123; public static void main(String[] args) &#123; int N = 4; CyclicBarrier barrier = new CyclicBarrier(N); for(int i=0;i&lt;N;i++) &#123; new Writer(barrier).start(); &#125; try &#123; Thread.sleep(25000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(\"CyclicBarrier重用\"); for(int i=0;i&lt;N;i++) &#123; new Writer(barrier).start(); &#125; &#125; static class Writer extends Thread&#123; private CyclicBarrier cyclicBarrier; public Writer(CyclicBarrier cyclicBarrier) &#123; this.cyclicBarrier = cyclicBarrier; &#125; @Override public void run() &#123; System.out.println(\"线程\"+Thread.currentThread().getName()+\"正在写入数据...\"); try &#123; Thread.sleep(5000); //以睡眠来模拟写入数据操作 System.out.println(\"线程\"+Thread.currentThread().getName()+\"写入数据完毕，等待其他线程写入完毕\"); cyclicBarrier.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;catch(BrokenBarrierException e)&#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName()+\"所有线程写入完毕，继续处理其他任务...\"); &#125; &#125;&#125; 执行结果： 12345678910111213141516171819202122232425线程Thread-0正在写入数据...线程Thread-1正在写入数据...线程Thread-3正在写入数据...线程Thread-2正在写入数据...线程Thread-1写入数据完毕，等待其他线程写入完毕线程Thread-3写入数据完毕，等待其他线程写入完毕线程Thread-2写入数据完毕，等待其他线程写入完毕线程Thread-0写入数据完毕，等待其他线程写入完毕Thread-0所有线程写入完毕，继续处理其他任务...Thread-3所有线程写入完毕，继续处理其他任务...Thread-1所有线程写入完毕，继续处理其他任务...Thread-2所有线程写入完毕，继续处理其他任务...CyclicBarrier重用线程Thread-4正在写入数据...线程Thread-5正在写入数据...线程Thread-6正在写入数据...线程Thread-7正在写入数据...线程Thread-7写入数据完毕，等待其他线程写入完毕线程Thread-5写入数据完毕，等待其他线程写入完毕线程Thread-6写入数据完毕，等待其他线程写入完毕线程Thread-4写入数据完毕，等待其他线程写入完毕Thread-4所有线程写入完毕，继续处理其他任务...Thread-5所有线程写入完毕，继续处理其他任务...Thread-6所有线程写入完毕，继续处理其他任务...Thread-7所有线程写入完毕，继续处理其他任务... 从执行结果可以看出，在初次的4个线程越过barrier状态后，又可以用来进行新一轮的使用。而CountDownLatch无法进行重复使用。 SemaphoreSemaphore翻译成字面意思为 信号量，Semaphore可以控同时访问的线程个数，通过 acquire() 获取一个许可，如果没有就等待，而 release() 释放一个许可。 基础Semaphore类位于java.util.concurrent包下，它提供了2个构造器： 构造方法123456public Semaphore(int permits) &#123; //参数permits表示许可数目，即同时可以允许多少线程进行访问 sync = new NonfairSync(permits);&#125;public Semaphore(int permits, boolean fair) &#123; //这个多了一个参数fair表示是否是公平的，即等待时间越久的越先获取许可 sync = (fair)? new FairSync(permits) : new NonfairSync(permits);&#125; 方法下面说一下Semaphore类中比较重要的几个方法，首先是acquire()、release()方法： 1234public void acquire() throws InterruptedException &#123; &#125; //获取一个许可public void acquire(int permits) throws InterruptedException &#123; &#125; //获取permits个许可public void release() &#123; &#125; //释放一个许可public void release(int permits) &#123; &#125; //释放permits个许可 acquire()用来获取一个许可，若无许可能够获得，则会一直等待，直到获得许可。 release()用来释放许可。注意，在释放许可之前，必须先获获得许可。 这4个方法都会被阻塞，如果想立即得到执行结果，可以使用下面几个方法： 1234public boolean tryAcquire() &#123; &#125;; //尝试获取一个许可，若获取成功，则立即返回true，若获取失败，则立即返回falsepublic boolean tryAcquire(long timeout, TimeUnit unit) throws InterruptedException &#123; &#125;; //尝试获取一个许可，若在指定的时间内获取成功，则立即返回true，否则则立即返回falsepublic boolean tryAcquire(int permits) &#123; &#125;; //尝试获取permits个许可，若获取成功，则立即返回true，若获取失败，则立即返回falsepublic boolean tryAcquire(int permits, long timeout, TimeUnit unit) throws InterruptedException &#123; &#125;; //尝试获取permits个许可，若在指定的时间内获取成功，则立即返回true，否则则立即返回false 另外还可以通过availablePermits()方法得到可用的许可数目。 类比理解下面通过一个例子来看一下Semaphore的具体使用： 假若一个工厂有5台机器，但是有8个工人，一台机器同时只能被一个工人使用，只有使用完了，其他工人才能继续使用。那么我们就可以通过Semaphore来实现： 123456789101112131415161718192021222324252627282930public class Test &#123; public static void main(String[] args) &#123; int N = 8; //工人数 Semaphore semaphore = new Semaphore(5); //机器数目 for(int i=0;i&lt;N;i++) new Worker(i,semaphore).start(); &#125; static class Worker extends Thread&#123; private int num; private Semaphore semaphore; public Worker(int num,Semaphore semaphore)&#123; this.num = num; this.semaphore = semaphore; &#125; @Override public void run() &#123; try &#123; semaphore.acquire(); System.out.println(\"工人\"+this.num+\"占用一个机器在生产...\"); Thread.sleep(2000); System.out.println(\"工人\"+this.num+\"释放出机器\"); semaphore.release(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 执行结果： 12345678910111213141516工人0占用一个机器在生产...工人1占用一个机器在生产...工人2占用一个机器在生产...工人4占用一个机器在生产...工人5占用一个机器在生产...工人0释放出机器工人2释放出机器工人3占用一个机器在生产...工人7占用一个机器在生产...工人4释放出机器工人5释放出机器工人1释放出机器工人6占用一个机器在生产...工人3释放出机器工人7释放出机器工人6释放出机器 FAQ总结下面对上面说的三个辅助类进行一个总结： 1）CountDownLatch和CyclicBarrier都能够实现线程之间的等待，只不过它们侧重点不同： CountDownLatch一般用于某个线程A等待若干个其他线程执行完任务之后，它才执行； 而CyclicBarrier一般用于一组线程互相等待至某个状态，然后这一组线程再同时执行； 另外，CountDownLatch是不能够重用的，而CyclicBarrier是可以重用的。 2）Semaphore其实和锁有点类似，它一般用于控制对某组资源的访问权限。 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 【3】disruptor官网 【4】JAVA CAS原理深度分析 【5】并发框架Disruptor译文 【6】从构建分布式秒杀系统聊聊Disruptor高性能队列 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"},{"name":"高并发","slug":"高并发","permalink":"https://lywlefan.github.io/tags/高并发/"},{"name":"并发基础","slug":"并发基础","permalink":"https://lywlefan.github.io/tags/并发基础/"}]},{"title":"架构导航","date":"2019-06-25T16:00:00.000Z","path":"2019/06/26/软件研发/架构/架构导航/","text":"万丈高楼平地起的前提是地基好. 技术选型网关 Nginx Kong Zuul GateWay 缓存 Redis MemCached OsCache EhCache 搜索 ElasticSearch Solr 熔断 Hystrix resilience4j 负载均衡 DNS F5 LVS Nginx OpenResty HAproxy 注册中心 Eureka Zookeeper Redis Etcd Consul 认证鉴权 JWT 消费队列 RabbitMQ ZeroMQ Redis ActiveMQ Kafka 系统监控 Grafana Prometheus Influxdb Telegraf Lepus Istio 文件系统 OSS NFS FastDFS MogileFS RPC框架 Dubbo Motan Thrift grpc 构建工具 Maven Gradle 集成部署 Docker Jenkins Git Maven 分布式配置 Disconf Apollo Spring Cloud Config Diamond Diamond是淘宝研发的分布式配置管理系统。使用Diamond可以让集群中的服务进程动态感知数据的变化，无需重启服务就可以实现配置数据的更新。 具有简单、可靠、易用等特点 压测 LoadRunner JMeter AB webbench ab.exe 数据库 MySql Redis MongoDB PostgreSQL Memcache HBase MPP数据库(Greenplum、TiDB、Postgresql XC、HAWQ等) 网络 专用网络VPC 弹性公网IP CDN CDN就可以理解为分布在每个县城的火车票代售点，用户在浏览网站的时候，CDN会选择一个离用户最近的CDN边缘节点来响应用户的请求，这样海南移动用户的请求就不会千里迢迢跑到北京电信机房的服务器（假设源站部署在北京电信机房）上了。 数据库中间件 DRDS Mycat 360 Atlas Cobar (不维护了) 分布式框架 Dubbo Motan Spring-Could 分布式任务 XXL JOB Elastic-Job Saturn Quartz 分布式追踪 Pinpoint CAT zipkin 分布式日志 elasticsearch logstash Kibana redis kafka 版本发布 蓝绿部署 A/B测试 灰度发布／金丝雀发布 持续交付 链路监控 监控架构四层监控 前端监控：IP、PV、运营商、系统、性能、状态码 业务监控：登录、注册、下单、支付 应用层监控：service、sql、cache、相应时间 系统监控：物理机、虚拟机、容器，CPU、内存、IO、硬盘 基础监控：网络、交换机、路由器 监控分类 日志监控 调用链监控 告警系统 Metrics监控 监控检查 Docker、Grafana、Prometheus、Telegraf、Influxdb、Lepus、Elasticsearch、Logstash、Kibana、kafka、node插件、dashboards仪表盘、钉钉、邮件、微信。 服务框架和治理 架构必备 负载均衡（负载均衡算法） 反向代理 服务隔离 服务限流 sentinel 1.限流文章 服务降级（自动优雅降级） 失效转移 超时重试（代理超时、容器超时、前端超时、中间件超时、数据库超时、NoSql超时） 回滚机制（上线回滚、数据库版本回滚、事务回滚） 高并发 应用缓存 HTTP缓存 多级缓存 分布式缓存 连接池 异步并发 分布式事务 二阶段提交(强一致) 三阶段提交(强一致) 消息中间件(最终一致性)，推荐阿里的RocketMQ 队列 任务队列 消息队列 请求队列 扩容 单体垂直扩容 单体水平扩容 应用拆分 数据库拆分 数据库分库分表 sharding-jdbc(当当/京东) mycat(民间组织) TDDL(CLIENT模式)，DRDS和cobar(PROXY模式)(阿里) Atlas(360) zebra(美团) 数据异构 数据同步 canal(binlog日志同步) 分布式任务 网络安全 SQL注入 XSS攻击 CSRF攻击 拒绝服务（DoS，Denial of Service）攻击 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 【3】LMAX架构简介·汤雪华 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"架构导航","slug":"架构导航","permalink":"https://lywlefan.github.io/tags/架构导航/"}]},{"title":"撮合系统设计","date":"2019-06-25T16:00:00.000Z","path":"2019/06/26/软件研发/业务/交易所/撮合系统设计/","text":"摘要：撮合技术主要是从数据库撮合技术向内存撮合技术发展，这是因为数据库撮合技术越来越无法满足金融交易对于高可靠性、高性能、强安全性、可扩展性以及易维护性的需求。本文来自中生代技术群的34期分享，将和大家讨论基于内存的撮合的系统设计。李伟山，毕业于国防科技大学，曾就职于华为、阿里巴巴，目前人江苏大圆银泰技术总监，对于高并发、大数据架构设计有深刻的了解。1.概述 随着信息技术的日新月异和金融业务的快速发展,金融交易领域对于核心技术的求也在不断增强,国内外金融交易模式已经从传统的人工叫价的方式变成了由高度电子化交易系统撮合订单的方式。传统的金融交易主要发生在有型金融市场中,金融交易的买卖双方通过叫价进行价格协商等方式最终达成一致,从而形成一笔交易,同时按照交易订单到指定的交割地点进行实物交割的交易方式。由于交易的整个过程主要依靠人来执行,传统的金融交易缺点主要有:效率低速度慢、交易时间限制大、交易空间限制大、交易成本非常髙、容易有内幕交易、交易扩展性差、交易容易出错、资金安全性差等一系列的缺点。 时代不断变迁,金融交易通过与计算机技术的结合,走上了电子化交易的道路,通过将金融交易市场电子化,电子交易不仅消除了传统金融交易的种种弊端,也促进了现代金融业的快速发展。电子金融交易的主要优点有:交易效率高速度快、交易透明度高、交易成本低、系统安全性高、不受交易时间的限制、不受交易空间的限制、可以进行多方位的扩展、大力推动现代金融业发展等。 因此现在电子交易己经成为了金融交易市场的主流交易方式。随着交易人数、笔数的不断增加,系统承受着越来越大的压力,如果在交易时间内系统发生故障,造成的损失往往不可估量。因此发出更可靠更高效的电子交易系统己经成为了金融交易领域的当务之急。 撮合交易在金融交易系统中扮演者非常重要的角色。了解撮合交易的本质以及业务对于设计撮合系统至关重要。江苏大泰技术有限公司，致力于互联网金融平台的开发，目前已经在运行的平台有大宗交易、普洱茶交易系统，后期会发布连续现货和发售交易平台，接下来为大家介绍基于内存的撮合交易系统设计概要。 2.系统总体设计2.1 层次设计一般而言,金融交易撮合系统中包括以下几个核心模块: 用户:终端用户委托报价与数量,生成订单发送至交易平台。 网关:负责收集用户订单,并将其派发给撮合引擎。 撮合引擎:交易系统中的核心部分,用于接收订单并根据业务逻辑实现订单 撮合同时生成交易记录,随后给予用户交易结果反馈。 数据库:用来存放交易过程中的订单和交易记录,实现数据持久化。 此外,本文根据不同类型的金融交易展品将撮合模块划分为若干业务分区,每个分区独立进行撮合,彼此不受影响。对于单个业务分区而言,撮合系统整体架构设计如图1.2所示,本章的总体设计围绕撮合引擎层以及撮合引擎与网关层、数据库层的交互方式的总体设计。 2.2 撮合交易算法如图2.1所示,撮合引擎的核心业务模块就是撮合交易算法撮合交易算法的任务一方面是完成对客户所下订单进行公平合理的排列和撮合功能,也要保证撮合算法的公平性、高效性以及扩展性等。由于不同金融交易系统的撮合业务各有不同,因此本节对通用的撮合交易算法进行概括性描述。 2.2.1订单队列撮合交易的重要组成部分就是买卖订单,通过对买卖订单进行撮合最后形成交易记录。所以对无法立刻完成撮合的订单,需要有买入队列和卖出队列保存订单。队列按照“价格优先、同价格下时间优先”的原则。买入队列按照委托价格从低到高的顺序,卖出队列则按照委托价格从低到高的顺序排列,如图 2.2.2撮合顺序撮合引擎接收到新的买入订单,则会到卖出队列的头部查找是否存在符合价格规则的卖出订单,如果存在卖出价格小于或等于买入价格的订单,则从队列中取出此订单并撮合成一笔交易;如果卖出队列为空或队列头部不满足价格关系,则将买入订单插入买入队列中,由于买入队列是按照价格与时间先后进行排序,所以新插入的订单会经过一次排序插入到买入队列的相应位置。 相同的,当撮合引擎接收到新的卖出订单,则会到买入队列的头部査找是否存在符合价格规则的买入订单,如果存在买入价格大于或等于卖出价格的订单,则从订单队列中取出此订单并撮合成一笔交易;如果买入队列为空或队列头部不满足价格关系,则将卖出订单插入到卖出队列中,由于卖出队列也是按照价格与时间先后进行排序的所以新插入的订单会经过一次排序插入到卖出队列的相应位置[23]。 结合买卖订单情况,撮合算法流程如图2.3所示。从图2.3所示的撮合顺序可知,买卖队列的有序性是保证撮合顺序的确定性的基础,并且撮合过程中每笔订单都可以撮合出当前最优交易。 2.3 内存撮合当前的数据库撮合技术的性能低下的原因在于过多与数据库交互,使得I/O很多,系统整体处理速度同时受数据库事务逻辑约束。 本文釆用内存撮合技术,通过最大程度去除与数据库的交互过程,将整个错和逻辑放在内存中进行(如图2.4所示)。因此比数据库撮合技术少了许多I/O交S间,在性能上可以大幅提升撮合速度;例是内存撮合的弊端就是由于内存的易失性,.?服务器出现故障停机时,所有的交易数据将会丢失,系统的可靠性以及一致性都相应人幅降低。因此本文在提高内存撮合技术可靠性的方面采用丫多机热备份及分布式一致性技术作为补充,从而获得内存撮合技术的高性能以及数据库撮合技术的数据持久性。 2.4 多机热备份由于内存撮合技术在撮合引攀出现异常时的可靠性和一致性非常差,而金融交场系统因为其业务特性,对服务小断以及数据丢失的容忍度非常低,提高容错性,一般多采取的是多机热条份技术。本文采用多机热备份技术,将一组撮合引樂部署成互为备份的撮合引擎集群,并且在同一时间内只有一台撮合引擎提供服务。当-其中运行这的一台撮六引擎出现故障无法继续正常工作 ,撮合引擎集群会迅速检测到这个故障,并选举出一个备份撮合引擎接管故障撮合引舉的任务从而保证整个撮合系统的正常运行多机热备份技术的本质就足针对服务器临时故障所做的一种备份技术,本文迎过采用多机热备份技术,来避免长 间的撮合服务中断,保证撮合系统长期、可靠的服务。如阁2.5所示,通过将多台撮合引擎进行热格份,从而保证在撮合引擎出现故障时,会在可以接受的时间内完成主机和备机之间的切换,由备份机提供无缝连续服务。 通过釆用多机热备份技术,降低了单一内存撮合引擎故障时系统不可用的问题,但仍旧无法提供100%的可用性,因为当出现大规模服务器集群故障时,仍旧存在服务不可用的可能性,但在实际生产环境中,三台互为备份的服务器就可以提供较高的可以用于生产环境的可靠性。 2.5 内存状态机复制由于多机热备份技术引入了多台互为热备份的撮合引擎,根据撮合系统设计以及撮合逻辑要求,需要保证服务器之间的数据一致,这就需要保证多服务器之间一致性,这也是本文难点之一。 本文提出一种内存状态机复制方案,即将撮合算法视作一个确定性状态机,将其复制多份并部署到撮合系统中的多台撮合引擎中。每个撮合引擎副本从相同的初始状态开始运行,当撮合系统收到网关发来的订单时,系统中的每个撮合引擎都会撮合这个订单,并依次产生交易记录,同时更新确定性撮合算法状态机的独立状态。通过这样的方式,当撮合系统正常运转时,每个撮合引擎副本都会具有相同的结果状态;当撮合系统出现故障或异常时,撮合引擎就会出现状态的不一致情况,换句话说一旦撮合系统的结果或状态出现了不一致的情况就可以断定系统出现了异常。 2.5.1关键技术点本文为了实现这样的内存状态机复制撮合系统,将撮合系统划分为以下组成关键技术点： 将确定性撮合算法状态机服务部署到多个独立撮合引擎 接收网关订单,并作为确定性撮合算法状态机的输入 根据撮合算法需求,选择一种订单排序方式 每个撮合引擎对按照排序方式排序过的订单进行撮合 将确定性撮合算法状态机输出的交易记录作为给用户或数据库的响应 监控撮合引擎副本的状态或输出的差别 2.5.2实现方案为实现基于内存状态机复制的撮合系统,本文主要通过以下方案实现状态机复制的关键技术点: 采用原子多播解决撮合引擎订单的可靠多播与全局有序性 采用基于无锁订单队列的流水线撮合技术提供快速的订单撮合 采用异步一致性持久化技术实现与数据库的交互 采用失效备援技术对撮合引擎集群进行状态监控并保证系统的容错能; 采用进度追赶技术解决将故障撮合引擎的恢复或新撮合引擎的加入 2.6 系统架构2.6.1系统硬件体系架构典型的高可靠高性能撮合模型硬件架构如图2.6所示,系统由n台客户端、N台网关、X个产品集群(每个集群由2至3台撮合引擎组成,负责响应产品订单的处理)、一个交易记录数据库和可选的监视系统组成。其中客户端连接到相应网关,网关负责接收客户端提交的订单,并根据订单相关的金融产品类别,转发到相对应的产品集群。产品集群中所有撮合引擎均接收网关发送的订单,根据撮合业务规则,将其撮合并回馈消息给网关和客户端,同时将撮合生成的交易记录持久化到交易记录数据库中。 通过对产品集群进行扩充,增加撮合引擎数量,可以增强产品集群的可靠性。将不同金融产品转发到不同的撮合产品集群中可以实现多产品高效并行撮合。 2.6.2 系统软件体系架构 如图2.7所示,高可靠高性能撮合模型主要由表示层、转发层、业务层和数据层组成。其核心部分业务层主要由撮合引擎集群组成,每个撮合引擎采用原子多播将订单定序后进行撮合处理,并结合无锁订单队列实现高效流水线撮合,最后结果写入本地日志。整个业务流程由消息传递总线将消息反馈给转发层。转发层则根据产品转发规则将订单转发给相应撮合引擎集群;而撮合引擎将本地日志中的交易记录读取到异步持久化代理进程中,并进而与数据层的异步持久化写入进程通信,并最终持久化到数据库中。本地日志增强了撮合系统数据的可靠性,在出现故障后,数据仍就可以从本地日志中恢复;而界步的持久化机制则提高了数据的持久化吞吐率。 2.6.3撮合引擎架构 为了使系统可扩展易维护,撮合引擎由原子多播订单定序模块、撮合处理器模块、交易记录日志模块和内存数据组成,每个模块根据功能业务划分。其中各部分主要有以下功能:交易订单接收线程:负责从网关接收订单,并完成原子多播定序流程。交易订单发送线程:将定序完成的订单发送给相关撮合业务线程。交易信息发送线程:将订单交易状态反馈给网关。外围业务逻辑线程:进行撮合数据的准备处理,更新内存订单数据。撮合业务逻辑线程:根据确定性撮合算法撮合接收的订单。交易行情发布线程:处理内存行情信息并发布给网关。同步日志写线程:将订单撮合产生的交易记录同步持久化到本地日志文件。异步持久化代理进程:异步将日志文件中的数据读取并持久化到数据库。订单信息:存储订单的相关价格、数量、用户、限制、类型和状态等信息交易行情信息:撮合交易过程中的交易行情信息。 2.6.4系统接口撮合系统主要为使用者提供订单的下单和查询服务、交易行情的实时反馈功能以及系统状态的监控查看服务。因此系统需要实现预留的接口主要包括:下单接口、订单查询接口、行情查询接口、系统控制接口和运行状态查询接口等。 2.7 小节从总体设计入手,将撮合业务处理从数据库迁移至内存中,同时釆用多机热备份技术解决内存撮合技术的易失性问题,最终提出内存状态机复制方案作为高可靠髙性能撮合系统的实现路线。撮合技术的具体实现将在下一章进行详细论述。 ###FAQ Q：热备的机制上。多个机器内存上的状态如何保证强一致性的？ A： 是热备机器都是无状态，普洱茶按照不同品种产生不同撮合序列，只要保证单品种有序，其他撮合机和本机没有关系。 Q: 如果新加入一台撮合引擎，怎么判断所有的撮合数据都同步到了这台新的引擎上？ A: 委托单先要写raid文件系统，新增撮合引擎，也可以拿到数据。 Q: 根据你的描述，一个集群中为了判断撮合引擎是否有故障，至少应该有3台撮合引擎吧? A: zk来管理，并且有风控进程监控撮合进度。 Q: 内存状态机的复制究竟是结果还是数据？ A: 数据，就是把处理到某个状态的数据复制出来。 Q: 如果只有两台撮合引擎，如果对一个买入订单，发现结果不一致，如何判断是哪一台的故障？ A: 撮合只有一台进行撮合，撮合结束才回写数据库产生行情和分发个个终端，用户就可以看到自己委托单是否成交。 【1】简书主页·share猿【2】掘金主页·share猿【3】撮合系统· 李伟山【4】撮合系统·技术方舟【5】交易所视角下的套利指令撮合机制 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"交易所","slug":"交易所","permalink":"https://lywlefan.github.io/tags/交易所/"},{"name":"撮合","slug":"撮合","permalink":"https://lywlefan.github.io/tags/撮合/"}]},{"title":"1.disruptor初识","date":"2019-06-25T16:00:00.000Z","path":"2019/06/26/软件研发/后端/高并发/java/并发框架/disruptor/1.disruptor初识/","text":"disruptor号称能够在一个线程里每秒处理6百万订单,业务逻辑处理器完全是运行在内存中，使用事件源驱动方式。 要学的概念乐观锁打个比方理解乐观锁就是到桥头再看有没有车来过此桥,没有的话快速过桥. 悲观锁打个比方理解悲观锁说白了就是先发制人,我的车要过桥,但是我担心桥上有其他车,所以我提前把桥口加一个锁,我到桥头了在开锁过桥,过去了再把锁子接触了. 死锁打个比方理解简单的比方,两俩车同时过一个桥,不能倒车,如果两辆车同时在桥上就会造成死锁,车就相当于我们的线程,桥就相当于资源. CASCAS简介谷歌翻译CAS是比较并转换,java.util.concurrent包中借助CAS实现了区别于synchronouse同步锁的一种乐观锁。 CAS应用CAS有3个操作数，内存值V，旧的预期值A，要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。 非阻塞算法 （nonblocking algorithms） 一个线程的失败或者挂起不应该影响其他线程的失败或挂起的算法。 CAS原理CAS通过调用JNI的代码实现的。JNI:Java Native Interface为JAVA本地调用，允许java调用其他语言而compareAndSwapInt就是借助C来调用CPU底层指令实现的。 CAS缺点 ABA问题 循环时间长开销大 只能保证一个共享变量的原子操作 缓存行初识性能 一个线程每秒处理6百万订单 内存中运行 ,使用事件源驱动方式 业务逻辑处理核心Disruptor hello world 建立一个event类,用于创建Event类实例对象 需要有一个监听事件类,用于处理数据(Event类) 实例化Disruptor实例,配置一系列参数,编写Disruptor核心组件 编写生产者组件,向Disruptor容器中去投递数据 核心讲解 RingBuffer基于数组的缓存实现,也是创建sequencer与定义WaitStrategy的入口 RingBuffer拥有一个序号,这个需要指向数组中下一个可用的元素 收尾相接的环 (环状数组) 假如缓存区芝麻满了,芝麻扔到哪里? 假如缓存区没芝麻了,如何取芝麻? 2的n次方更利于计算 Disruptor持有RingBuffer、消费者线程池Executor、消费者集合ConsumerRepository等引用. Sequence 通顺序递增的序号来编号,管理进行交换的数据(事件) 对数据(事件)的处理过程总是沿着序号逐个递增处理 一个Sequence用于跟踪标识某个特定的事件处理者(RingBuffer/Producer/Consumer)的处理进度 Sequence可以看成是一个AtomicLong用于标识进度 还有另外一个目的就是防止不同Sequence之间CPU缓存伪共享(Flase Sharing)的问题 Sequencer Sequencer是Disruptor的真正核心,包含Sequence 此接口有两个实现类 SingleProducerSequencer MultiProducerSequencer 主要实现生产者和消费者之间快速、正确的传递数据并发算法 Sequence Barrier 用于保持RingBuffer的Main Published Sequence(Producer)和Consumer之间平衡关系; 决定Consumer是否还有可处理事件逻辑 WaitStrategy 决定一个消费者将如何等待生产者将Event置入Disruptor 主要策略 BlockWaitStrategy 最低效策略 cpu消耗最小 在各种不同部署环境中提供更加一致性能表现 SleepingWaitStrategy 和上面性能差不多 cpu性能和上面差不多 对生产者线程影响最小,适合用于异步日志类似的场景 YieldingWaitStrategy 性能最好 适用低延迟系统 要求极高性能 要求极高性能且事件处理线数小于CPU逻辑核心数场景,列如:CPU开启超线程的特性 Event 从生产者到消费者过程中所处理的数据单元 Disruptor中没有代码表示Event,因为它完全是由用户定义的 EventProcessor 主要事件循环,处理Disruptor中的Event,拥有消费者Sequence 他是一个实现类是BatchEventProcessor,包含了event loop有效的实现,并且将回调一个EventHandler接口的实现对象. EventHandler 由用户并且代表了Disruptor中的一个消费者接口,也就是我们消费者逻辑都要写到这里. WorkProcessor 确保每个sequence只被一个processor消费,在同一个WorkPool中处理多个WorkProcessor不会消费同样的sequence 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 【3】disruptor官网 【4】JAVA CAS原理深度分析 【5】并发框架Disruptor译文 【6】从构建分布式秒杀系统聊聊Disruptor高性能队列 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"},{"name":"高并发","slug":"高并发","permalink":"https://lywlefan.github.io/tags/高并发/"},{"name":"disruptor","slug":"disruptor","permalink":"https://lywlefan.github.io/tags/disruptor/"}]},{"title":"2.disruptor应用","date":"2019-06-25T16:00:00.000Z","path":"2019/06/26/软件研发/后端/高并发/java/并发框架/disruptor/2.disruptor应用/","text":"disruptor号称能够在一个线程里每秒处理6百万订单,业务逻辑处理器完全是运行在内存中，使用事件源驱动方式。 本节导航 Disruptor核心链路场景应用讲解 并行计算- 串行操作 并行计算- 并行操作 并行计算- 多遍形高端操作 并行计算- 多生产者消费模型 并行计算- 多消费者消费模型 Disruptor核心链路场景应用讲解概念啥是核心链路?就拿京东来说,下单支付就是核心链路,物流也是核心链路. 核心链路特点 代码复杂 业务逻辑复杂 如何实现 传统完全解耦的方式 模板模式 使用框架 有限状态机框架：Spring-StateMachine 使用Disruptor 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 【3】disruptor官网 【4】JAVA CAS原理深度分析 【5】并发框架Disruptor译文 【6】从构建分布式秒杀系统聊聊Disruptor高性能队列 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"},{"name":"高并发","slug":"高并发","permalink":"https://lywlefan.github.io/tags/高并发/"},{"name":"disruptor","slug":"disruptor","permalink":"https://lywlefan.github.io/tags/disruptor/"}]},{"title":"环形缓冲区","date":"2019-06-24T16:00:00.000Z","path":"2019/06/25/软件研发/后端/基础巩固/java/数据结构/环形缓冲区/","text":"万丈高楼平地起的前提是地基好. 环形缓冲区介绍圆形缓冲区（circular buffer），也称作圆形队列（circular queue），循环缓冲区（cyclic buffer），环形缓冲区（ring buffer），是一种数据结构用于表示一个固定尺寸、头尾相连的缓冲区，适合缓存数据流。 用法圆形缓冲区的一个有用特性是：当一个数据元素被用掉后，其余数据元素不需要移动其存储位置。相反，一个非圆形缓冲区（例如一个普通的队列）在用掉一个数据元素后，其余数据元素需要向前搬移。换句话说，圆形缓冲区适合实现先进先出缓冲区，而非圆形缓冲区适合后进先出缓冲区。 圆形缓冲区适合于事先明确了缓冲区的最大容量的情形。扩展一个圆形缓冲区的容量，需要搬移其中的数据。因此一个缓冲区如果需要经常调整其容量，用链表实现更为合适。 写操作覆盖圆形缓冲区中未被处理的数据在某些情况下是允许的。特别是在多媒体处理时。例如，音频的生产者可以覆盖掉声卡尚未来得及处理的音频数据。 工作过程一个圆形缓冲区最初为空并有预定的长度。例如，这是一个具有七个元素空间的圆形缓冲区，其中底部的单线与箭头表示“头尾相接”形成一个圆形地址空间： 假定1被写入缓冲区中部（对于圆形缓冲区来说，最初的写入位置在哪里是无关紧要的）： 再写入2个元素，分别是2 &amp; 3 — 被追加在1之后： 如果两个元素被处理，那么是缓冲区中最老的两个元素被卸载。在本例中，1 &amp; 2被卸载，缓冲区中只剩下3: 如果缓冲区中有7个元素，则是满的： 如果缓冲区是满的，又要写入新的数据，一种策略是覆盖掉最老的数据。此例中，2个新数据— A &amp; B — 写入，覆盖了3 &amp; 4: 也可以采取其他策略，禁止覆盖缓冲区的数据，采取返回一个错误码或者抛出异常。 最终，如果从缓冲区中卸载2个数据，不是3 &amp; 4 而是 5 &amp; 6 。因为 A &amp; B 已经覆盖了3 &amp; 4： 圆形缓冲区工作机制由于计算机内存是线性地址空间，因此圆形缓冲区需要特别的设计才可以从逻辑上实现。 读指针与写指针一般的，圆形缓冲区需要4个指针： 在内存中实际开始位置； 在内存中实际结束位置，也可以用缓冲区长度代替； 存储在缓冲区中的有效数据的开始位置（读指针）； 存储在缓冲区中的有效数据的结尾位置（写指针）。 读指针、写指针可以用整型值来表示。 下例为一个未满的缓冲区的读写指针： 下例为一个满的缓冲区的读写指针： 区分缓冲区满或者空缓冲区是满、或是空，都有可能出现读指针与写指针指向同一位置： 250px有多种策略用于检测缓冲区是满、或是空. 总是保持一个存储单元为空缓冲区中总是有一个存储单元保持未使用状态。缓冲区最多存入个数据。如果读写指针指向同一位置，则缓冲区为空。如果写指针位于读指针的相邻后一个位置，则缓冲区为满。这种策略的优点是简单、鲁棒；缺点是语义上实际可存数据量与缓冲区容量不一致，测试缓冲区是否满需要做取余数计算。 使用数据计数这种策略不使用显式的写指针，而是保持着缓冲区内存储的数据的计数。因此测试缓冲区是空是满非常简单；对性能影响可以忽略。缺点是读写操作都需要修改这个存储数据计数，对于多线程访问缓冲区需要并发控制。 镜像指示位缓冲区的长度如果是n，逻辑地址空间则为0至n-1；那么，规定n至2n-1为镜像逻辑地址空间。本策略规定读写指针的地址空间为0至2n-1，其 中低半部分对应于常规的逻辑地址空间，高半部分对应于镜像逻辑地址空间。当指针值大于等于2n时，使其折返（wrapped）到ptr-2n。使用一位表 示写指针或读指针是否进入了虚拟的镜像存储区：置位表示进入，不置位表示没进入还在基本存储区。 在读写指针的值相同情况下，如果二者的指示位相同，说明缓冲区为空；如果二者的指示位不同，说明缓冲区为满。这种方法优点是测试缓冲区满/空很简 单；不需要做取余数操作；读写线程可以分别设计专用算法策略，能实现精致的并发控制。 缺点是读写指针各需要额外的一位作为指示位。 如果缓冲区长度是2的幂，则本方法可以省略镜像指示位。如果读写指针的值相等，则缓冲区为空；如果读写指针相差n，则缓冲区为满，这可以用条件表达式（写指针 == (读指针 异或 缓冲区长度)）来判断。 读/写 计数用两个有符号整型变量分别保存写入、读出缓冲区的数据数量。其差值就是缓冲区中尚未被处理的有效数据的数量。这种方法的优点是读线程、写线程互不干扰；缺点是需要额外两个变量。 记录最后的操作使用一位记录最后一次操作是读还是写。读写指针值相等情况下，如果最后一次操作为写入，那么缓冲区是满的；如果最后一次操作为读出，那么缓冲区是空。 这种策略的缺点是读写操作共享一个标志位，多线程时需要并发控制。 POSIX优化实现Linux内核的kfifo在Linux内核文件kfifo.h和kfifo.c中，定义了一个先进先出圆形缓冲区实现。如果只有一个读线程、一个写线程，二者没有共享的被修改的控制变量，那么可以证明这种情况下不需要并发控制。kfifo就满足上述条件。kfifo要求缓冲区长度必须为2的幂。读、写指针分别是无符号整型变量。把读写指针变换为缓冲区内的索引值，仅需要“按位与”操作：（指针值 按位与 （缓冲区长度-1））。这避免了计算代价高昂的“求余”操作。且下述关系总是成立： 读指针 + 缓冲区存储的数据长度 == 写指针即使在写指针达到了无符号整型的上界，上溢出后写指针的值小于读指针的值，上述关系仍然保持成立（这是因为无符号整型加法的性质）。 kfifo的写操作，首先计算缓冲区中当前可写入存储空间的数据长度：len = min[待写入数据长度, 缓冲区长度 - （写指针 - 读指针）]然后，分两段写入数据。第一段是从写指针开始向缓冲区末尾方向；第二段是从缓冲区起始处写入余下的可写入数据，这部分可能数据长度为0即并无实际数据写入。 【1】简书主页·share猿【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"},{"name":"基础","slug":"基础","permalink":"https://lywlefan.github.io/tags/基础/"}]},{"title":"LMAX架构","date":"2019-06-20T16:00:00.000Z","path":"2019/06/21/软件研发/架构/从100到1000万高并发的架构演进之路/","text":"万丈高楼平地起的前提是地基好. 基本概念在介绍架构之前，为了避免部分读者对架构设计中的一些概念不了解，下面对几个最基础的概念进行介绍。 什么是分布式？系统中的多个模块在不同服务器上部署，即可称为分布式系统，如Tomcat和数据库分别部署在不同的服务器上，或两个相同功能的Tomcat分别部署在不同服务器上。 什么是高可用？系统中部分节点失效时，其他节点能够接替它继续提供服务，则可认为系统具有高可用性。 什么是集群？一个特定领域的软件部署在多台服务器上并作为一个整体提供一类服务，这个整体称为集群。 如Zookeeper中的Master和Slave分别部署在多台服务器上，共同组成一个整体提供集中配置服务。 在常见的集群中，客户端往往能够连接任意一个节点获得服务，并且当集群中一个节点掉线时，其他节点往往能够自动的接替它继续提供服务，这时候说明集群具有高可用性。 什么是负载均衡？请求发送到系统时，通过某些方式把请求均匀分发到多个节点上，使系统中每个节点能够均匀的处理请求负载，则可认为系统是负载均衡的。 什么是正向代理和反向代理？系统内部要访问外部网络时，统一通过一个代理服务器把请求转发出去，在外部网络看来就是代理服务器发起的访问，此时代理服务器实现的是正向代理； 当外部请求进入系统时，代理服务器把该请求转发到系统中的某台服务器上，对外部请求来说，与之交互的只有代理服务器，此时代理服务器实现的是反向代理。 简单来说，正向代理是代理服务器代替系统内部来访问外部网络的过程，反向代理是外部请求访问系统时通过代理服务器转发到内部服务器的过程。 架构演讲纯真年代：单机架构 以淘宝作为例子：在网站最初时，应用数量与用户数都较少，可以把Tomcat和数据库部署在同一台服务器上。浏览器往www.taobao.com发起请求时，首先经过DNS服务器（域名系统）把域名转换为实际IP地址10.102.4.1，浏览器转而访问该IP对应的Tomcat。 架构瓶颈：随着用户数的增长，Tomcat和数据库之间竞争资源，单机性能不足以支撑业务。 第一次演进：Tomcat与数据库分开部署 Tomcat和数据库分别独占服务器资源，显著提高两者各自性能。 架构瓶颈：随着用户数的增长，并发读写数据库成为瓶颈。 第二次演进：引入本地缓存和分布式缓存 在Tomcat同服务器上或同JVM中增加本地缓存，并在外部增加分布式缓存，缓存热门商品信息或热门商品的html页面等。通过缓存能把绝大多数请求在读写数据库前拦截掉，大大降低数据库压力。其中涉及的技术包括：使用memcached作为本地缓存，使用Redis作为分布式缓存，还会涉及缓存一致性、缓存穿透/击穿、缓存雪崩、热点数据集中失效等问题。 架构瓶颈：缓存抗住了大部分的访问请求，随着用户数的增长，并发压力主要落在单机的Tomcat上，响应逐渐变慢。 第三次演进：引入反向代理实现负载均衡 在多台服务器上分别部署Tomcat，使用反向代理软件（Nginx）把请求均匀分发到每个Tomcat中。此处假设Tomcat最多支持100个并发，Nginx最多支持50000个并发，那么理论上Nginx把请求分发到500个Tomcat上，就能抗住50000个并发。 其中涉及的技术包括：Nginx、HAProxy，两者都是工作在网络第七层的反向代理软件，主要支持http协议，还会涉及session共享、文件上传下载的问题。 架构瓶颈：反向代理使应用服务器可支持的并发量大大增加，但并发量的增长也意味着更多请求穿透到数据库，单机的数据库最终成为瓶颈。 第四次演进：数据库读写分离 把数据库划分为读库和写库，读库可以有多个，通过同步机制把写库的数据同步到读库，对于需要查询最新写入数据场景，可通过在缓存中多写一份，通过缓存获得最新数据。其中涉及的技术包括：Mycat，它是数据库中间件，可通过它来组织数据库的分离读写和分库分表，客户端通过它来访问下层数据库，还会涉及数据同步，数据一致性的问题。 架构瓶颈：业务逐渐变多，不同业务之间的访问量差距较大，不同业务直接竞争数据库，相互影响性能。 第五次演进：数据库按业务分库 把不同业务的数据保存到不同的数据库中，使业务之间的资源竞争降低，对于访问量大的业务，可以部署更多的服务器来支撑。这样同时导致跨业务的表无法直接做关联分析，需要通过其他途径来解决，但这不是本文讨论的重点，有兴趣的可以自行搜索解决方案。 架构瓶颈：随着用户数的增长，单机的写库会逐渐会达到性能瓶颈。 第六次演进：把大表拆分为小表 比如针对评论数据，可按照商品ID进行hash，路由到对应的表中存储；针对支付记录，可按照小时创建表，每个小时表继续拆分为小表，使用用户ID或记录编号来路由数据。只要实时操作的表数据量足够小，请求能够足够均匀的分发到多台服务器上的小表，那数据库就能通过水平扩展的方式来提高性能。其中前面提到的Mycat也支持在大表拆分为小表情况下的访问控制。 这种做法显著的增加了数据库运维的难度，对DBA的要求较高。数据库设计到这种结构时，已经可以称为分布式数据库，但是这只是一个逻辑的数据库整体，数据库里不同的组成部分是由不同的组件单独来实现的，如分库分表的管理和请求分发，由Mycat实现，SQL的解析由单机的数据库实现，读写分离可能由网关和消息队列来实现，查询结果的汇总可能由数据库接口层来实现等等，这种架构其实是MPP（大规模并行处理）架构的一类实现。 目前开源和商用都已经有不少MPP数据库，开源中比较流行的有Greenplum、TiDB、Postgresql XC、HAWQ等，商用的如南大通用的GBase、睿帆科技的雪球DB、华为的LibrA等等，不同的MPP数据库的侧重点也不一样，如TiDB更侧重于分布式OLTP场景，Greenplum更侧重于分布式OLAP场景，这些MPP数据库基本都提供了类似Postgresql、Oracle、MySQL那样的SQL标准支持能力，能把一个查询解析为分布式的执行计划分发到每台机器上并行执行，最终由数据库本身汇总数据进行返回，也提供了诸如权限管理、分库分表、事务、数据副本等能力，并且大多能够支持100个节点以上的集群，大大降低了数据库运维的成本，并且使数据库也能够实现水平扩展。 架构瓶颈：数据库和Tomcat都能够水平扩展，可支撑的并发大幅提高，随着用户数的增长，最终单机的Nginx会成为瓶颈。 第七次演进：使用LVS或F5来使多个Nginx负载均衡 由于瓶颈在Nginx，因此无法通过两层的Nginx来实现多个Nginx的负载均衡。图中的LVS和F5是工作在网络第四层的负载均衡解决方案，其中LVS是软件，运行在操作系统内核态，可对TCP请求或更高层级的网络协议进行转发，因此支持的协议更丰富，并且性能也远高于Nginx，可假设单机的LVS可支持几十万个并发的请求转发；F5是一种负载均衡硬件，与LVS提供的能力类似，性能比LVS更高，但价格昂贵。由于LVS是单机版的软件，若LVS所在服务器宕机则会导致整个后端系统都无法访问，因此需要有备用节点。可使用keepalived软件模拟出虚拟IP，然后把虚拟IP绑定到多台LVS服务器上，浏览器访问虚拟IP时，会被路由器重定向到真实的LVS服务器，当主LVS服务器宕机时，keepalived软件会自动更新路由器中的路由表，把虚拟IP重定向到另外一台正常的LVS服务器，从而达到LVS服务器高可用的效果。 此处需要注意的是，上图中从Nginx层到Tomcat层这样画并不代表全部Nginx都转发请求到全部的Tomcat，在实际使用时，可能会是几个Nginx下面接一部分的Tomcat，这些Nginx之间通过keepalived实现高可用，其他的Nginx接另外的Tomcat，这样可接入的Tomcat数量就能成倍的增加。 架构瓶颈：由于LVS也是单机的，随着并发数增长到几十万时，LVS服务器最终会达到瓶颈，此时用户数达到千万甚至上亿级别，用户分布在不同的地区，与服务器机房距离不同，导致了访问的延迟会明显不同。 第八次演进：通过DNS轮询实现机房间的负载均衡 在DNS服务器中可配置一个域名对应多个IP地址，每个IP地址对应到不同的机房里的虚拟IP。当用户访问www.taobao.com时，DNS服务器会使用轮询策略或其他策略，来选择某个IP供用户访问。此方式能实现机房间的负载均衡，至此，系统可做到机房级别的水平扩展，千万级到亿级的并发量都可通过增加机房来解决，系统入口处的请求并发量不再是问题。 架构瓶颈：随着数据的丰富程度和业务的发展，检索、分析等需求越来越丰富，单单依靠数据库无法解决如此丰富的需求。 第九次演进：引入NoSQL数据库和搜索引擎等技术 当数据库中的数据多到一定规模时，数据库就不适用于复杂的查询了，往往只能满足普通查询的场景。对于统计报表场景，在数据量大时不一定能跑出结果，而且在跑复杂查询时会导致其他查询变慢，对于全文检索、可变数据结构等场景，数据库天生不适用。因此需要针对特定的场景，引入合适的解决方案。如对于海量文件存储，可通过分布式文件系统HDFS解决，对于key value类型的数据，可通过HBase和Redis等方案解决，对于全文检索场景，可通过搜索引擎如ElasticSearch解决，对于多维分析场景，可通过Kylin或Druid等方案解决。 当然，引入更多组件同时会提高系统的复杂度，不同的组件保存的数据需要同步，需要考虑一致性的问题，需要有更多的运维手段来管理这些组件等。 架构瓶颈：引入更多组件解决了丰富的需求，业务维度能够极大扩充，随之而来的是一个应用中包含了太多的业务代码，业务的升级迭代变得困难。 第十次演进：大应用拆分为小应用 按照业务板块来划分应用代码，使单个应用的职责更清晰，相互之间可以做到独立升级迭代。这时候应用之间可能会涉及到一些公共配置，可以通过分布式配置中心Zookeeper来解决。 架构瓶颈：不同应用之间存在共用的模块，由应用单独管理会导致相同代码存在多份，导致公共功能升级时全部应用代码都要跟着升级。 第十一次演进：复用的功能抽离成微服务 如用户管理、订单、支付、鉴权等功能在多个应用中都存在，那么可以把这些功能的代码单独抽取出来形成一个单独的服务来管理，这样的服务就是所谓的微服务，应用和服务之间通过HTTP、TCP或RPC请求等多种方式来访问公共服务，每个单独的服务都可以由单独的团队来管理。此外，可以通过Dubbo、SpringCloud等框架实现服务治理、限流、熔断、降级等功能，提高服务的稳定性和可用性。 架构瓶颈：不同服务的接口访问方式不同，应用代码需要适配多种访问方式才能使用服务，此外，应用访问服务，服务之间也可能相互访问，调用链将会变得非常复杂，逻辑变得混乱。 第十二次演进：引入企业服务总线ESB屏蔽服务接口的访问差异 通过ESB统一进行访问协议转换，应用统一通过ESB来访问后端服务，服务与服务之间也通过ESB来相互调用，以此降低系统的耦合程度。 这种单个应用拆分为多个应用，公共服务单独抽取出来来管理，并使用企业消息总线来解除服务之间耦合问题的架构，就是所谓的SOA（面向服务）架构，这种架构与微服务架构容易混淆，因为表现形式十分相似。 个人理解，微服务架构更多是指把系统里的公共服务抽取出来单独运维管理的思想，而SOA架构则是指一种拆分服务并使服务接口访问变得统一的架构思想，SOA架构中包含了微服务的思想。 架构瓶颈：业务不断发展，应用和服务都会不断变多，应用和服务的部署变得复杂，同一台服务器上部署多个服务还要解决运行环境冲突的问题，此外，对于如大促这类需要动态扩缩容的场景，需要水平扩展服务的性能，就需要在新增的服务上准备运行环境，部署服务等，运维将变得十分困难。 第十三次演进：引入容器化技术实现运行环境隔离与动态服务管理 目前最流行的容器化技术是Docker，最流行的容器管理服务是Kubernetes(K8S)，应用/服务可以打包为Docker镜像，通过K8S来动态分发和部署镜像。Docker镜像可理解为一个能运行你的应用/服务的最小的操作系统，里面放着应用/服务的运行代码，运行环境根据实际的需要设置好。把整个“操作系统”打包为一个镜像后，就可以分发到需要部署相关服务的机器上，直接启动Docker镜像就可以把服务起起来，使服务的部署和运维变得简单。 在大促的之前，可以在现有的机器集群上划分出服务器来启动Docker镜像，增强服务的性能，大促过后就可以关闭镜像，对机器上的其他服务不造成影响（在第18节之前，服务运行在新增机器上需要修改系统配置来适配服务，这会导致机器上其他服务需要的运行环境被破坏）。 架构瓶颈：使用容器化技术后服务动态扩缩容问题得以解决，但是机器还是需要公司自身来管理，在非大促的时候，还是需要闲置着大量的机器资源来应对大促，机器自身成本和运维成本都极高，资源利用率低。 第十四次演进：以云平台承载系统 系统可部署到公有云上，利用公有云的海量机器资源，解决动态硬件资源的问题，在大促的时间段里，在云平台中临时申请更多的资源，结合Docker和K8S来快速部署服务，在大促结束后释放资源，真正做到按需付费，资源利用率大大提高，同时大大降低了运维成本。 所谓的云平台，就是把海量机器资源，通过统一的资源管理，抽象为一个资源整体，在之上可按需动态申请硬件资源（如CPU、内存、网络等），并且之上提供通用的操作系统，提供常用的技术组件（如Hadoop技术栈，MPP数据库等）供用户使用，甚至提供开发好的应用，用户不需要关系应用内部使用了什么技术，就能够解决需求（如音视频转码服务、邮件服务、个人博客等）。 在云平台中会涉及如下几个概念： IaaS：基础设施即服务。对应于上面所说的机器资源统一为资源整体，可动态申请硬件资源的层面； PaaS：平台即服务。对应于上面所说的提供常用的技术组件方便系统的开发和维护； SaaS：软件即服务。对应于上面所说的提供开发好的应用或服务，按功能或性能要求付费。 至此：以上所提到的从高并发访问问题，到服务的架构和系统实施的层面都有了各自的解决方案。但同时也应该意识到，在上面的介绍中，其实是有意忽略了诸如跨机房数据同步、分布式事务实现等等的实际问题，这些问题以后有机会再拿出来单独讨论。 小结架构的调整是否必须按照上述演变路径进行？不是的，以上所说的架构演变顺序只是针对某个侧面进行单独的改进，在实际场景中，可能同一时间会有几个问题需要解决，或者可能先达到瓶颈的是另外的方面，这时候就应该按照实际问题实际解决。如在政府类的并发量可能不大，但业务可能很丰富的场景，高并发就不是重点解决的问题，此时优先需要的可能会是丰富需求的解决方案。 对于将要实施的系统，架构应该设计到什么程度？对于单次实施并且性能指标明确的系统，架构设计到能够支持系统的性能指标要求就足够了，但要留有扩展架构的接口以便不备之需。对于不断发展的系统，如电商平台，应设计到能满足下一阶段用户量和性能指标要求的程度，并根据业务的增长不断的迭代升级架构，以支持更高的并发和更丰富的业务。 服务端架构和大数据架构有什么区别？所谓的“大数据”其实是海量数据采集清洗转换、数据存储、数据分析、数据服务等场景解决方案的一个统称，在每一个场景都包含了多种可选的技术，如数据采集有Flume、Sqoop、Kettle等，数据存储有分布式文件系统HDFS、FastDFS，NoSQL数据库HBase、MongoDB等，数据分析有Spark技术栈、机器学习算法等。总的来说大数据架构就是根据业务的需求，整合各种大数据组件组合而成的架构，一般会提供分布式存储、分布式计算、多维分析、数据仓库、机器学习算法等能力。而服务端架构更多指的是应用组织层面的架构，底层能力往往是由大数据架构来提供。 有没有一些架构设计的原则？ a. N+1设计：系统中的每个组件都应做到没有单点故障； b. 回滚设计：确保系统可以向前兼容，在系统升级时应能有办法回滚版本； c. 禁用设计：应该提供控制具体功能是否可用的配置，在系统出现故障时能够快速下线功能； d. 监控设计：在设计阶段就要考虑监控的手段； e. 多活数据中心设计：若系统需要极高的高可用，应考虑在多地实施数据中心进行多活，至少在一个机房断电的情况下系统依然可用； f. 采用成熟的技术：刚开发的或开源的技术往往存在很多隐藏的bug，出了问题没有商业支持可能会是一个灾难； g. 资源隔离设计：应避免单一业务占用全部资源； h. 架构应能水平扩展：系统只有做到能水平扩展，才能有效避免瓶颈问题； i. 非核心则购买：非核心功能若需要占用大量的研发资源才能解决，则考虑购买成熟的产品； j. 使用商用硬件：商用硬件能有效降低硬件故障的机率； k. 快速迭代：系统应该快速开发小功能模块，尽快上线进行验证，早日发现问题大大降低系统交付的风险； l. 无状态设计：服务接口应该做成无状态的，当前接口的访问不依赖于接口上次访问的状态。 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 《新手入门：零基础理解大型分布式架构的演进历史、技术原理、最佳实践》 《腾讯资深架构师干货总结：一文读懂大型分布式系统设计的方方面面》 《一篇读懂分布式架构下的负载均衡技术：分类、原理、算法、常见方案等》 《快速理解高性能HTTP服务端的负载均衡技术原理》 《知乎技术分享：从单机到2000万QPS并发的Redis高性能缓存实践之路》 《达达O2O后台架构演进实践：从0到4000高并发请求背后的努力》 《小米技术分享：解密小米抢购系统千万高并发架构的演进和实践》 《通俗易懂：如何设计能支撑百万并发的数据库架构？》 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"总结","slug":"总结","permalink":"https://lywlefan.github.io/tags/总结/"}]},{"title":"LMAX架构","date":"2019-06-20T16:00:00.000Z","path":"2019/06/21/软件研发/架构/LMAX架构/LMAX架构/","text":"万丈高楼平地起的前提是地基好. LMAX架构简介 该架构主要基于：Disruptor + In Memory DDD + Event Sourcing 通过高并发框架（Disruptor）实现用户事件的输入和Domain Event的输出； 一个常驻内存的Business Logic Processor（DDD领域模型），它负责在纯内存中处理业务逻辑；关键点：首先确保用户输入事件被持久化到数据库，并定时创建快照，然后在内存中响应事件更改业务对象的状态；因为一切都是在内存中处理，所以没有IO，也不需要数据库事务，非常快； 机器down了怎么办？因为我们首先确保了业务对象的任何状态改变之前先持久化用户输入事件，所以在down机的时候通过事件回溯重新得到最新的业务对象。因为有了快照的保存，所以重建对象也非常快； 该架构的主要观点： 肯定了In-Memory内存模式 + 异步输入与输出事件（Disruptor） + Event Sourcing 架构，LMAX实践也验证了这个架构。这个架构降低复杂性。 LMAX的核心是新型并发框架Disruptor，其核心是根据现代CPU硬件缓存特点发明不同于通用LinkedList或Queue的新型数据结构RingBuffer。 号称并发未来的Actor模型被LMAX团队验证是有瓶颈的。 提出新的并发模型，每个CPU一个线程，多个CPU多个线程并发模式，摒弃了锁模式。 ORM等Hibernate没有完全解决OO的目标，关系数据库的事务也不是最后救命的稻草。LMAX用自己的事件记录的方式实现事务，这也不同于所谓内存事务STM。 架构师要分离关注，一是通过DDD降低业务的复杂性；二是通过技术探索创新，降低技术平台的复杂性，让程序员更多精力投入业务问题解决上。 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 【3】LMAX架构简介·汤雪华 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"LMAX","slug":"LMAX","permalink":"https://lywlefan.github.io/tags/LMAX/"}]},{"title":"使用Java8新的时间API使用","date":"2019-06-20T16:00:00.000Z","path":"2019/06/21/软件研发/后端/基础巩固/java/工具类/使用 Java8 新的时间 API使用/","text":"标题","tags":[{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"},{"name":"基础","slug":"基础","permalink":"https://lywlefan.github.io/tags/基础/"}]},{"title":"java枚举的总结和学习","date":"2019-06-20T16:00:00.000Z","path":"2019/06/21/软件研发/后端/基础巩固/java/枚举/java枚举的总结和学习/","text":"万丈高楼平地起的前提是地基好. 枚举基础规范 实例常量用大写 enum是个类(特别实用的特性,可以在switch语句中使用) 方法 toString:显示某个实例的名字 ordinal:显示常量的顺序 static values:按枚举常量顺序,产生常量构成的数组. 枚举类可以实现一个接口 使用常量123public enum Color &#123; RED, GREEN, BLANK, YELLOW &#125; switch12345678910111213141516171819enum Signal &#123; GREEN, YELLOW, RED &#125; public class TrafficLight &#123; Signal color = Signal.RED; public void change() &#123; switch (color) &#123; case RED: color = Signal.GREEN; break; case YELLOW: color = Signal.RED; break; case GREEN: color = Signal.YELLOW; break; &#125; &#125; &#125; 构造方法&emsp;&emsp;规定构造方法必须为private修饰符所修饰，也就是说只能在类的内部构造，不能在其他类中通过构造方法新增枚举类型。 在枚举类中创建一个构造函数 123456789@Getter@AllArgsConstructorpublic enum CommonEnum &#123; SUCCESS(\"交易成功\",\"SUCCESS\"); private String name; private String value; &#125; 枚举可以实现一个接口 123456789101112131415161718192021222324252627public interface Behaviour &#123; void print(); String getInfo(); &#125; public enum Color implements Behaviour&#123; RED(&quot;红色&quot;, 1), GREEN(&quot;绿色&quot;, 2), BLANK(&quot;白色&quot;, 3), YELLO(&quot;黄色&quot;, 4); // 成员变量 private String name; private int index; // 构造方法 private Color(String name, int index) &#123; this.name = name; this.index = index; &#125; //接口方法 @Override public String getInfo() &#123; return this.name; &#125; //接口方法 @Override public void print() &#123; System.out.println(this.index+&quot;:&quot;+this.name); &#125; &#125; 使用接口组织枚举12345678public interface Food &#123; enum Coffee implements Food&#123; BLACK_COFFEE,DECAF_COFFEE,LATTE,CAPPUCCINO &#125; enum Dessert implements Food&#123; FRUIT, CAKE, GELATO &#125; &#125; 关于枚举集合的使用&emsp;&emsp;java.util.EnumSet和java.util.EnumMap是两个枚举集合。EnumSet保证集合中的元素不重复；EnumMap中的 key是enum类型，而value则可以是任意类型。关于这个两个集合的使用就不在这里赘述，可以参考JDK文档。 【1】简书主页·share猿【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"},{"name":"基础","slug":"基础","permalink":"https://lywlefan.github.io/tags/基础/"}]},{"title":"java整体脉络总结","date":"2019-06-04T16:00:00.000Z","path":"2019/06/05/软件研发/后端/指导思想/java/java整体脉络总结/","text":"java学习指导战略。 基础 Java基础知识 阅读源代码 String Integer Long Enum BigDecimal ThreadLocal ClassLoader&amp;URLClassLoader ArrayList&amp;LinkedList HashMap&amp;LinkedHashMap&amp;TreeMap&amp;CouncurrentHashMap HashSet&amp;LinkedHashSet&amp;TreeSet Java中的各种变量类型 熟悉Java String的使用，熟悉String的各种函数 JDK6和JDK7中substring的原理及区别 replaceFirst、replaceAll、replace区别 String对“+”的重载 String.valueOf和Integer.toString的区别 字符串的不可变性 自动拆装箱 Integer的缓存机制 熟悉Java中各种关键字原理和用法 transient instanceof volatile synchronized final static const 集合类 常用集合类的使用 ArrayList和LinkedList和Vector的区别 SynchronizedList和Vector的区别 HashMap、HashTable、ConcurrentHashMap区别 Java 8中stream相关用法 apache集合处理工具类的使用 不同版本的JDK中HashMap的实现的区别以及原因 枚举 枚举的用法 枚举与单例 Enum类 Java IO&amp;Java NIO bio nio aio 三种IO的用法与原理 netty Java反射与javassist 反射与工厂模式 java.lang.reflect.* Java序列化 什么是序列化与反序列化、为什么序列化 序列化底层原理 序列化与单例模式 protobuf 为什么说序列化并不安全 注解 元注解 自定义注解 Java中常用注解使用 注解与反射的结合 JMS 什么是Java消息服务 JMS消息传送模型 JMX java.lang.management.* javax.management.* 泛型 泛型与继承 类型擦除 泛型中K T V E object等的含义、泛型各种用法 单元测试 junit mock mockito 内存数据库（h2） 正则表达式 java.lang.util.regex.* 常用的Java工具库 commons.lang commons.*… guava-libraries netty 什么是API&amp;SPI 异常 异常类型 正确处理异常 自定义异常 时间处理 时区 时令 Java中时间API 编码方式 解决乱码问题 常用编码方式 语法糖 Java中语法糖原理 解语法糖 Java并发编程 什么是线程，与进程的区别 阅读相关源代码，并学会使用 Thread Runnable Callable ReentrantLock、ReentrantReadWriteLock、Atomic*、Semaphore、CountDownLatch、、ConcurrentHashMap、Executors 线程池 自己设计线程池、submit() 和 execute() 线程安全 死锁、死锁如何排查、Java线程调度、线程安全和内存模型的关系 锁 CAS、乐观锁与悲观锁、数据库相关锁机制、分布式锁、偏向锁、轻量级锁、重量级锁、monitor、锁优化、锁消除、锁粗化、自旋锁、可重入锁、阻塞锁、死锁 死锁 volatile happens-before、编译器指令重排和CPU指令重 synchronized synchronized是如何实现的？ synchronized和lock之间关系，不使用synchronized如何实现一个线程安全的单例 sleep 和 wait wait 和 notify notify 和 notifyAll ThreadLocal 写一个死锁的程序 写代码来解决生产者消费者问题 守护线程 守护线程和非守护线程的区别以及用法 JVM JVM内存结构 堆 栈 方法区 直接内存 堆和栈的区别 Java内存模型 内存可见性 重排序 顺序一致性 volatile 锁 final 垃圾回收 内存分配策略 垃圾收集器 G1 GC算法 GC参数 对象存活的判定 JVM参数及调优 Java对象模型 oop-klass 对象头 HotSpot 即时编译器 编译优化 类加载机制 classLoader 类加载过程 双亲委派（破坏双亲委派） 模块化 jboss modules osgi jigsaw 虚拟机性能监控与故障处理工具 jps jstack jmap jstat jconsole jhat javap btrace TProfiler 编译与反编译 javac javap jad CRF 进阶 Java底层知识 字节码、class文件格式 CPU缓存，L1，L2，L3和伪共享 尾递归 位运算 位运算实现加、减、乘、除、取余 设计模式 了解23种设计模式 在软件工程中，设计模式（design pattern）是对软件设计中普遍存在的各种问题，所提出的解决方案。设计模式并不是固定的一套代码，而是针对某一特定问题的具体解决思路与方案。可以认为是一种最佳实践，因为他是无数软件开发人员经过长时间的实践总结出来的。 设计模式的六大原则 开闭原则 里氏代换原则 依赖倒转原则 接口隔离原则 迪米特法则（最少知道原则） 合成复用原则 设计模式分类 创建型模式 单例模式 保证一个类仅有一个实例，并提供一个访问它的全局访问点。 在内存里只有一个实例，减少了内存的开销，尤其是频繁的创建和销毁实例（比如网站首页页面缓存）。 避免对资源的多重占用（比如写文件操作） 饿汉式 1234567891011public class Singleton &#123; //在类内部实例化一个实例 private static Singleton instance = new Singleton(); //私有的构造函数,外部无法访问 private Singleton() &#123; &#125; //对外提供获取实例的静态方法 public static Singleton getInstance() &#123; return instance; &#125; &#125; 饿汉式单例，在类被加载的时候对象就会实例化。这也许会造成不必要的消耗，因为有可能这个实例根本就不会被用到。而且，如果这个类被多次加载的话也会造成多次实例化。其实解决这个问题的方式有很多，下面提供两种解决方式，第一种是使用静态内部类的形式。第二种是使用懒汉式。 静态内部类式 饿汉式是只要Singleton类被装载了，那么instance就会被实例化（没有达到lazy loading效果），而这种方式是Singleton类被装载了，instance不一定被初始化。因为SingletonHolder类没有被主动使用，只有显示通过调用getInstance方法时，才会显示装载SingletonHolder类，从而实例化instance 想象一下，如果实例化instance很消耗资源，我想让他延迟加载，另外一方面，我不希望在Singleton类加载时就实例化，因为我不能确保Singleton类还可能在其他的地方被主动使用从而被加载，那么这个时候实例化instance显然是不合适的。这个时候，这种方式相比饿汉式更加合理。 12345678910111213public class StaticInnerClassSingleton &#123; //在静态内部类中初始化实例对象 private static class SingletonHolder &#123; private static final StaticInnerClassSingleton INSTANCE = new StaticInnerClassSingleton(); &#125; //私有的构造方法 private StaticInnerClassSingleton() &#123; &#125; //对外提供获取实例的静态方法 public static final StaticInnerClassSingleton getInstance() &#123; return SingletonHolder.INSTANCE; &#125; &#125; 懒汉式 1234567891011121314public class Singleton &#123; //定义实例 private static Singleton instance; //私有构造方法 private Singleton()&#123;&#125; //对外提供获取实例的静态方法 public static Singleton getInstance() &#123; //在对象被使用的时候才实例化 if (instance == null) &#123; instance = new Singleton(); &#125; return instance; &#125; &#125; 这种懒汉式单例其实还存在一个问题，那就是线程安全问题。在多线程情况下，有可能两个线程同时进入if语句中，这样，在两个线程都从if中退出的时候就创建了两个不一样的对象。 懒汉，就是不会提前把实例创建出来，将类对自己的实例化延迟到第一次被引用的时候。getInstance方法的作用是希望该对象在第一次被使用的时候被new出来。 线程安全的懒汉式 1234567891011121314public class SynchronizedSingleton &#123; //定义实例 private static SynchronizedSingleton instance; //私有构造方法 private SynchronizedSingleton()&#123;&#125; //对外提供获取实例的静态方法,对该方法加锁 public static synchronized SynchronizedSingleton getInstance() &#123; //在对象被使用的时候才实例化 if (instance == null) &#123; instance = new SynchronizedSingleton(); &#125; return instance; &#125; &#125; 遗憾的是，他效率很低，因为99%情况下不需要同步。（因为上面的synchronized的加锁范围是整个方法，该方法的所有操作都是同步进行的，但是对于非第一次创建对象的情况，也就是没有进入if语句中的情况，根本不需要同步操作，可以直接返回instance。） 双重校验锁 123456789101112131415161718public class Singleton &#123; private static Singleton singleton; private Singleton() &#123; &#125; public static Singleton getSingleton() &#123; if (singleton == null) &#123; synchronized (Singleton.class) &#123; if (singleton == null) &#123; singleton = new Singleton(); &#125; &#125; &#125; return singleton; &#125; &#125; 线程A发现变量没有被初始化, 然后它获取锁并开始变量的初始化。 由于某些编程语言的语义，编译器生成的代码允许在线程A执行完变量的初始化之前，更新变量并将其指向部分初始化的对象。 线程B发现共享变量已经被初始化，并返回变量。由于线程B确信变量已被初始化，它没有获取锁。如果在A完成初始化之前共享变量对B可见（这是由于A没有完成初始化或者因为一些初始化的值还没有穿过B使用的内存(缓存一致性)），程序很可能会崩溃。 在J2SE 1.4或更早的版本中使用双重检查锁有潜在的危险，有时会正常工作（区分正确实现和有小问题的实现是很困难的。取决于编译器，线程的调度和其他并发系统活动，不正确的实现双重检查锁导致的异常结果可能会间歇性出现。重现异常是十分困难的。） 在J2SE 5.0中，这一问题被修正了。volatile关键字保证多个线程可以正确处理单件实例 子主题 双重校验锁优化 1234567891011121314151617public class VolatileSingleton &#123; private static volatile VolatileSingleton singleton; private VolatileSingleton() &#123; &#125; public static VolatileSingleton getSingleton() &#123; if (singleton == null) &#123; synchronized (VolatileSingleton.class) &#123; if (singleton == null) &#123; singleton = new VolatileSingleton(); &#125; &#125; &#125; return singleton; &#125; &#125; 12345678910111213141516171819202122232425class FinalWrapper&lt;T&gt; &#123; public final T value; public FinalWrapper(T value) &#123; this.value = value; &#125; &#125; public class FinalSingleton &#123; private FinalWrapper&lt;FinalSingleton&gt; helperWrapper = null; public FinalSingleton getHelper() &#123; FinalWrapper&lt;FinalSingleton&gt; wrapper = helperWrapper; if (wrapper == null) &#123; synchronized (this) &#123; if (helperWrapper == null) &#123; helperWrapper = new FinalWrapper&lt;FinalSingleton&gt;(new FinalSingleton()); &#125; wrapper = helperWrapper; &#125; &#125; return wrapper.value; &#125; &#125; 防止序列化方式 123456789101112131415161718192021222324package com.hollis; import java.io.Serializable; /** * Created by hollis on 16/2/5. * 使用双重校验锁方式实现单例 */ public class Singleton implements Serializable&#123; private volatile static Singleton singleton; private Singleton ()&#123;&#125; public static Singleton getSingleton() &#123; if (singleton == null) &#123; synchronized (Singleton.class) &#123; if (singleton == null) &#123; singleton = new Singleton(); &#125; &#125; &#125; return singleton; &#125; private Object readResolve() &#123; return singleton; &#125; &#125; 抽象工厂模式 建造者模式 工厂模式 原型模式 结构型模式 适配器模式 桥接模式 组合模式 装饰模式 外观模式 享元模式 代理模式 行为型模式 模板方法模式 命令模式 迭代器模式 观察者模式 中介者模式 解析器模式（Interpreter模式） 状态模式 策略模式 责任链模式 访问者模式 使用常用设计模式 单例 策略 工厂 适配器 责任链 实现AOP 实现IOC 不用synchronized和lock，实现线程安全的单例模式 nio和reactor设计模式 网络编程 tcp、udp、http、https等常用协议 三次握手协议 四次关闭 流量控制和拥塞控制 OSI七层模型 tcp粘包和拆包 http/1.0 http/1.1 http/2 之间的区别 Java RMI Socket HttpClient cookie与session cookie被禁用，如何实现session 用Java写一个简单的静态文件的HTTP服务器 实现客户端缓存功能，支持返回304 实现可并发下载一个文件 使用线程池处理客户端请求 使用nio处理客户端请求 支持简单的rewrite规则 上述功能在实现的时候需要满足“开闭原则” 了解nginx和apache服务器特性并搭建一个对应的服务器 用Java实现FTP、SMTP协议 进程间通讯的方式 什么是CDN？如果实现 什么是DNS 反向代理 框架知识 Servlet线程安全问题 Servlet中的filter和listener Hibernate的缓存机制 Hibernate的懒加载 Spring Bean的初始化 Spring的AOP原理 自己实现Spring的IOC Spring MVC Spring Boot2.0 Spring Boot的starter原理，自己实现一个starter Spring Security 应用服务器 JBoss tomcat jetty Weblogic 工具 git&amp;svn maven&amp;gradle 高级 新技术 Java8 lambda表达式 Stream API Java9 Jigsaw Jshell Reactive Streams Java10 局部变量类型推断 G1的并行Full GC ThreadLocal握手机制 响应式编程 Spring Boot 2.0 线上问题分析 dump获取 线程Dump 内存Dump gc dump分析 分析死锁 分析内存泄漏 自己编写各种outofmemory,stackoverflow程序 HeapOutOfMemory、 Young OutOfMemory、MethodArea OutOfMemory、ConstantPool OutOfMemory、DirectMemory OutOfMemory、Stack OutOfMemory Stack OverFlow 常见问题解决思路 内存溢出 线程死锁 类加载冲突 使用工具尝试解决问题，并总结 当一个Java程序响应很慢时如何查找问题 当一个Java程序频繁FullGC时如何解决问题 如何查看垃圾回收日志 当一个Java应用发生OutOfMemory时如何解决 如何判断是否出现死锁 如何判断是否存在内存泄漏 性能优化 使用单例 使用Future模式 使用线程池 选择就绪 减少上下文切换 减小锁粒度 数据压缩 结果缓存 编译原理知识 编译与反编译 Java代码的编译与反编译 Java的反编译工具 词法分析，语法分析（LL算法，递归下降算法，LR算法），语义分析，运行时环境，中间代码，代码生成，代码优化 操作系统知识 Linux的常用命令 进程同步 缓冲区溢出 分段和分页 虚拟内存与主存 数据库知识 MySql执行引擎 数据库建模三范式 Mysql执行计划 如何查看执行计划 如何根据执行计划进行sql优化 SQL优化 事务 事务的隔离级别 事务能不能实现锁的功能 数据库锁 行锁 表锁 使用数据库实现乐观锁 数据库主备搭建 binlog 内存数据库 常用的nosql数据库 redis memcached 使用数据库锁、NoSql实现分布式锁 性能调优 数据结构和算法知识 简单的数据结构 栈 队列 链表 数组 哈希表 树 二叉树 字典树 平衡树 排序树 B树 B+树 R树 多路树 红黑树 排序算法 各种排序算法和时间复杂度 深度优先和广度优先搜索 全排列 贪心算法 KMP算法 hash算法 一致性hash算法 海量数据处理 大数据知识 Zookeeper Solr，Lucene，ElasticSearch Storm，流式计算，了解Spark，S4 Hadoop，离线计算 分布式日志收集flume，kafka，logstash 数据挖掘，mahout 网络安全 什么是XSS 什么是CSRF 什么是注入攻击 什么是文件上传漏洞 加密与解密 什么是DOS攻击和DDOS攻击 SSL，TLS，HTTPS 如何通过Hash碰撞进行DOS攻击 用openssl签一个证书部署到apache或nginx 架构 分布式 分布式事务 rpc 分布式数据库 分布式文件系统 分布式缓存 微服务 SOA 康威定律 ServiceMesh Docker &amp; Kubernets Spring Boot Spring Cloud 高并发 分库分表 CDN技术 消息队列 ActiveMQ 监控 监控什么 CPU 内存 磁盘IO 网络IO 服务监控 监控手段 进程监控 语义监控 机器资源监控 数据波动 监控数据采集 日志 埋点 Dapper 负载均衡 DNS CDN 数据一致性 扩展 云计算 IaaS SaaS PaaS 虚拟化技术 Serverlsess openstack 搜索引擎 Solr Lucene Nutch Elasticsearch 权限管理-必须的 Shiro 区块链 基础 哈希算法 Merkle树 公钥密码算法 共识算法 Raft协议 Paxos 算法与 Raft 算法 拜占庭问题与算法 消息认证码与数字签名 应用 比特币 以太坊 超级账本 人工智能 基础 数学基础 机器学习 人工神经网络 深度学习 应用场景 框架 TensorFlow DeepLearning4J 其他语言 Groovy Python Go NodeJs Swift Rust 书籍推荐 《深入理解Java虚拟机》 《Effective Java》 《深入分析Java Web技术内幕》 《大型网站技术架构》 《代码整洁之道》 《Head First设计模式》 《maven实战》 《区块链原理、设计与应用》 《Java并发编程实战》 《鸟哥的Linux私房菜》 《从Paxos到Zookeeper》 《架构即未来》 【1】简书主页·share猿【2】掘金主页·share猿【3】JavaGuide·Snailclimb 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"},{"name":"指导思想","slug":"指导思想","permalink":"https://lywlefan.github.io/tags/指导思想/"}]},{"title":"微服务架构的理论基础 - 康威定律","date":"2019-06-04T16:00:00.000Z","path":"2019/06/05/软件研发/后端/指导思想/java/微服务架构的理论基础 - 康威定律/","text":"概述&emsp;&emsp;关于微服务的介绍，可以参考微服务那点事。 &emsp;&emsp;微服务是最近非常火热的新概念，大家都在追，也都觉得很对，但是似乎没有很充足的理论基础说明这是正确的，给人的感觉是 不明觉厉 。前段时间看了Mike Amundsen 《远距离条件下的康威定律——分布式世界中实现团队构建》（是Design RESTful API的作者）在InfoQ上的一个分享，觉得很有帮助，结合自己的一些思考，整理了该演讲的内容。 &emsp;&emsp;可能出乎很多人意料之外的一个事实是，微服务很多核心理念其实在半个世纪前的一篇文章中就被阐述过了，而且这篇文章中的很多论点在软件开发飞速发展的这半个世纪中竟然一再被验证，这就是康威定律（Conway’s Law）。 &emsp;&emsp;在康威的这篇文章中，最有名的一句话就是： Organizations which design systems are constrained to produce designs which are copies of the communication structures of these organizations. - Melvin Conway(1967) &emsp;&emsp;中文直译大概的意思就是：设计系统的组织，其产生的设计等同于组织之内、组织之间的沟通结构。看看下面的图片（来源于互联网，侵删），再想想Apple的产品、微软的产品设计，就能形象生动的理解这句话。 &emsp;&emsp;用通俗的说法就是：组织形式等同系统设计。 &emsp;&emsp;这里的系统按原作者的意思并不局限于软件系统。据说这篇文章最初投的哈佛商业评论，结果程序员屌丝的文章不入商业人士的法眼，无情被拒，康威就投到了一个编程相关的杂志，所以被误解为是针对软件开发的。最初这篇文章显然不敢自称定律（law），只是描述了作者自己的发现和总结。后来，在Brooks Law著名的人月神话中，引用这个论点，并将其“吹捧”成了现在我们熟知“康威定律”。 康威定律详细介绍&emsp;&emsp;Mike从他的角度归纳这篇论文中的其他一些核心观点，如下： 第一定律：Communication dictates design（组织沟通方式会通过系统设计表达出来） 第二定律：There is never enough time to do something right, but there is always enough time to do it over（时间再多一件事情也不可能做的完美，但总有时间做完一件事情） 第三定律：There is a homomorphism from the linear graph of a system to the linear graph of its design organization（线型系统和线型组织架构间有潜在的异质同态特性） 第四定律： The structures of large systems tend to disintegrate during development, qualitatively more so than with small systems（大的系统组织总是比小系统更倾向于分解） 一.人是复杂社会动物&emsp;&emsp;第一定律：Communication dictates design（组织沟通方式会通过系统设计表达出来） &emsp;&emsp;组织的沟通和系统设计之间的紧密联系，在很多别的领域有类似的阐述。对于复杂的系统，聊设计就离不开聊人与人的沟通，解决好人与人的沟通问题，才能有一个好的系统设计。相信几乎每个程序员都读过的《人月神话》（1975年，感觉都是老古董了，经典的就是经得起时间考验）里面许多观点都和这句话有异曲同工之妙。 &emsp;&emsp;比如《人月神话》中最著名的一句话就是 Adding manpower to a late software project makes it later –Fred Brooks, (1975) &emsp;&emsp;Boss们都听到了吗？为了赶进度加程序员就像用水去灭油锅里的火一样（无奈大家还是前赴后继）。 &emsp;&emsp;为什么？人月神话也给出了很简洁的答案：沟通成本 = n(n-1)/2，沟通成本随着项目或者组织的人员增加呈指数级增长。是的，项目管理这个算法的复杂度是O(n^2)。举个例子 5个人的项目组，需要沟通的渠道是 5*(5–1)/2 = 10 15个人的项目组，需要沟通的渠道是15*(15–1)/2 = 105 50个人的项目组，需要沟通的渠道是50*(50–1)/2 = 1,225 150个人的项目组，需要沟通的渠道是150*(150–1)/2 = 11,175 &emsp;&emsp;所以知道为什么互联网创业公司都这么小了吧，必须小啊，不然等CEO和所有人讲一遍创业的想法后，风投的钱都烧完了。 &emsp;&emsp;Mike还举了一个非常有意思的理论，叫“Dunbar Number”，这是一个叫Dunbar（废话）生物学家在1992年最早提出来的。最初，他发现灵长类的大脑容量和其对应的族群大小有一定关联，进而推断出人类的大脑能维系的关系的一些有趣估计。举例来说 亲密（intimate）朋友: 5 信任（trusted）朋友: 15 酒肉（close）朋友: 35 照面（casual）朋友: 150 &emsp;&emsp;是不是和上面的沟通成本的数字很貌似有关联？是的，我们的大脑智力只能支持我们维系这么多的关系。（大家都知道这不是程序猿擅长的领域，在开发团队里，这个值应该更小，估计和猿差不多 -_-凸 ） &emsp;&emsp;沟通的问题，会带来系统设计的问题，进而影响整个系统的开发效率和最终产品结果。 二.一口气吃不成胖子，先搞定能搞定的&emsp;&emsp;第二定律：There is never enough time to do something right, but there is always enough time to do it over（时间再多一件事情也不可能做的完美，但总有时间做完一件事情） Eric Hollnagel是敏捷开发社区的泰斗之一，在他《Efficiency-Effectiveness Trade Offs》 一书中解释了类似的论点。 &emsp;&emsp;系统越做越复杂，功能越来越多，外部市场的竞争越来越剧烈，投资人的期待越来越高。但人的智力是有上限的，即使再牛逼的人，融到钱再多也不一定招到足够多合适的人。对于一个巨复杂的系统，我们永远无法考虑周全。Eric认为，这个时候最好的解决办法竟然是——“破罐子破摔”。 &emsp;&emsp;其实我们在日常开发中也经常碰到。产品经理的需求太复杂了？适当忽略一些细节，先抓主线。产品经理的需求太多了？放弃一些功能。 &emsp;&emsp;据说Eric被一家航空公司请去做安全咨询顾问，复杂保证飞机飞行系统的稳定性和安全性。Eric认为做到安全有两种方式： 常规的安全指的是尽可能多的发现并消除错误的部分，达到绝对安全，这是理想。 另一种则是弹性安全，即使发生错误，只要及时恢复，也能正常工作，这是现实。 &emsp;&emsp;对于飞机这样的复杂系统，再牛逼的人也无法考虑到漏洞的方方面面，所以Eric建议放弃打造完美系统的想法，而是通过不断的试飞，发现问题，确保问题发生时，系统能自动复原即可，而不追求飞行系统的绝对正确和安全。 &emsp;&emsp;下面的图很好的解释了这个过程： &emsp;&emsp;听着很耳熟不是吗？这不就是 持续集成 和敏捷开发吗？的确就是。 &emsp;&emsp;另一方面，这和互联网公司维护的分布式系统的弹性设计也是一个道理。对于一个分布式系统，我们几乎永远不可能找到并修复所有的bug，单元测试覆盖1000%也没有用，错误流淌在分布式系统的血液里。解决方法不是消灭这些问题，而是容忍这些问题，在问题发生时，能自动回复，微服务组成的系统，每一个微服务都可能挂掉，这是常态，我们只有有足够的冗余和备份即可。即所谓的 弹性设计（Resilience） 或者叫高可用设计（High Availability）。 三.种瓜得瓜，做独立自治的字系统减少沟通成本&emsp;&emsp;第三定律：There is a homomorphism from the linear graph of a system to the linear graph of its design organization（线型系统和线型组织架构间有潜在的异质同态特性） &emsp;&emsp;这是康威第一定律组织和设计间内在关系的一个具体应用。更直白的说，你想要什么样的系统，就搭建什么样的团队。如果你的团队分成前端团队，Java后台开发团队，DBA团队，运维团队，你的系统就会长成下面的样子： &emsp;&emsp;相反，如果你的系统是按照业务边界划分的，大家按照一个业务目标去把自己的模块做出小系统，小产品的话，你的大系统就会长成下面的样子，即微服务的架构 &emsp;&emsp;微服务的理念团队间应该是 inter-operate, not integrate 。inter-operate是定义好系统的边界和接口，在一个团队内全栈，让团队自治，原因就是因为如果团队按照这样的方式组建，将沟通的成本维持在系统内部，每个子系统就会更加内聚，彼此的依赖耦合能变弱，跨系统的沟通成本也就能降低。 四.合久必分，分而治之&emsp;&emsp;第四定律： The structures of large systems tend to disintegrate during development, qualitatively more so than with small systems（大的系统组织总是比小系统更倾向于分解） &emsp;&emsp;前面说了，人是复杂的社会动物，人与人的通过非常复杂。但是当我们面对复杂系统时，又往往只能通过增加人力来解决。这时，我们的组织一般是如何解决这个沟通问题的呢？Divide and conquer,分而治之。大家看看自己的公司的组织，是不是一个一线经理一般都是管理15个人以下的？二线经理再管理更少的一线？三线再管理更少的，以此类推。（这里完全没有暗示开发经理比程序猿更难管理） &emsp;&emsp;所以，一个大的组织因为沟通成本/管理问题，总为被拆分成一个个小团队。 创业的想法太好了，反正风投钱多，多招点程序猿 人多管不过来啊，找几个经理帮我管，我管经理 最后， 康威定律 告诉我们组织沟通的方式会在系统设计上有所表达，每个经理都被赋予一定的职责去做大系统的某一小部分，他们和大系统便有了沟通的边界，所以大的系统也会因此被拆分成一个个小团队负责的小系统（微服务是一种好的模式） 康威定律如何解释微服务的合理性&emsp;&emsp;了解了康威定律是什么，再来看看他如何在半个世纪前就奠定了微服务架构的理论基础。 人与人的沟通是非常复杂的，一个人的沟通精力是有限的，所以当问题太复杂需要很多人解决的时候，我们需要做拆分组织来达成对沟通效率的管理 组织内人与人的沟通方式决定了他们参与的系统设计，管理者可以通过不同的拆分方式带来不同的团队间沟通方式，从而影响系统设计 如果子系统是内聚的，和外部的沟通边界是明确的，能降低沟通成本，对应的设计也会更合理高效 复杂的系统需要通过容错弹性的方式持续优化，不要指望一个大而全的设计或架构，好的架构和设计都是慢慢迭代出来的 &emsp;&emsp;带来的具体的实践建议是： 我们要用一切手段提升沟通效率，比如slack，github，wiki。能2个人讲清楚的事情，就不要拉更多人，每个人每个系统都有明确的分工，出了问题知道马上找谁，避免踢皮球的问题。 通过MVP的方式来设计系统，通过不断的迭代来验证优化，系统应该是弹性设计的。 你想要什么样的系统设计，就架构什么样的团队，能扁平化就扁平化。最好按业务来划分团队，这样能让团队自然的自治内聚，明确的业务边界会减少和外部的沟通成本，每个小团队都对自己的模块的整个生命周期负责，没有边界不清，没有无效的扯皮，inter-operate, not integrate。 做小而美的团队，人多会带来沟通的成本，让效率下降。亚马逊的Bezos有个逗趣的比喻，如果2个披萨不够一个团队吃的，那么这个团队就太大了。事实上一般一个互联网公司小产品的团队差不多就是7，8人左右（包含前后端测试交互用研等，可能身兼数职）。 &emsp;&emsp; 再对应下衡量微服务的标准，我们很容易会发现他们之间的密切关系： 分布式服务组成的系统 按照业务而不是技术来划分组织 做有生命的产品而不是项目 Smart endpoints and dumb pipes（我的理解是强服务个体和弱通信） 自动化运维（DevOps） 容错 快速演化 【1】简书主页·share猿【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"},{"name":"指导思想","slug":"指导思想","permalink":"https://lywlefan.github.io/tags/指导思想/"}]},{"title":"常用工具收集","date":"2019-05-27T16:00:00.000Z","path":"2019/05/28/软件研发/工具/常用工具收集/","text":"工欲善其事，必先利器！ 常用工具总结windows必备神器解放双手神器 Wox-解放双手 文档编辑工具markdown typora-超级好用而且免费 inspire-收费好用 常用小工具GIF图生成 LICEcap(比较好用的生成gif的小工具) Mac文档编辑工具markdown Ulysses Linux文档编辑工具markdown typora-超级好用而且免费 ​ 【1】简书主页·share猿【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"工具","slug":"工具","permalink":"https://lywlefan.github.io/tags/工具/"},{"name":"收藏","slug":"收藏","permalink":"https://lywlefan.github.io/tags/收藏/"}]},{"title":"常用工具收集","date":"2019-05-27T16:00:00.000Z","path":"2019/05/28/软件研发/工具/开发工具/常用开发工具导航/","text":"工欲善其事，必先利器！ 前端工具IDE抓包工具 Charles 后端工具​ 【1】简书主页·share猿【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"工具","slug":"工具","permalink":"https://lywlefan.github.io/tags/工具/"},{"name":"收藏","slug":"收藏","permalink":"https://lywlefan.github.io/tags/收藏/"}]},{"title":"idea常用快捷键总结","date":"2019-05-16T16:00:00.000Z","path":"2019/05/17/软件研发/后端/开发IDE/java/idea/idea常用快捷键总结/","text":"工欲善其事，必先利器！ 必需会的快捷键 提出选中内容为局部变量:Ctrl+Alt+V 选中代码的情况下,包裹代码(try):Ctrl+alt+T 删除类中无用的import包:Ctrl + Alt + O 格式化代码:Ctrl+Alt+L 抽取方法:Ctrl+Alt+m(该快捷键可以快速抽取方法) 界面相关快捷键 快速切换方案:Ctrl+~ 展开/折叠项目侧边栏:Alt+1 打开设置界面:Ctrl + Alt + S 扩展成一个窗口：shift+ctrl+f12 代码提示相关快捷键 代码提示:Ctrl+空格 代码插入:Alt+enter 基础代码补全:Ctrl + Space 智能代码提示:Ctrl + Shift + Space 代码浏览相关快捷键 折叠代码:Ctrl + - (Ctrl+Shift+-为所有) 展开代码:Ctrl + + 代码移动相关快捷键 移动方法顺序:Ctrl+Shift+↑/↓ 光标控制相关快捷键 光标定位到上个浏览处:Ctrl(shift)+alt+left 光标定位到下一个浏览出:Ctrl(shift)+Alt+right 光标移动到下一个方法开始处:alt+down 光标移动到上一个方法开始处:alt+up 光标移动到前一个单词处:Ctrl+left 光标移动到后一个单词处:Ctrl+right 光标在代码块之间移动:Ctrl+[/] 快速定位到下一个错误和警告处:F2(加Shift键，定位到上一个错误处) 光标跳出括号(单引号等其他的类似):shift+相应符号 选中相关的快捷键 连续选中文件中相同的内容:Alt+j 按语法选中代码:Ctrl+W (连续按会有其他效果，加Shift键，产生反向选中效果) 多行选择:Ctrl+Shift+← 新建相关快捷键 新建类文件:Alt+insert(光标放到文件夹) 文件切换 查看最近打开的文件:Ctrl+E 切换最近文件:Ctrl+Tab 编辑窗口的切换:Alt+left/right 查找相关快捷键 当前文件查找:Ctrl+F 当前文件替换:Ctrl+R 当前项目查找:Ctrl+shift+F 当前项目替换:Ctrl+Shift+R 查找文件:Ctrl+shift+N 查找类文件:ctrl+shift+alt+n 全局查找:shift+shift 删除和插入相关快捷键 删除当前行:Ctrl+Y 按单个单词删除:Ctrl+Backspace 复制光标所在的行:Ctrl+D 向下插入一行:shift+enter 向上插入一行:alt+shift+enter 当前行向上移动:ctrl+shift+up/down 大小写转换快捷键 大小写转换快捷键:Ctrl+shift+U 版本控制相关的快捷键 提交到本地仓库备注的快捷键:Ctrl+k 提交到本地仓库:Ctrl+Alt+K push的快捷键:Ctrl+shift+K（窗口处理的时候ctrl+enter可以快速提交） pull的快捷键:Ctrl+T 【1】简书主页·share猿【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"},{"name":"开发IDE","slug":"开发IDE","permalink":"https://lywlefan.github.io/tags/开发IDE/"}]},{"title":"JAR包如何取工程外部文件","date":"2019-05-14T16:00:00.000Z","path":"2019/05/15/软件研发/后端/框架/java/spring/JAR包如何取工程外部文件/","text":"问题起源&emsp;&emsp;在开发支付stater的过程中会用到证书，而证书我们一般配置在工程项目中，那么我们自己开发的stater如何才能取到工程项目中的证书文件那？？？ 问题深究分解问题&emsp;&emsp;要想解决这个问题，我们要明确 【1】简书主页·share猿【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"spring","slug":"spring","permalink":"https://lywlefan.github.io/tags/spring/"},{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"},{"name":"框架","slug":"框架","permalink":"https://lywlefan.github.io/tags/框架/"}]},{"title":"RestTemplate常见问题的解决办法.md","date":"2019-05-14T16:00:00.000Z","path":"2019/05/15/软件研发/后端/框架/java/spring/RestTemplate常见问题的解决办法/","text":"问题汇总 用restTemplate请求域名或着ip一直报No instances available的错 restTemplate的post请求报415错 问题处理用restTemplate请求域名或着ip一直报No instances available的错 错误描述 123java.lang.IllegalStateException: No instances available for www.baidu.comat org.springframework.cloud.netflix.ribbon.RibbonLoadBalancerClient.execute(RibbonLoadBalancerClient.java:79) ~[spring-cloud-netflix-core-1.1.0.RELEASE.jar:1.1.0.RELEASE] at org.springframework.cloud.client.loadbalancer.LoadBalancerInterceptor.intercept(LoadBalancerInterceptor.java:46) ~[spring-cloud-commons-1.1.0.RELEASE.jar:1.1.0.RELEASE] at org.springframework.http.client.InterceptingClientHttpRequest$InterceptingRequestExecution.execute(InterceptingClientHttpRequest.java:86) ~[spring-web-4.3.10.RELEASE.jar:4.3.10.RELEASE] at org.springframework.http.client.InterceptingClientHttpRequest.executeInternal(InterceptingClientHttpRequest.java:70) ~[spring-web-4.3.10.RELEASE.jar:4.3.10.RELEASE] at ..... &emsp;&emsp;查看错误的跟踪链发现,自动注入的restTemplate中加入了cloud.netflix*包下面的interceptor, &emsp;&emsp;所以默认会通过RibbonLoadBalancerClient去查找注册中心的instances, &emsp;&emsp;如上面的代码，www.baidu.com肯定不存在，所以就报错了。 错误解决 &emsp;&emsp;重新实例化一个RestTemplate。 123456789101112131415@Configurationpublic class MyConfiguration &#123; @LoadBalanced @Bean RestTemplate loadBalanced() &#123; return new RestTemplate(); &#125; @Primary @Bean RestTemplate restTemplate() &#123; return new RestTemplate(); &#125;&#125; restTemplate的post请求报415错 错误描述 &emsp;&emsp;报错415 问具体解决 1234567HttpHeaders headers = new HttpHeaders();MediaType type = MediaType.parseMediaType(\"application/json;\");headers.setContentType(type);headers.add(\"Accept\", MediaType.APPLICATION_JSON.toString());JSONObject jsonObj = JSON.parseObject(JSON.toJSONString(payParams));HttpEntity&lt;String&gt; formEntity = new HttpEntity&lt;String&gt;(jsonObj.toString(), headers);restTemplate.postForObject(bestPayProperties.getBestPayUrl(),formEntity,String.class); 【1】简书主页·share猿【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"spring","slug":"spring","permalink":"https://lywlefan.github.io/tags/spring/"},{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"},{"name":"框架","slug":"框架","permalink":"https://lywlefan.github.io/tags/框架/"}]},{"title":"不用spring如何实例化一个bean","date":"2019-05-13T16:00:00.000Z","path":"2019/05/14/软件研发/后端/框架/java/spring/不用spring如何实例化一个bean/","text":"问题源起&emsp;&emsp;为什么写这么一篇文章那？主要还是源自最近在写支付的starter的过程中遇到的一个问题，我们知道在支付的过程中需要去配置一些相关的参数，因为是starter我们一般是通过配置文件的方式进行配置，引用我们stater的工程会通过yml文件中配置的属性把这些值给我们。 &emsp;&emsp;那么我想在stater里面取到这些值该如何去做那？？我直接new一个配置类对象但是却取不到，因此我们就在思考spring到底是如何实例化bean的？？他对bean做了什么？？如果不用spring的注解我们又该如何去实例化我们的bean那？带着这些问题我开始了我的解惑之旅。。。 问题深究提出问题，分解问题12345678910111213141516@AllArgsConstructor@RestController@RequestMapping(\"/api/v1/app/\")public class AppController extends BaseController &#123; @Autowired AppBannerService appBannerService; @RequestMapping(value = \"index\", method = RequestMethod.POST) public Result index(HttpServletRequest request,@RequestBody @Valid AppBannerAreaCode appBannerAreaCode) &#123; Map&lt;String,Object&gt; appMessage=new HashMap&lt;&gt;(); String appId=CommonUtils.getAppIdFromHeader(request); List&lt;AppBanner&gt; banners=appBannerService.getBannersByAppIdAndCode(appId,appBannerAreaCode.getProvinceCode()); return new Result(banners); &#125;&#125; &emsp;&emsp;上面的controller是我用日常开发常用的，AppBannerService是我们定义的业务接口，接口有实现类，我们只需要简单的注解就可以直接调用接口的方法了。 spring如何实例化bean？？ spring实例化方式有那些？？ 容器是如何实例化的？？ 我们假如不用这个注解如何去调这个接口那？？&emsp;&emsp;接下来我们就围绕以上两个问题进行展开。 解决各个问题spring实例化方式有那些？？&emsp;&emsp;软件开发到最后的最高境界就是制定标准，然后严格安装标准去开发和迭代。我个人认为spring也是如此，spring给自己定义了标准的四种实例化方式，我们在日常开发中就可以通过这四种实例化方式进行实例化，下面让我们一起细究一下这四种实例化方式： setter方法实例化 主类 1234567891011121314151617181920212223242526public interface IUserDao &#123; void addUser(); void delUser(); void updateUser(); &#125; public class UserDaoImpl implements IUserDao &#123; public void addUser() &#123; System.out.println(\"addUser方法被调用了\"); &#125; public void delUser() &#123; System.out.println(\"delUser方法被调用了\"); &#125; public void updateUser() &#123; System.out.println(\"updateUser方法被调用了\"); &#125; &#125; public class UserAction &#123; private IUserDao dao; //dao是一个依赖对象,要由springg进行管理,要生成 get set 方法 public void execute()&#123; dao.addUser(); dao.updateUser(); dao.delUser(); &#125; &#125; 配置文件 12345//配置文件&lt;bean name=\"userAction_name\" class=\"cat.action.UserAction\" &gt;&lt;property name=\"dao\" ref=\"userDao_name\" /&gt; //引用的是下面的名称&lt;/bean&gt; &lt;bean name=\"userDao_name\" class=\"cat.dao.UserDaoImpl\" /&gt; 测试 1234 //测试ClassPathXmlApplicationContext ctx=new ClassPathXmlApplicationContext(\"beans.xml\");UserAction action=(UserAction)ctx.getBean(\"userAction_name\");action.execute(); 构造函数 主类 123456789101112131415161718192021222324public class UserAction &#123; //public UserAction()&#123;&#125; 可以保保留一个无参的构造函数 //这是几个依赖对象,不用生成get set方法了 private UserInfo user; private String school; private IUserDao dao; //希望Spring 由构造函数注入依赖对象 public UserAction(IUserDao dao,UserInfo user,String school)&#123; this.dao=dao; this.school=school; this.user=user; &#125; public void execute()&#123; dao.addUser(); dao.updateUser(); dao.delUser(); System.out.println(user); System.out.println(school);&#125; 配置文件 123456789101112131415161718192021222324//配置文件&lt;bean name=\"userInfo_name\" class=\"cat.beans.UserInfo\" &gt; &lt;property name=\"id\" value=\"1\" /&gt; &lt;property name=\"userName\" value=\"周周\" /&gt; &lt;property name=\"password\" value=\"123\" /&gt; &lt;property name=\"note\" value=\"这是备注\" /&gt;&lt;/bean&gt; &lt;bean name=\"userAction_name\" class=\"cat.action.UserAction\" &gt; &lt;constructor-arg ref=\"userDao_name\" /&gt; &lt;constructor-arg ref=\"userInfo_name\" /&gt; &lt;constructor-arg value=\"哈尔滨师范大学\" /&gt;&lt;/bean&gt; /*也可以指定 索引和 type 属性 , 索引和type 都可以不指定&lt;bean name=\"userAction_name\" class=\"cat.action.UserAction\" &gt;&lt;constructor-arg index=\"0\" ref=\"userDao_name\" type=\"cat.dao.IUserDao\" /&gt; 如果是接口,就不能指定是实现类的类型&lt;constructor-arg index=\"1\" ref=\"userInfo_name\" type=\"cat.beans.UserInfo\" /&gt;&lt;constructor-arg index=\"2\" value=\"哈尔滨师范大学\" /&gt;&lt;/bean&gt;*/ &lt;bean name=\"userDao_name\" class=\"cat.dao.UserDaoImpl\" /&gt; 测试 1234//测试ClassPathXmlApplicationContext ctx=new ClassPathXmlApplicationContext(\"beans.xml\");UserAction action=(UserAction)ctx.getBean(\"userAction_name\");action.execute(); 静态工厂方式 主类 123456789101112131415161718192021//工厂,用来生成dao的实现类public class UserDaoFactory &#123;public static IUserDao createUserDaoInstance()&#123; return new UserDaoOracleImpl(); &#125;&#125; public class UserAction &#123; private IUserDao dao;//使用工厂方式注值,也要生成set方法 public void execute()&#123; dao.addUser(); dao.updateUser(); dao.delUser();&#125; public void setDao(IUserDao dao) &#123; this.dao = dao;&#125; &#125; 配置文件 123456//配置文件 &lt;bean name=\"userAction_name\" class=\"cat.action.UserAction\" &gt;&lt;property name=\"dao\" ref=\"userDao_name\" /&gt;&lt;/bean&gt; &lt;bean name=\"userDao_name\" class=\"cat.dao.UserDaoFactory\" factory-method=\"createUserDaoInstance\" /&gt; 测试 1234//测试ClassPathXmlApplicationContext ctx=new ClassPathXmlApplicationContext(\"beans.xml\");UserAction action=(UserAction)ctx.getBean(\"userAction_name\");action.execute(); 实例工厂 主类 1234567//工厂 =&gt;public class UserDaoFactory &#123;//这个方法不是静态的public IUserDao createUserDaoInstance()&#123; return new UserDaoOracleImpl(); &#125;&#125; 配置文件 1234567//配置文件 &lt;bean name=\"userAction_name\" class=\"cat.action.UserAction\" &gt;&lt;property name=\"dao\" ref=\"userDao_name\" /&gt;&lt;/bean&gt; &lt;bean name=\"userDaoFactory_name\" class=\"cat.dao.UserDaoFactory\" /&gt;&lt;bean name=\"userDao_name\" factory-bean=\"userDaoFactory_name\" factory-method=\"createUserDaoInstance\" /&gt; 测试 【1】简书主页·share猿【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"spring","slug":"spring","permalink":"https://lywlefan.github.io/tags/spring/"},{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"},{"name":"框架","slug":"框架","permalink":"https://lywlefan.github.io/tags/框架/"}]},{"title":"如何写一个stater","date":"2019-05-12T16:00:00.000Z","path":"2019/05/13/软件研发/后端/框架/java/spring/如何写一个stater/","text":"目标刻在岩石上，方法写在沙滩上. 命名规范&emsp;&emsp;不要使用spring-boot开头的，以避免将来spring-boot官方使用你的starter而重名。 正例：xxxx-spring-boot-starter 反例：spring-boot-starter-xxxx 定功能&emsp;&emsp;你所定义的starter需要有自己的独特功能，比如spring-boot-starter-web 提供的springmvc相关的自动装配，内嵌tomcat以及相关依赖，那们你自己定义的starter也是需要界定好自己的功能。举个列子，比如要写一个支付的stater： 支付 支付通知 支付查询 退款 退款查询 退款通知 项目依赖 【1】简书主页·share猿【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"spring","slug":"spring","permalink":"https://lywlefan.github.io/tags/spring/"},{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"},{"name":"框架","slug":"框架","permalink":"https://lywlefan.github.io/tags/框架/"}]},{"title":"自定义SPEL的注解","date":"2019-05-12T16:00:00.000Z","path":"2019/05/13/软件研发/后端/框架/java/spring/自定义SPEL的注解/","text":"目标刻在岩石上，方法写在沙滩上. 【1】简书主页·share猿【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"spring","slug":"spring","permalink":"https://lywlefan.github.io/tags/spring/"},{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"},{"name":"框架","slug":"框架","permalink":"https://lywlefan.github.io/tags/框架/"}]},{"title":"初始Docker","date":"2018-07-18T16:00:00.000Z","path":"2018/07/19/软件研发/后端/容器管理/docker/初始Docker/","text":"【1】简书主页·share猿 【2】掘金主页·share猿 【3】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"容器管理","slug":"容器管理","permalink":"https://lywlefan.github.io/tags/容器管理/"},{"name":"Docker","slug":"Docker","permalink":"https://lywlefan.github.io/tags/Docker/"}]},{"title":"初始Docker","date":"2018-07-18T16:00:00.000Z","path":"2018/07/19/软件研发/后端/容器管理/Kubernetes/初始Kubernetes/","text":"【1】简书主页·share猿 【2】掘金主页·share猿 【3】Kubernetes官方文档 【4】Kubernetes官方文档APi 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"容器管理","slug":"容器管理","permalink":"https://lywlefan.github.io/tags/容器管理/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://lywlefan.github.io/tags/Kubernetes/"}]},{"title":"Spring Boot配置FastJson报错","date":"2018-05-29T16:00:00.000Z","path":"2018/05/30/软件研发/后端/bug收集桶/java/Lombok初次使用启动项目报错解决/","text":"错误描述123456789101112131415161718192021222324252627282930313233343536373839404142434445464748org.springframework.web.util.NestedServletException: Request processing failed; nested exception is java.lang.IllegalArgumentException: Content-Type cannot contain wildcard type '*' at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1013) ~[spring-webmvc-5.1.6.RELEASE.jar:5.1.6.RELEASE] at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:908) ~[spring-webmvc-5.1.6.RELEASE.jar:5.1.6.RELEASE] at javax.servlet.http.HttpServlet.service(HttpServlet.java:665) ~[javax.servlet-api-4.0.1.jar:4.0.1] at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:882) ~[spring-webmvc-5.1.6.RELEASE.jar:5.1.6.RELEASE] at javax.servlet.http.HttpServlet.service(HttpServlet.java:750) ~[javax.servlet-api-4.0.1.jar:4.0.1] at io.undertow.servlet.handlers.ServletHandler.handleRequest(ServletHandler.java:74) ~[undertow-servlet-2.0.19.Final.jar:2.0.19.Final] at io.undertow.servlet.handlers.FilterHandler.handleRequest(FilterHandler.java:81) ~[undertow-servlet-2.0.19.Final.jar:2.0.19.Final] at io.undertow.servlet.handlers.security.ServletSecurityRoleHandler.handleRequest(ServletSecurityRoleHandler.java:62) ~[undertow-servlet-2.0.19.Final.jar:2.0.19.Final] at io.undertow.servlet.handlers.ServletChain$1.handleRequest(ServletChain.java:68) ~[undertow-servlet-2.0.19.Final.jar:2.0.19.Final] at io.undertow.servlet.handlers.ServletDispatchingHandler.handleRequest(ServletDispatchingHandler.java:36) ~[undertow-servlet-2.0.19.Final.jar:2.0.19.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-2.0.19.Final.jar:2.0.19.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-2.0.19.Final.jar:2.0.19.Final] at io.undertow.servlet.handlers.ServletInitialHandler.dispatchRequest(ServletInitialHandler.java:274) [undertow-servlet-2.0.19.Final.jar:2.0.19.Final] at io.undertow.servlet.handlers.ServletInitialHandler.dispatchToPath(ServletInitialHandler.java:209) [undertow-servlet-2.0.19.Final.jar:2.0.19.Final] at io.undertow.servlet.spec.RequestDispatcherImpl.error(RequestDispatcherImpl.java:502) ~[undertow-servlet-2.0.19.Final.jar:2.0.19.Final] at io.undertow.servlet.spec.RequestDispatcherImpl.error(RequestDispatcherImpl.java:428) ~[undertow-servlet-2.0.19.Final.jar:2.0.19.Final] at io.undertow.servlet.handlers.ServletInitialHandler.handleFirstRequest(ServletInitialHandler.java:331) [undertow-servlet-2.0.19.Final.jar:2.0.19.Final] at io.undertow.servlet.handlers.ServletInitialHandler.access$100(ServletInitialHandler.java:81) [undertow-servlet-2.0.19.Final.jar:2.0.19.Final] at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:138) [undertow-servlet-2.0.19.Final.jar:2.0.19.Final] at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:135) [undertow-servlet-2.0.19.Final.jar:2.0.19.Final] at io.undertow.servlet.core.ServletRequestContextThreadSetupAction$1.call(ServletRequestContextThreadSetupAction.java:48) [undertow-servlet-2.0.19.Final.jar:2.0.19.Final] at io.undertow.servlet.core.ContextClassLoaderSetupAction$1.call(ContextClassLoaderSetupAction.java:43) [undertow-servlet-2.0.19.Final.jar:2.0.19.Final] at io.undertow.servlet.handlers.ServletInitialHandler.dispatchRequest(ServletInitialHandler.java:272) [undertow-servlet-2.0.19.Final.jar:2.0.19.Final] at io.undertow.servlet.handlers.ServletInitialHandler.access$000(ServletInitialHandler.java:81) [undertow-servlet-2.0.19.Final.jar:2.0.19.Final] at io.undertow.servlet.handlers.ServletInitialHandler$1.handleRequest(ServletInitialHandler.java:104) [undertow-servlet-2.0.19.Final.jar:2.0.19.Final] at io.undertow.server.Connectors.executeRootHandler(Connectors.java:364) [undertow-core-2.0.19.Final.jar:2.0.19.Final] at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:830) [undertow-core-2.0.19.Final.jar:2.0.19.Final] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [na:1.8.0_181] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [na:1.8.0_181] at java.lang.Thread.run(Thread.java:748) [na:1.8.0_181]Caused by: java.lang.IllegalArgumentException: Content-Type cannot contain wildcard type '*' at org.springframework.util.Assert.isTrue(Assert.java:118) ~[spring-core-5.1.6.RELEASE.jar:5.1.6.RELEASE] at org.springframework.http.HttpHeaders.setContentType(HttpHeaders.java:915) ~[spring-web-5.1.6.RELEASE.jar:5.1.6.RELEASE] at org.springframework.http.converter.AbstractHttpMessageConverter.addDefaultHeaders(AbstractHttpMessageConverter.java:256) ~[spring-web-5.1.6.RELEASE.jar:5.1.6.RELEASE] at org.springframework.http.converter.AbstractHttpMessageConverter.write(AbstractHttpMessageConverter.java:211) ~[spring-web-5.1.6.RELEASE.jar:5.1.6.RELEASE] at com.alibaba.fastjson.support.spring.FastJsonHttpMessageConverter.write(FastJsonHttpMessageConverter.java:184) ~[fastjson-1.2.49.jar:na] at org.springframework.web.servlet.mvc.method.annotation.AbstractMessageConverterMethodProcessor.writeWithMessageConverters(AbstractMessageConverterMethodProcessor.java:290) ~[spring-webmvc-5.1.6.RELEASE.jar:5.1.6.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.HttpEntityMethodProcessor.handleReturnValue(HttpEntityMethodProcessor.java:223) ~[spring-webmvc-5.1.6.RELEASE.jar:5.1.6.RELEASE] at org.springframework.web.method.support.HandlerMethodReturnValueHandlerComposite.handleReturnValue(HandlerMethodReturnValueHandlerComposite.java:82) ~[spring-web-5.1.6.RELEASE.jar:5.1.6.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:119) ~[spring-webmvc-5.1.6.RELEASE.jar:5.1.6.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:892) ~[spring-webmvc-5.1.6.RELEASE.jar:5.1.6.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:797) ~[spring-webmvc-5.1.6.RELEASE.jar:5.1.6.RELEASE] at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) ~[spring-webmvc-5.1.6.RELEASE.jar:5.1.6.RELEASE] at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1038) ~[spring-webmvc-5.1.6.RELEASE.jar:5.1.6.RELEASE] at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:942) ~[spring-webmvc-5.1.6.RELEASE.jar:5.1.6.RELEASE] at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1005) ~[spring-webmvc-5.1.6.RELEASE.jar:5.1.6.RELEASE] ... 29 common frames omitted 错误分析idea设置有问题 错误解决下载idea的lombok插件让idea支持lombok编译勾选idea的Enable annotation processing选项，该选项在Preference——Build,Execution,Deployment——Compiler——Annotation Processors中 学习总结lombok常用的注解学习@Data：注解在类上，将类提供的所有属性都添加get、set方法，并添加、equals、canEquals、hashCode、toString方法@Setter：注解在类上，为所有属性添加set方法、注解在属性上为该属性提供set方法@Getter：注解在类上，为所有的属性添加get方法、注解在属性上为该属性提供get方法@NotNull：在参数中使用时，如果调用时传了null值，就会抛出空指针异常@Synchronized 用于方法，可以锁定指定的对象，如果不指定，则默认创建一个对象锁定@Log作用于类，创建一个log属性@Builder：使用builder模式创建对象@NoArgsConstructor：创建一个无参构造函数@AllArgsConstructor：创建一个全参构造函数@ToStirng：创建一个toString方法@Accessors(chain = true)使用链式设置属性，set方法返回的是this对象。@RequiredArgsConstructor：创建对象@UtilityClass:工具类@ExtensionMethod:设置父类@FieldDefaults：设置属性的使用范围，如private、public等，也可以设置属性是否被final修饰。@Cleanup: 关闭流、连接点。@EqualsAndHashCode：重写equals和hashcode方法。@toString：创建toString方法。 【1】简书主页·share猿 【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"spring","slug":"spring","permalink":"https://lywlefan.github.io/tags/spring/"},{"name":"bug","slug":"bug","permalink":"https://lywlefan.github.io/tags/bug/"}]},{"title":"spring的核心jar","date":"2018-05-29T16:00:00.000Z","path":"2018/05/30/软件研发/后端/框架/java/spring/spring的核心jar/","text":"&emsp;&emsp;实践一门技术的最好方式就是深入理解它的思想，然后造一个出来！ Spring AOP：Spring的面向切面编程，提供AOP（面向切面编程）的实现 Spring Aspects：Spring提供的对AspectJ框架的整合 Spring Beans：Spring IOC的基础实现，包含访问配置文件、创建和管理bean等。 Spring Context：在基础IOC功能上提供扩展服务，此外还提供许多企业级服务的支持，有邮件服务、任务调度、JNDI定位，EJB集成、远程访问、缓存以及多种视图层框架的支持。 Spring Context Support：Spring context的扩展支持，用于MVC方面。 Spring Core：Spring的核心工具包 Spring expression：Spring表达式语言 Spring Framework Bom： Spring Instrument：Spring对服务器的代理接口 Spring Instrument Tomcat：Spring对tomcat连接池的集成 Spring JDBC：对JDBC 的简单封装 Spring JMS：为简化jms api的使用而做的简单封装 Spring Messaging： Spring orm：整合第三方的orm实现，如hibernate，ibatis，jdo以及spring 的jpa实现 Spring oxm：Spring对于object/xml映射的支持，可以让JAVA与XML之间来回切换 Spring test：对JUNIT等测试框架的简单封装 Spring tx：为JDBC、Hibernate、JDO、JPA等提供的一致的声明式和编程式事务管理。 Spring web：包含Web应用开发时，用到Spring框架时所需的核心类，包括自动载入WebApplicationContext特性的类、Struts与JSF集成类、文件上传的支持类、Filter类和大量工具辅助类。 Spring webmvc：包含SpringMVC框架相关的所有类。包含国际化、标签、Theme、视图展现的FreeMarker、JasperReports、Tiles、Velocity、XSLT相关类。当然，如果你的应用使用了独立的MVC框架，则无需这个JAR文件里的任何类。 Spring webmvc portlet：Spring MVC的增强 【1】简书主页·share猿 【2】掘金主页·share猿 — 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"spring","slug":"spring","permalink":"https://lywlefan.github.io/tags/spring/"},{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"},{"name":"框架","slug":"框架","permalink":"https://lywlefan.github.io/tags/框架/"}]},{"title":"MySQL优化总结","date":"2018-05-26T16:00:00.000Z","path":"2018/05/27/软件研发/后端/数据存储/关系型数据库/mysql/MySQL优化总结/","text":"&emsp;&emsp;实践一门技术的最好方式就是深入理解它的思想，然后造一个出来！ 数据库设计 适当冗余 冗余长时间不变更的字段 冗余数据增量较小的表的字段,衡量好得失 适当建立索引 可是天下没有免费的午餐，查询速度的提高是以插入、更新、删除的速度为代价的，这些写操作，增加了大量的I/O。 一个表的索引所占空间比数据所占空间还大的情况经常发生. 我们建立一个索引，必须保证这个索引不会“亏本”,一般需要遵守这样的规则： 索引的字段必须是经常作为查询条件的字段 如果索引多个字段，第一个字段要是经常作为查询条件的。如果只有第二个字段作为查询条件，这个索引不会起到作用; 索引的字段必须有足够的区分度; Mysql 对于长字段支持前缀索引(所谓的前缀索引就是某些字段只过长,可以取部分值进行检索); 对表进行水平划分 记录数太多了,上千万条 可以取一个维度对表进行拆分,比如地域/月份 对表进行垂直划分 记录不多,但是字段很长的情况 选择适当的字段类型，特别是主键 保小不保大，能用占用字节小的字段就不用大字段(比如主键，我们强烈建议用自增类型) 值得一提的是，datetime和timestamp，datetime占用8个字节，而timestamp占用4个字节 文件、图片等大文件用文件系统存储，不用数据库外键表示清楚，方便建立索引&emsp;&emsp;我们都知道，在powerdesigner里为两个实体建立关系，生成物理模型时会自动给外键建立索引。所以我们不要怕建立关系把线拉乱，建立个ShortCut就好了。 掌握表的写入时机 同样是写入一个表，先写和后写对后续的操作会产生很大影响 宁可集中批量操作，避免频繁读写&emsp;&emsp;系统里包含了积分部分，学生和老师通过系统做了操作都可以获得积分，而且积分规则很复杂，限制每类操作获得积分不同，每人每天每类积分都有上限。比如登录，一次登录就可以获得1分，但是不管你登录多少次，一天只能累积一个登录积分。这个还是简单的，有的积分很变态，比如老师积分中有一类是看老师判作业的情况，规则是：老师判了作业，发现学生有错的，学生改过了，老师再判，如果这时候学生都对了，就给老师加分，如果学生还是错的，那就接着改，知道学生都改对了，老师都判完了，才能给老师加分。如果用程序来处理，很可能每个功能都会额外的写一堆代码来处理这个鸡肋似的积分。不仅编程的同事干活找不到重点，还平白给数据库带来了很大的压力。经过和需求人员的讨论，确定积分没有必要实时累积，于是我们采取后台脚本批量处理的方式。夜深人静的时候，让机器自己玩去吧。 选择合适的引擎&emsp;&emsp;Mysql提供了很多种引擎，我们用的最多的是myisam，innodb，memory这三类。官方手册上说道myisqm比innodb的读速度要快，大概是3倍。不过书不能尽信啊，《OreIlly.High.Performance.Mysql》这本书里提到了myisam和innodb的比较，在测试中myisam的表现还不及innodb。至于memory，哈哈，还是比较好用的。在批处理种作临时表是个不错的选择(如果内存够大)。在我的一个批处理中，速度比近乎1：10。 Sql语句优化 Sql语句优化工具 慢日志 &emsp;&emsp;配置很简单，参数文件里配置： 12slow_query_log=d:/slow.txtlong_query_time = 2 &amp;emsp;&amp;emsp;慢日志文件可能会很大，让人去看是很难受的事。这时候我们可以通过mysql自带的工具来分析。 【1】简书主页·share猿 【2】掘金主页·share猿 【3】MySQL优化总结·周长亮 — 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"关系型数据库","slug":"关系型数据库","permalink":"https://lywlefan.github.io/tags/关系型数据库/"},{"name":"mysql","slug":"mysql","permalink":"https://lywlefan.github.io/tags/mysql/"}]},{"title":"MySQL优化总结","date":"2017-05-26T16:00:00.000Z","path":"2017/05/27/软件研发/运维/Linux/常用命令总结/","text":"​ 系统命令系统属性查询系统内存使用情况 【1】简书主页·share猿 【2】掘金主页·share猿 【3】MySQL优化总结·周长亮 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"Linux","slug":"Linux","permalink":"https://lywlefan.github.io/tags/Linux/"}]},{"title":"微服务架构导航","date":"2017-05-05T16:00:00.000Z","path":"2017/05/06/软件研发/架构/微服务架构/微服务架构导航/","text":"技术总结服务服务管理部署kubernetes服务通讯治理Istio数据关系数据库分库分表技术简单易用的组件： 当当sharding-jdbc 蘑菇街TSharding 强悍重量级的中间件： sharding TDDL Smart Client的方式（淘宝） Atlas(Qihoo 360) alibaba.cobar(是阿里巴巴（B2B）部门开发) MyCAT（基于阿里开源的Cobar产品而研发） Oceanus(58同城数据库中间件) OneProxy(支付宝首席架构师楼方鑫开发) vitess（谷歌开发的数据库中间件） 文档总结 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 【3】LMAX架构简介·汤雪华 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"微服务","slug":"微服务","permalink":"https://lywlefan.github.io/tags/微服务/"}]},{"title":"Slack","date":"2011-12-31T16:00:00.000Z","path":"2012/01/01/软件研发/工具/团队协作工具/Slack/","text":"工欲善其事，必先利器！ 【1】简书主页·share猿【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"协作","slug":"协作","permalink":"https://lywlefan.github.io/tags/协作/"}]}]